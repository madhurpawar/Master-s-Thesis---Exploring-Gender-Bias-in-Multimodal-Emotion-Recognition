# Master's Thesis: Exploring Gender Bias in Multimodal Emotion Recognition - The Impact of Training Data Representation and Fusion Techniques
This repository contains the code and resources for the thesis on multimodal emotion recognition systems and the analysis of gender bias within these models. The project focuses on evaluating various fusion techniques, datasets, and fairness metrics to understand how gender bias manifests and impacts model performance in emotion recognition systems.

## Repository Structure

- **`/data`**: Contains sample of datasets (RAVDESS and CREMA-D) used in the study as well as the csv files provided with the dataset or generated by us during the development.
- **`/notebooks`**: Includes implementations of the different unimodal and emotion recognition models used in the thesis, such as Audio, Video, Early Fusion, Intermediate Fusion, and Late Fusion models. Model architectures and training routines are provided. Details of implementation are included in the respective notebooks. For maximum and step by step visualization of the flow of experiment, analysis is performed in Jupyter Notebook
- **`/scripts`**: Utility scripts for label extraction, and visualizing results.
- **`/results`**: Contains plots based on the experimentation
