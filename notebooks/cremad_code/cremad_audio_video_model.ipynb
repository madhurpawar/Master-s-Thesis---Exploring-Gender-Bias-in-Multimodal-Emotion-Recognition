{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43f2777e-3afa-4c42-a606-c920a89255fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-07 20:07:45.719066: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import random as rd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "import pickle\n",
    "import dlib\n",
    "\n",
    "from deepface import DeepFace\n",
    "from deepface.basemodels import VGGFace, OpenFace, Facenet, FbDeepFace, DeepID\n",
    "from deepface.extendedmodels import Age, Gender, Race, Emotion\n",
    "#from deepface.modules import verification\n",
    "from deepface.commons import functions, distance as dst\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Input,Conv2D,MaxPooling2D,Dropout,LSTM,\\\n",
    "                            TimeDistributed,Flatten,Dense,Bidirectional,ConvLSTM2D,MaxPooling3D,AveragePooling2D,Lambda,\\\n",
    "                            Activation,BatchNormalization\n",
    "\n",
    "from tensorflow import keras\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a18abb3-f94e-42d0-b2ed-02bc14d2e6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_constant = 27\n",
    "np.random.seed(seed_constant)\n",
    "rd.seed(seed_constant)\n",
    "tf.random.set_seed(seed_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a833c773-f5db-4023-aa1a-8f69a414863b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = '/var/scratch/mpa326/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "526288dc-eb32-42c7-92ff-94856ef33e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = open('/var/scratch/mpa326/CREMA-D_code/Video Features/video_train_50m_50f', 'rb')     \n",
    "df = pickle.load(dbfile)\n",
    "\n",
    "y_train_50m_50f = df['labels']\n",
    "gender_train_50m_50f = df['genders']\n",
    "X_train_50m_50f=df['features']\n",
    "race_train_50m_50f = df['races']\n",
    "ethnicity_train_50m_50f = df['ethnicity']\n",
    "paths_train_50m_50f = df['video_files_paths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70e18466-5b31-4ed0-bdf5-2bce6d24c669",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = open('/var/scratch/mpa326/CREMA-D_code/Video Features/video_train_40m_60f', 'rb')     \n",
    "df = pickle.load(dbfile)\n",
    "\n",
    "y_train_40m_60f = df['labels']\n",
    "gender_train_40m_60f = df['genders']\n",
    "X_train_40m_60f=df['features']\n",
    "race_train_40m_60f = df['races']\n",
    "ethnicity_train_40m_60f = df['ethnicity']\n",
    "paths_train_40m_60f = df['video_files_paths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26ad3349-d728-4973-aa82-9c827c93b8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = open('/var/scratch/mpa326/CREMA-D_code/Video Features/video_train_60m_40f', 'rb')     \n",
    "df = pickle.load(dbfile)\n",
    "\n",
    "y_train_60m_40f = df['labels']\n",
    "gender_train_60m_40f = df['genders']\n",
    "X_train_60m_40f=df['features']\n",
    "race_train_60m_40f = df['races']\n",
    "ethnicity_train_60m_40f = df['ethnicity']\n",
    "paths_train_60m_40f = df['video_files_paths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fee39842-3c4e-42b1-bc33-4f6c993619f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = open('/var/scratch/mpa326/CREMA-D_code/Video Features/video_test_common', 'rb')     \n",
    "df = pickle.load(dbfile)\n",
    "\n",
    "y_test = df['labels']\n",
    "gender_test = df['genders']\n",
    "X_test=df['features']\n",
    "race_test = df['races']\n",
    "ethnicity_test = df['ethnicity']\n",
    "paths_test = df['video_files_paths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07801ff4-4e69-4ddc-8388-d374f29bf0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = open('/var/scratch/mpa326/CREMA-D_code/Audio Features/audio_train_50m_50f', 'rb')     \n",
    "df = pickle.load(dbfile)\n",
    "X_train_aud_50m_50f=df['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49205b85-85aa-46b0-ae8a-2f0e82637e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = open('/var/scratch/mpa326/CREMA-D_code/Audio Features/audio_train_40m_60f', 'rb')     \n",
    "df = pickle.load(dbfile)\n",
    "X_train_aud_40m_60f=df['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4683f799-fc08-42f7-9f7d-395e0652a3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = open('/var/scratch/mpa326/CREMA-D_code/Audio Features/audio_train_60m_40f', 'rb')     \n",
    "df = pickle.load(dbfile)\n",
    "X_train_aud_60m_40f=df['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1235211c-0e94-4fa9-af5f-2cdc3937abc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = open('/var/scratch/mpa326/CREMA-D_code/Audio Features/audio_test_common', 'rb')     \n",
    "df = pickle.load(dbfile)\n",
    "X_test_aud=df['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47fc5839-027a-4a00-9f64-946f097448bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X_train_50m_50f, X_train_aud_50m_50f, y_train_50m_50f, gender_train_50m_50f, race_train_50m_50f, ethnicity_train_50m_50f = shuffle(X_train_50m_50f, X_train_aud_50m_50f, y_train_50m_50f, gender_train_50m_50f, race_train_50m_50f, ethnicity_train_50m_50f, random_state=27)\n",
    "X_train_50m_50f, X_train_aud_50m_50f, y_train_50m_50f, gender_train_50m_50f, race_train_50m_50f, ethnicity_train_50m_50f = shuffle(X_train_50m_50f, X_train_aud_50m_50f, y_train_50m_50f, gender_train_50m_50f, race_train_50m_50f, ethnicity_train_50m_50f, random_state=7)\n",
    "X_train_50m_50f, X_train_aud_50m_50f, y_train_50m_50f, gender_train_50m_50f, race_train_50m_50f, ethnicity_train_50m_50f = shuffle(X_train_50m_50f, X_train_aud_50m_50f, y_train_50m_50f, gender_train_50m_50f, race_train_50m_50f, ethnicity_train_50m_50f, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c06c838f-5cbe-4fa0-871a-8b22964427f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_40m_60f, X_train_aud_40m_60f, y_train_40m_60f, gender_train_40m_60f, race_train_40m_60f, ethnicity_train_40m_60f = shuffle(X_train_40m_60f, X_train_aud_40m_60f, y_train_40m_60f, gender_train_40m_60f, race_train_40m_60f, ethnicity_train_40m_60f, random_state=27)\n",
    "X_train_40m_60f, X_train_aud_40m_60f, y_train_40m_60f, gender_train_40m_60f, race_train_40m_60f, ethnicity_train_40m_60f = shuffle(X_train_40m_60f, X_train_aud_40m_60f, y_train_40m_60f, gender_train_40m_60f, race_train_40m_60f, ethnicity_train_40m_60f, random_state=7)\n",
    "X_train_40m_60f, X_train_aud_40m_60f, y_train_40m_60f, gender_train_40m_60f, race_train_40m_60f, ethnicity_train_40m_60f = shuffle(X_train_40m_60f, X_train_aud_40m_60f, y_train_40m_60f, gender_train_40m_60f, race_train_40m_60f, ethnicity_train_40m_60f, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae008154-e418-41e5-ae71-02b4cdfbaee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_60m_40f, X_train_aud_60m_40f, y_train_60m_40f, gender_train_60m_40f, race_train_60m_40f, ethnicity_train_60m_40f = shuffle(X_train_60m_40f, X_train_aud_60m_40f, y_train_60m_40f, gender_train_60m_40f, race_train_60m_40f, ethnicity_train_60m_40f, random_state=27)\n",
    "X_train_60m_40f, X_train_aud_60m_40f, y_train_60m_40f, gender_train_60m_40f, race_train_60m_40f, ethnicity_train_60m_40f = shuffle(X_train_60m_40f, X_train_aud_60m_40f, y_train_60m_40f, gender_train_60m_40f, race_train_60m_40f, ethnicity_train_60m_40f, random_state=7)\n",
    "X_train_60m_40f, X_train_aud_60m_40f, y_train_60m_40f, gender_train_60m_40f, race_train_60m_40f, ethnicity_train_60m_40f = shuffle(X_train_60m_40f, X_train_aud_60m_40f, y_train_60m_40f, gender_train_60m_40f, race_train_60m_40f, ethnicity_train_60m_40f, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "723a89dc-c071-4f0f-9d0d-6a652b6b954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_test_aud, y_test, gender_test, race_test, ethnicity_test = shuffle(X_test, X_test_aud, y_test, gender_test, race_test, ethnicity_test, random_state=27)\n",
    "X_test, X_test_aud, y_test, gender_test, race_test, ethnicity_test = shuffle(X_test, X_test_aud, y_test, gender_test, race_test, ethnicity_test, random_state=7)\n",
    "X_test, X_test_aud, y_test, gender_test, race_test, ethnicity_test = shuffle(X_test, X_test_aud, y_test, gender_test, race_test, ethnicity_test, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d5c354b-2ad2-40c7-a6c8-8f3bacd2832c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_2\n",
      "average_pooling2d\n",
      "conv2d_3\n",
      "conv2d_4\n",
      "average_pooling2d_1\n",
      "flatten\n",
      "dense\n",
      "dropout\n",
      "dense_1\n",
      "dropout_1\n",
      "dense_2\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "emotion=Emotion.loadModel()\n",
    "for layer in emotion.layers:\n",
    "    print(layer.name)\n",
    "features_emotion=Model(inputs=emotion.input, outputs=emotion.get_layer('dense_1').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "197b911e-e440-4bfa-a6d0-1db96b23cbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_input (InputLayer)   [(None, 48, 48, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 44, 44, 64)        1664      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 20, 20, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 18, 18, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " average_pooling2d (Average  (None, 7, 7, 64)          0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 5, 5, 128)         73856     \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 3, 3, 128)         147584    \n",
      "                                                                 \n",
      " average_pooling2d_1 (Avera  (None, 1, 1, 128)         0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              132096    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1478656 (5.64 MB)\n",
      "Trainable params: 1478656 (5.64 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "features_emotion.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1737975-d04c-485e-b899-c3134799a7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1487"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed7f02bb-4e68-47c1-8f75-a7e05d3a3300",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = np.ones((4678,20,48,48))\n",
    "for i in range(4678):\n",
    "  for j in range(20):\n",
    "    img=X_train_50m_50f[i][j]\n",
    "    img=img.astype(np.float32)\n",
    "    # df_[i][j]=cv2.resize(img,(48, 48))/255\n",
    "    df_[i][j]=img/255\n",
    "X_train_50m_50f=df_\n",
    "df_=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05720b5c-1e66-40c0-b79b-21e30e07a9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = np.ones((4678,20,48,48))\n",
    "for i in range(4678):\n",
    "  for j in range(20):\n",
    "    img=X_train_40m_60f[i][j]\n",
    "    img=img.astype(np.float32)\n",
    "    # df_[i][j]=cv2.resize(img,(48, 48))/255\n",
    "    df_[i][j]=img/255\n",
    "X_train_40m_60f=df_\n",
    "df_=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51bab63d-7b89-4b85-aecb-8adcc1f3b46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = np.ones((4677,20,48,48))\n",
    "for i in range(4677):\n",
    "  for j in range(20):\n",
    "    img=X_train_60m_40f[i][j]\n",
    "    img=img.astype(np.float32)\n",
    "    # df_[i][j]=cv2.resize(img,(48, 48))/255\n",
    "    df_[i][j]=img/255\n",
    "X_train_60m_40f=df_\n",
    "df_=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94695bb6-1e1e-4505-bb33-4968e1520b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = np.ones((1487,20,48,48))\n",
    "for i in range(1487):\n",
    "  for j in range(20):\n",
    "    img=X_test[i][j]\n",
    "    img=img.astype(np.float32)\n",
    "    # df_[i][j]=cv2.resize(img,(48, 48))/255\n",
    "    df_[i][j]=img/255\n",
    "X_test=df_\n",
    "df_=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a62b0f72-301a-4b4e-bae0-5e88e258dfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_emotion.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4613c102-6af2-454c-b834-8d7283ad79b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spatial transformer network (STN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01e9261d-a308-4440-90eb-c5e767deea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Localization(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Localization, self).__init__()\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(20, [5, 5], activation='relu')\n",
    "        self.pool2 = tf.keras.layers.MaxPool2D()\n",
    "        self.conv2 = tf.keras.layers.Conv2D(20, [5, 5], activation='relu')\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc1 = tf.keras.layers.Dense(20, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(6, activation=None, bias_initializer=tf.keras.initializers.constant([1.0, 0.0, 0.0, 0.0, 1.0, 0.0]), kernel_initializer='zeros')\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        print(\"Building Localization Network with input shape:\", input_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [None, 2, 3]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        theta = self.fc2(x)\n",
    "        theta = tf.keras.layers.Reshape((2, 3))(theta)\n",
    "        return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77db6e8e-9d10-4194-82d5-a31b7b6402cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BilinearInterpolation(tf.keras.layers.Layer):\n",
    "    def __init__(self, height=40, width=40):\n",
    "        super(BilinearInterpolation, self).__init__()\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [None, self.height, self.width, 1]\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            'height': self.height,\n",
    "            'width': self.width,\n",
    "        }\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        print(\"Building Bilinear Interpolation Layer with input shape:\", input_shape)\n",
    "\n",
    "    def advance_indexing(self, inputs, x, y):\n",
    "        '''\n",
    "        Numpy like advance indexing is not supported in tensorflow, hence, this function is a hack around the same method\n",
    "        '''        \n",
    "        shape = tf.shape(inputs)\n",
    "        batch_size, _, _ = shape[0], shape[1], shape[2]\n",
    "        \n",
    "        batch_idx = tf.range(0, batch_size)\n",
    "        batch_idx = tf.reshape(batch_idx, (batch_size, 1, 1))\n",
    "        b = tf.tile(batch_idx, (1, self.height, self.width))\n",
    "        indices = tf.stack([b, y, x], 3)\n",
    "        return tf.gather_nd(inputs, indices)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        images, theta = inputs\n",
    "        homogenous_coordinates = self.grid_generator(batch=tf.shape(images)[0])\n",
    "        return self.interpolate(images, homogenous_coordinates, theta)\n",
    "\n",
    "    def grid_generator(self, batch):\n",
    "        x = tf.linspace(-1, 1, self.width)\n",
    "        y = tf.linspace(-1, 1, self.height)\n",
    "            \n",
    "        xx, yy = tf.meshgrid(x, y)\n",
    "        xx = tf.reshape(xx, (-1,))\n",
    "        yy = tf.reshape(yy, (-1,))\n",
    "        homogenous_coordinates = tf.stack([xx, yy, tf.ones_like(xx)])\n",
    "        homogenous_coordinates = tf.expand_dims(homogenous_coordinates, axis=0)\n",
    "        homogenous_coordinates = tf.tile(homogenous_coordinates, [batch, 1, 1])\n",
    "        homogenous_coordinates = tf.cast(homogenous_coordinates, dtype=tf.float32)\n",
    "        return homogenous_coordinates\n",
    "    \n",
    "    def interpolate(self, images, homogenous_coordinates, theta):\n",
    "\n",
    "        with tf.name_scope(\"Transformation\"):\n",
    "            transformed = tf.matmul(theta, homogenous_coordinates)\n",
    "            transformed = tf.transpose(transformed, perm=[0, 2, 1])\n",
    "            transformed = tf.reshape(transformed, [-1, self.height, self.width, 2])\n",
    "                \n",
    "            x_transformed = transformed[:, :, :, 0]\n",
    "            y_transformed = transformed[:, :, :, 1]\n",
    "                \n",
    "            x = ((x_transformed + 1.) * tf.cast(self.width, dtype=tf.float32)) * 0.5\n",
    "            y = ((y_transformed + 1.) * tf.cast(self.height, dtype=tf.float32)) * 0.5\n",
    "\n",
    "        with tf.name_scope(\"VariableCasting\"):\n",
    "            x0 = tf.cast(tf.math.floor(x), dtype=tf.int32)\n",
    "            x1 = x0 + 1\n",
    "            y0 = tf.cast(tf.math.floor(y), dtype=tf.int32)\n",
    "            y1 = y0 + 1\n",
    "\n",
    "            x0 = tf.clip_by_value(x0, 0, self.width-1)\n",
    "            x1 = tf.clip_by_value(x1, 0, self.width-1)\n",
    "            y0 = tf.clip_by_value(y0, 0, self.height-1)\n",
    "            y1 = tf.clip_by_value(y1, 0, self.height-1)\n",
    "            x = tf.clip_by_value(x, 0, tf.cast(self.width, dtype=tf.float32)-1.0)\n",
    "            y = tf.clip_by_value(y, 0, tf.cast(self.height, dtype=tf.float32)-1)\n",
    "\n",
    "        with tf.name_scope(\"AdvanceIndexing\"):\n",
    "            Ia = self.advance_indexing(images, x0, y0)\n",
    "            Ib = self.advance_indexing(images, x0, y1)\n",
    "            Ic = self.advance_indexing(images, x1, y0)\n",
    "            Id = self.advance_indexing(images, x1, y1)\n",
    "\n",
    "        with tf.name_scope(\"Interpolation\"):\n",
    "            x0 = tf.cast(x0, dtype=tf.float32)\n",
    "            x1 = tf.cast(x1, dtype=tf.float32)\n",
    "            y0 = tf.cast(y0, dtype=tf.float32)\n",
    "            y1 = tf.cast(y1, dtype=tf.float32)\n",
    "                            \n",
    "            wa = (x1-x) * (y1-y)\n",
    "            wb = (x1-x) * (y-y0)\n",
    "            wc = (x-x0) * (y1-y)\n",
    "            wd = (x-x0) * (y-y0)\n",
    "\n",
    "            wa = tf.expand_dims(wa, axis=3)\n",
    "            wb = tf.expand_dims(wb, axis=3)\n",
    "            wc = tf.expand_dims(wc, axis=3)\n",
    "            wd = tf.expand_dims(wd, axis=3)\n",
    "                        \n",
    "        return tf.math.add_n([wa*Ia + wb*Ib + wc*Ic + wd*Id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bfaff051-29e1-42fc-bbb1-5ab7084e2fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_en = ['ANG', 'DIS', 'FEA', 'HAP', 'NEU', 'SAD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc8c6349-b092-4ee0-b548-f4b339ba7210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create__LRCN_with_STN() :\n",
    "  image = tf.keras.layers.Input(shape=(20,48,48,1))\n",
    "  theta = TimeDistributed(Localization())(image)\n",
    "  x = TimeDistributed(BilinearInterpolation(height=48, width=48))([image, theta])\n",
    "  features=TimeDistributed(features_emotion)(x)\n",
    "  lstm=Bidirectional(LSTM(200, activation='tanh',input_shape=(20, 1024),dropout=.3))(features)\n",
    "  out=Dense(len(emotions_en), activation = 'softmax')(lstm)\n",
    "\n",
    "  return tf.keras.models.Model(inputs=image, outputs=out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24f15e29-c225-44ac-940d-2de997b52da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Localization Network with input shape: (None, 48, 48, 1)\n",
      "Building Bilinear Interpolation Layer with input shape: ((None, 48, 48, 1), (None, 2, 3))\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 20, 48, 48, 1)]      0         []                            \n",
      "                                                                                                  \n",
      " time_distributed (TimeDist  (None, 20, 2, 3)             43086     ['input_1[0][0]']             \n",
      " ributed)                                                                                         \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDi  (None, 20, 48, 48, 1)        0         ['input_1[0][0]',             \n",
      " stributed)                                                          'time_distributed[0][0]']    \n",
      "                                                                                                  \n",
      " time_distributed_2 (TimeDi  (None, 20, 1024)             1478656   ['time_distributed_1[0][0]']  \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " bidirectional (Bidirection  (None, 400)                  1960000   ['time_distributed_2[0][0]']  \n",
      " al)                                                                                              \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 6)                    2406      ['bidirectional[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3484148 (13.29 MB)\n",
      "Trainable params: 2005492 (7.65 MB)\n",
      "Non-trainable params: 1478656 (5.64 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "create__LRCN_with_STN().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6fabdc4-ce17-4161-b588-976af45c0155",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(k):\n",
    "    return 'model_'+str(k)+'.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ee6f9f0-e38a-4431-9819-8059800399d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "seed = 7\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=False, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f0de64f-732b-4a74-9e69-75ca401a20dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Female appears 2338 times\n",
      "Value Male appears 2340 times\n"
     ]
    }
   ],
   "source": [
    "unique_values, counts = np.unique(gender_train_50m_50f, return_counts=True)\n",
    "\n",
    "# Print the results\n",
    "for value, count in zip(unique_values, counts):\n",
    "    print(f\"Value {value} appears {count} times\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c3c10ba6-f80b-4125-9354-765574394339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value African American appears 1139 times\n",
      "Value Asian appears 346 times\n",
      "Value Caucasian appears 3140 times\n",
      "Value Unknown appears 53 times\n"
     ]
    }
   ],
   "source": [
    "unique_values, counts = np.unique(race_train_50m_50f, return_counts=True)\n",
    "\n",
    "# Print the results\n",
    "for value, count in zip(unique_values, counts):\n",
    "    print(f\"Value {value} appears {count} times\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31785bcd-0455-4394-a5d9-3b7facdd43c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Female appears 1870 times\n",
      "Value Male appears 2807 times\n"
     ]
    }
   ],
   "source": [
    "unique_values, counts = np.unique(gender_train_60m_40f, return_counts=True)\n",
    "\n",
    "# Print the results\n",
    "for value, count in zip(unique_values, counts):\n",
    "    print(f\"Value {value} appears {count} times\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a8b415a-de07-48a5-98ab-611c598f81b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value African American appears 1176 times\n",
      "Value Asian appears 376 times\n",
      "Value Caucasian appears 3085 times\n",
      "Value Unknown appears 40 times\n"
     ]
    }
   ],
   "source": [
    "unique_values, counts = np.unique(race_train_60m_40f, return_counts=True)\n",
    "\n",
    "# Print the results\n",
    "for value, count in zip(unique_values, counts):\n",
    "    print(f\"Value {value} appears {count} times\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e887ba1-d21b-4b1f-adfa-46cc12287a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Localization Network with input shape: (None, 48, 48, 1)\n",
      "Building Bilinear Interpolation Layer with input shape: ((None, 48, 48, 1), (None, 2, 3))\n",
      "Epoch 1/80\n",
      "117/117 [==============================] - 88s 707ms/step - loss: 1.4053 - accuracy: 0.4362 - val_loss: 1.3996 - val_accuracy: 0.4295\n",
      "Epoch 2/80\n",
      "117/117 [==============================] - 81s 694ms/step - loss: 1.2630 - accuracy: 0.4975 - val_loss: 1.2819 - val_accuracy: 0.4872\n",
      "Epoch 3/80\n",
      "117/117 [==============================] - 81s 693ms/step - loss: 1.1728 - accuracy: 0.5394 - val_loss: 1.2129 - val_accuracy: 0.5353\n",
      "Epoch 4/80\n",
      "117/117 [==============================] - 82s 699ms/step - loss: 1.0991 - accuracy: 0.5624 - val_loss: 1.1476 - val_accuracy: 0.5385\n",
      "Epoch 5/80\n",
      "117/117 [==============================] - 83s 713ms/step - loss: 1.0287 - accuracy: 0.5929 - val_loss: 1.1055 - val_accuracy: 0.5630\n",
      "Epoch 6/80\n",
      "117/117 [==============================] - 83s 709ms/step - loss: 0.9667 - accuracy: 0.6236 - val_loss: 1.1039 - val_accuracy: 0.5833\n",
      "Epoch 7/80\n",
      "117/117 [==============================] - 84s 716ms/step - loss: 0.9214 - accuracy: 0.6434 - val_loss: 1.1168 - val_accuracy: 0.5705\n",
      "Epoch 8/80\n",
      "117/117 [==============================] - 84s 717ms/step - loss: 0.8570 - accuracy: 0.6672 - val_loss: 1.1019 - val_accuracy: 0.5876\n",
      "Epoch 9/80\n",
      "117/117 [==============================] - 87s 742ms/step - loss: 0.7837 - accuracy: 0.6985 - val_loss: 1.1497 - val_accuracy: 0.5844\n",
      "Epoch 10/80\n",
      "117/117 [==============================] - 86s 731ms/step - loss: 0.7284 - accuracy: 0.7271 - val_loss: 1.1388 - val_accuracy: 0.5823\n",
      "Epoch 11/80\n",
      "117/117 [==============================] - 85s 729ms/step - loss: 0.6739 - accuracy: 0.7396 - val_loss: 1.2094 - val_accuracy: 0.5620\n",
      "Epoch 12/80\n",
      "117/117 [==============================] - 88s 749ms/step - loss: 0.5917 - accuracy: 0.7773 - val_loss: 1.1466 - val_accuracy: 0.6015\n",
      "Epoch 13/80\n",
      "117/117 [==============================] - 87s 741ms/step - loss: 0.5269 - accuracy: 0.8073 - val_loss: 1.2365 - val_accuracy: 0.5844\n",
      "Epoch 14/80\n",
      "117/117 [==============================] - 88s 755ms/step - loss: 0.4565 - accuracy: 0.8311 - val_loss: 1.3024 - val_accuracy: 0.5780\n",
      "Epoch 15/80\n",
      "117/117 [==============================] - 88s 756ms/step - loss: 0.4032 - accuracy: 0.8492 - val_loss: 1.3314 - val_accuracy: 0.5801\n",
      "Epoch 16/80\n",
      "117/117 [==============================] - 89s 765ms/step - loss: 0.3370 - accuracy: 0.8794 - val_loss: 1.3388 - val_accuracy: 0.5962\n",
      "Epoch 17/80\n",
      "117/117 [==============================] - 89s 762ms/step - loss: 0.3081 - accuracy: 0.8885 - val_loss: 1.3812 - val_accuracy: 0.5983\n",
      "Epoch 18/80\n",
      "117/117 [==============================] - 89s 764ms/step - loss: 0.2457 - accuracy: 0.9150 - val_loss: 1.4591 - val_accuracy: 0.5929\n",
      "Epoch 19/80\n",
      "117/117 [==============================] - 91s 780ms/step - loss: 0.2152 - accuracy: 0.9286 - val_loss: 1.5555 - val_accuracy: 0.5823\n",
      "Epoch 20/80\n",
      "117/117 [==============================] - 90s 772ms/step - loss: 0.1745 - accuracy: 0.9423 - val_loss: 1.6420 - val_accuracy: 0.5876\n",
      "Epoch 21/80\n",
      "117/117 [==============================] - 90s 773ms/step - loss: 0.1606 - accuracy: 0.9479 - val_loss: 1.6806 - val_accuracy: 0.5769\n",
      "Epoch 22/80\n",
      "117/117 [==============================] - 90s 772ms/step - loss: 0.1283 - accuracy: 0.9610 - val_loss: 1.6656 - val_accuracy: 0.5897\n",
      "Epoch 23/80\n",
      "117/117 [==============================] - 91s 779ms/step - loss: 0.1200 - accuracy: 0.9644 - val_loss: 1.7891 - val_accuracy: 0.5748\n",
      "Epoch 24/80\n",
      "117/117 [==============================] - 91s 781ms/step - loss: 0.1058 - accuracy: 0.9709 - val_loss: 1.7528 - val_accuracy: 0.5780\n",
      "Epoch 25/80\n",
      "117/117 [==============================] - 92s 783ms/step - loss: 0.0995 - accuracy: 0.9733 - val_loss: 1.8456 - val_accuracy: 0.5801\n",
      "Epoch 26/80\n",
      "117/117 [==============================] - 91s 777ms/step - loss: 0.0862 - accuracy: 0.9754 - val_loss: 1.9167 - val_accuracy: 0.5812\n",
      "Epoch 27/80\n",
      "117/117 [==============================] - 91s 777ms/step - loss: 0.0650 - accuracy: 0.9829 - val_loss: 1.9395 - val_accuracy: 0.5759\n",
      "47/47 [==============================] - 7s 151ms/step - loss: 1.1363 - accuracy: 0.6026\n",
      "Building Localization Network with input shape: (None, 48, 48, 1)\n",
      "Building Bilinear Interpolation Layer with input shape: ((None, 48, 48, 1), (None, 2, 3))\n",
      "Epoch 1/80\n",
      "117/117 [==============================] - 95s 780ms/step - loss: 1.3744 - accuracy: 0.4501 - val_loss: 1.2553 - val_accuracy: 0.4957\n",
      "Epoch 2/80\n",
      "117/117 [==============================] - 86s 739ms/step - loss: 1.1991 - accuracy: 0.5365 - val_loss: 1.1778 - val_accuracy: 0.5342\n",
      "Epoch 3/80\n",
      "117/117 [==============================] - 87s 747ms/step - loss: 1.1149 - accuracy: 0.5616 - val_loss: 1.1437 - val_accuracy: 0.5406\n",
      "Epoch 4/80\n",
      "117/117 [==============================] - 87s 743ms/step - loss: 1.0441 - accuracy: 0.5948 - val_loss: 1.1416 - val_accuracy: 0.5417\n",
      "Epoch 5/80\n",
      "117/117 [==============================] - 87s 742ms/step - loss: 0.9846 - accuracy: 0.6140 - val_loss: 1.1098 - val_accuracy: 0.5470\n",
      "Epoch 6/80\n",
      "117/117 [==============================] - 87s 740ms/step - loss: 0.9303 - accuracy: 0.6490 - val_loss: 1.0947 - val_accuracy: 0.5780\n",
      "Epoch 7/80\n",
      "117/117 [==============================] - 87s 742ms/step - loss: 0.8786 - accuracy: 0.6533 - val_loss: 1.0953 - val_accuracy: 0.5780\n",
      "Epoch 8/80\n",
      "117/117 [==============================] - 88s 753ms/step - loss: 0.8113 - accuracy: 0.6913 - val_loss: 1.1048 - val_accuracy: 0.5620\n",
      "Epoch 9/80\n",
      "117/117 [==============================] - 92s 786ms/step - loss: 0.7364 - accuracy: 0.7225 - val_loss: 1.0921 - val_accuracy: 0.5630\n",
      "Epoch 10/80\n",
      "117/117 [==============================] - 121s 1s/step - loss: 0.6673 - accuracy: 0.7490 - val_loss: 1.1087 - val_accuracy: 0.5855\n",
      "Epoch 11/80\n",
      "117/117 [==============================] - 150s 1s/step - loss: 0.6075 - accuracy: 0.7736 - val_loss: 1.1188 - val_accuracy: 0.5652\n",
      "Epoch 12/80\n",
      "117/117 [==============================] - 134s 1s/step - loss: 0.5396 - accuracy: 0.7971 - val_loss: 1.1640 - val_accuracy: 0.5748\n",
      "Epoch 13/80\n",
      "117/117 [==============================] - 120s 1s/step - loss: 0.4840 - accuracy: 0.8241 - val_loss: 1.1970 - val_accuracy: 0.5897\n",
      "Epoch 14/80\n",
      "117/117 [==============================] - 91s 780ms/step - loss: 0.4233 - accuracy: 0.8428 - val_loss: 1.2537 - val_accuracy: 0.5769\n",
      "Epoch 15/80\n",
      "117/117 [==============================] - 112s 961ms/step - loss: 0.3481 - accuracy: 0.8802 - val_loss: 1.2724 - val_accuracy: 0.5865\n",
      "Epoch 16/80\n",
      "117/117 [==============================] - 141s 1s/step - loss: 0.3269 - accuracy: 0.8840 - val_loss: 1.3270 - val_accuracy: 0.5908\n",
      "Epoch 17/80\n",
      "117/117 [==============================] - 144s 1s/step - loss: 0.2573 - accuracy: 0.9131 - val_loss: 1.3606 - val_accuracy: 0.5919\n",
      "Epoch 18/80\n",
      "117/117 [==============================] - 143s 1s/step - loss: 0.2154 - accuracy: 0.9270 - val_loss: 1.4569 - val_accuracy: 0.5759\n",
      "Epoch 19/80\n",
      "117/117 [==============================] - 147s 1s/step - loss: 0.2145 - accuracy: 0.9281 - val_loss: 1.4879 - val_accuracy: 0.5855\n",
      "Epoch 20/80\n",
      "117/117 [==============================] - 147s 1s/step - loss: 0.1455 - accuracy: 0.9540 - val_loss: 1.5789 - val_accuracy: 0.5897\n",
      "Epoch 21/80\n",
      "117/117 [==============================] - 148s 1s/step - loss: 0.1431 - accuracy: 0.9522 - val_loss: 1.6096 - val_accuracy: 0.5908\n",
      "Epoch 22/80\n",
      "117/117 [==============================] - 148s 1s/step - loss: 0.1094 - accuracy: 0.9685 - val_loss: 1.6067 - val_accuracy: 0.5876\n",
      "Epoch 23/80\n",
      "117/117 [==============================] - 150s 1s/step - loss: 0.0970 - accuracy: 0.9727 - val_loss: 1.6823 - val_accuracy: 0.5588\n",
      "Epoch 24/80\n",
      "117/117 [==============================] - 149s 1s/step - loss: 0.1002 - accuracy: 0.9727 - val_loss: 1.7095 - val_accuracy: 0.5929\n",
      "Epoch 25/80\n",
      "117/117 [==============================] - 149s 1s/step - loss: 0.1082 - accuracy: 0.9647 - val_loss: 1.7432 - val_accuracy: 0.5812\n",
      "Epoch 26/80\n",
      "117/117 [==============================] - 148s 1s/step - loss: 0.0644 - accuracy: 0.9821 - val_loss: 1.8838 - val_accuracy: 0.5620\n",
      "Epoch 27/80\n",
      "117/117 [==============================] - 151s 1s/step - loss: 0.0457 - accuracy: 0.9893 - val_loss: 1.8508 - val_accuracy: 0.5673\n",
      "Epoch 28/80\n",
      "117/117 [==============================] - 152s 1s/step - loss: 0.0512 - accuracy: 0.9858 - val_loss: 1.8984 - val_accuracy: 0.5577\n",
      "Epoch 29/80\n",
      "117/117 [==============================] - 150s 1s/step - loss: 0.0992 - accuracy: 0.9703 - val_loss: 1.8541 - val_accuracy: 0.5588\n",
      "Epoch 30/80\n",
      "117/117 [==============================] - 149s 1s/step - loss: 0.0612 - accuracy: 0.9824 - val_loss: 1.8184 - val_accuracy: 0.5812\n",
      "Epoch 31/80\n",
      "117/117 [==============================] - 150s 1s/step - loss: 0.0761 - accuracy: 0.9770 - val_loss: 1.8741 - val_accuracy: 0.5641\n",
      "Epoch 32/80\n",
      "117/117 [==============================] - 149s 1s/step - loss: 0.0673 - accuracy: 0.9797 - val_loss: 1.8867 - val_accuracy: 0.5833\n",
      "Epoch 33/80\n",
      "117/117 [==============================] - 152s 1s/step - loss: 0.0494 - accuracy: 0.9864 - val_loss: 1.9545 - val_accuracy: 0.5983\n",
      "Epoch 34/80\n",
      "117/117 [==============================] - 151s 1s/step - loss: 0.0277 - accuracy: 0.9955 - val_loss: 2.0263 - val_accuracy: 0.5865\n",
      "Epoch 35/80\n",
      "117/117 [==============================] - 151s 1s/step - loss: 0.0450 - accuracy: 0.9861 - val_loss: 2.0551 - val_accuracy: 0.5620\n",
      "Epoch 36/80\n",
      "117/117 [==============================] - 152s 1s/step - loss: 0.0758 - accuracy: 0.9770 - val_loss: 2.0094 - val_accuracy: 0.5545\n",
      "Epoch 37/80\n",
      "117/117 [==============================] - 155s 1s/step - loss: 0.0930 - accuracy: 0.9687 - val_loss: 2.0712 - val_accuracy: 0.5524\n",
      "Epoch 38/80\n",
      "117/117 [==============================] - 156s 1s/step - loss: 0.0832 - accuracy: 0.9711 - val_loss: 1.9782 - val_accuracy: 0.5641\n",
      "Epoch 39/80\n",
      "117/117 [==============================] - 157s 1s/step - loss: 0.0473 - accuracy: 0.9861 - val_loss: 1.9495 - val_accuracy: 0.5513\n",
      "Epoch 40/80\n",
      "117/117 [==============================] - 156s 1s/step - loss: 0.0378 - accuracy: 0.9920 - val_loss: 2.0132 - val_accuracy: 0.5844\n",
      "Epoch 41/80\n",
      "117/117 [==============================] - 157s 1s/step - loss: 0.0497 - accuracy: 0.9840 - val_loss: 2.0672 - val_accuracy: 0.5652\n",
      "Epoch 42/80\n",
      "117/117 [==============================] - 159s 1s/step - loss: 0.0362 - accuracy: 0.9928 - val_loss: 2.0269 - val_accuracy: 0.5609\n",
      "Epoch 43/80\n",
      "117/117 [==============================] - 157s 1s/step - loss: 0.0271 - accuracy: 0.9939 - val_loss: 2.0369 - val_accuracy: 0.5662\n",
      "Epoch 44/80\n",
      "117/117 [==============================] - 156s 1s/step - loss: 0.0275 - accuracy: 0.9917 - val_loss: 2.1581 - val_accuracy: 0.5737\n",
      "Epoch 45/80\n",
      "117/117 [==============================] - 155s 1s/step - loss: 0.0368 - accuracy: 0.9890 - val_loss: 2.1612 - val_accuracy: 0.5662\n",
      "Epoch 46/80\n",
      "117/117 [==============================] - 157s 1s/step - loss: 0.0423 - accuracy: 0.9874 - val_loss: 2.2715 - val_accuracy: 0.5812\n",
      "Epoch 47/80\n",
      "117/117 [==============================] - 158s 1s/step - loss: 0.0780 - accuracy: 0.9735 - val_loss: 2.0691 - val_accuracy: 0.5598\n",
      "Epoch 48/80\n",
      "117/117 [==============================] - 157s 1s/step - loss: 0.0733 - accuracy: 0.9781 - val_loss: 2.0636 - val_accuracy: 0.5726\n",
      "47/47 [==============================] - 13s 279ms/step - loss: 1.9875 - accuracy: 0.5730\n",
      "Building Localization Network with input shape: (None, 48, 48, 1)\n",
      "Building Bilinear Interpolation Layer with input shape: ((None, 48, 48, 1), (None, 2, 3))\n",
      "Epoch 1/80\n",
      "117/117 [==============================] - 170s 1s/step - loss: 1.3802 - accuracy: 0.4401 - val_loss: 1.2396 - val_accuracy: 0.5144\n",
      "Epoch 2/80\n",
      "117/117 [==============================] - 153s 1s/step - loss: 1.2064 - accuracy: 0.5206 - val_loss: 1.2236 - val_accuracy: 0.5155\n",
      "Epoch 3/80\n",
      "117/117 [==============================] - 154s 1s/step - loss: 1.1163 - accuracy: 0.5564 - val_loss: 1.1974 - val_accuracy: 0.5273\n",
      "Epoch 4/80\n",
      "117/117 [==============================] - 155s 1s/step - loss: 1.0553 - accuracy: 0.5917 - val_loss: 1.1364 - val_accuracy: 0.5572\n",
      "Epoch 5/80\n",
      "117/117 [==============================] - 156s 1s/step - loss: 0.9856 - accuracy: 0.6136 - val_loss: 1.1103 - val_accuracy: 0.5882\n",
      "Epoch 6/80\n",
      "117/117 [==============================] - 155s 1s/step - loss: 0.9368 - accuracy: 0.6339 - val_loss: 1.1243 - val_accuracy: 0.5711\n",
      "Epoch 7/80\n",
      "117/117 [==============================] - 156s 1s/step - loss: 0.8774 - accuracy: 0.6507 - val_loss: 1.1294 - val_accuracy: 0.5583\n",
      "Epoch 8/80\n",
      "117/117 [==============================] - 158s 1s/step - loss: 0.7899 - accuracy: 0.6988 - val_loss: 1.1087 - val_accuracy: 0.5840\n",
      "Epoch 9/80\n",
      "117/117 [==============================] - 260s 2s/step - loss: 0.7579 - accuracy: 0.7084 - val_loss: 1.1155 - val_accuracy: 0.5893\n",
      "Epoch 10/80\n",
      "117/117 [==============================] - 157s 1s/step - loss: 0.6815 - accuracy: 0.7384 - val_loss: 1.2036 - val_accuracy: 0.5497\n",
      "Epoch 11/80\n",
      "117/117 [==============================] - 157s 1s/step - loss: 0.6105 - accuracy: 0.7750 - val_loss: 1.1722 - val_accuracy: 0.5722\n",
      "Epoch 12/80\n",
      "117/117 [==============================] - 157s 1s/step - loss: 0.5357 - accuracy: 0.7990 - val_loss: 1.1837 - val_accuracy: 0.5711\n",
      "Epoch 13/80\n",
      "117/117 [==============================] - 156s 1s/step - loss: 0.4765 - accuracy: 0.8180 - val_loss: 1.2716 - val_accuracy: 0.5711\n",
      "Epoch 14/80\n",
      "117/117 [==============================] - 155s 1s/step - loss: 0.4307 - accuracy: 0.8405 - val_loss: 1.3301 - val_accuracy: 0.5583\n",
      "Epoch 15/80\n",
      "117/117 [==============================] - 112s 954ms/step - loss: 0.3456 - accuracy: 0.8752 - val_loss: 1.3690 - val_accuracy: 0.5647\n",
      "Epoch 16/80\n",
      "117/117 [==============================] - 112s 962ms/step - loss: 0.2964 - accuracy: 0.8979 - val_loss: 1.4795 - val_accuracy: 0.5733\n",
      "Epoch 17/80\n",
      "117/117 [==============================] - 111s 953ms/step - loss: 0.2654 - accuracy: 0.9099 - val_loss: 1.4651 - val_accuracy: 0.5636\n",
      "Epoch 18/80\n",
      "117/117 [==============================] - 111s 951ms/step - loss: 0.2321 - accuracy: 0.9233 - val_loss: 1.5649 - val_accuracy: 0.5529\n",
      "Epoch 19/80\n",
      "117/117 [==============================] - 112s 959ms/step - loss: 0.1726 - accuracy: 0.9463 - val_loss: 1.6576 - val_accuracy: 0.5690\n",
      "Epoch 20/80\n",
      "117/117 [==============================] - 112s 958ms/step - loss: 0.1611 - accuracy: 0.9433 - val_loss: 1.6305 - val_accuracy: 0.5455\n",
      "Epoch 21/80\n",
      "117/117 [==============================] - 112s 959ms/step - loss: 0.1556 - accuracy: 0.9511 - val_loss: 1.6759 - val_accuracy: 0.5690\n",
      "Epoch 22/80\n",
      "117/117 [==============================] - 112s 960ms/step - loss: 0.1358 - accuracy: 0.9548 - val_loss: 1.6791 - val_accuracy: 0.5733\n",
      "Epoch 23/80\n",
      "117/117 [==============================] - 112s 960ms/step - loss: 0.1108 - accuracy: 0.9650 - val_loss: 1.7285 - val_accuracy: 0.5765\n",
      "Epoch 24/80\n",
      "117/117 [==============================] - 112s 953ms/step - loss: 0.0955 - accuracy: 0.9695 - val_loss: 1.7855 - val_accuracy: 0.5540\n",
      "47/47 [==============================] - 9s 185ms/step - loss: 1.0865 - accuracy: 0.5911\n",
      "Building Localization Network with input shape: (None, 48, 48, 1)\n",
      "Building Bilinear Interpolation Layer with input shape: ((None, 48, 48, 1), (None, 2, 3))\n",
      "Epoch 1/80\n",
      "117/117 [==============================] - 120s 986ms/step - loss: 1.3747 - accuracy: 0.4436 - val_loss: 1.2679 - val_accuracy: 0.5123\n",
      "Epoch 2/80\n",
      "117/117 [==============================] - 114s 971ms/step - loss: 1.2052 - accuracy: 0.5160 - val_loss: 1.1951 - val_accuracy: 0.5561\n",
      "Epoch 3/80\n",
      "117/117 [==============================] - 112s 958ms/step - loss: 1.1146 - accuracy: 0.5615 - val_loss: 1.1443 - val_accuracy: 0.5615\n",
      "Epoch 4/80\n",
      "117/117 [==============================] - 111s 949ms/step - loss: 1.0387 - accuracy: 0.5911 - val_loss: 1.1044 - val_accuracy: 0.5786\n",
      "Epoch 5/80\n",
      "117/117 [==============================] - 112s 959ms/step - loss: 0.9857 - accuracy: 0.6098 - val_loss: 1.1089 - val_accuracy: 0.5583\n",
      "Epoch 6/80\n",
      "117/117 [==============================] - 111s 950ms/step - loss: 0.9150 - accuracy: 0.6403 - val_loss: 1.0963 - val_accuracy: 0.5765\n",
      "Epoch 7/80\n",
      "117/117 [==============================] - 111s 949ms/step - loss: 0.8555 - accuracy: 0.6668 - val_loss: 1.0822 - val_accuracy: 0.5797\n",
      "Epoch 8/80\n",
      "117/117 [==============================] - 112s 959ms/step - loss: 0.7889 - accuracy: 0.7066 - val_loss: 1.1048 - val_accuracy: 0.5840\n",
      "Epoch 9/80\n",
      "117/117 [==============================] - 113s 963ms/step - loss: 0.7282 - accuracy: 0.7213 - val_loss: 1.0851 - val_accuracy: 0.5775\n",
      "Epoch 10/80\n",
      "117/117 [==============================] - 117s 999ms/step - loss: 0.6658 - accuracy: 0.7386 - val_loss: 1.1867 - val_accuracy: 0.5615\n",
      "Epoch 11/80\n",
      "117/117 [==============================] - 185s 2s/step - loss: 0.5879 - accuracy: 0.7720 - val_loss: 1.1620 - val_accuracy: 0.5936\n",
      "Epoch 12/80\n",
      "117/117 [==============================] - 175s 1s/step - loss: 0.5412 - accuracy: 0.7956 - val_loss: 1.2445 - val_accuracy: 0.5743\n",
      "Epoch 13/80\n",
      "117/117 [==============================] - 185s 2s/step - loss: 0.4664 - accuracy: 0.8322 - val_loss: 1.2241 - val_accuracy: 0.5947\n",
      "Epoch 14/80\n",
      "117/117 [==============================] - 176s 2s/step - loss: 0.3730 - accuracy: 0.8640 - val_loss: 1.3839 - val_accuracy: 0.5690\n",
      "Epoch 15/80\n",
      "117/117 [==============================] - 180s 2s/step - loss: 0.3495 - accuracy: 0.8755 - val_loss: 1.2873 - val_accuracy: 0.5979\n",
      "Epoch 16/80\n",
      "117/117 [==============================] - 187s 2s/step - loss: 0.2940 - accuracy: 0.8995 - val_loss: 1.4110 - val_accuracy: 0.5722\n",
      "Epoch 17/80\n",
      "117/117 [==============================] - 176s 2s/step - loss: 0.2549 - accuracy: 0.9083 - val_loss: 1.4616 - val_accuracy: 0.5807\n",
      "Epoch 18/80\n",
      "117/117 [==============================] - 188s 2s/step - loss: 0.2122 - accuracy: 0.9297 - val_loss: 1.5176 - val_accuracy: 0.5807\n",
      "Epoch 19/80\n",
      "117/117 [==============================] - 149s 1s/step - loss: 0.1951 - accuracy: 0.9329 - val_loss: 1.5647 - val_accuracy: 0.5925\n",
      "Epoch 20/80\n",
      "117/117 [==============================] - 182s 2s/step - loss: 0.1900 - accuracy: 0.9364 - val_loss: 1.5839 - val_accuracy: 0.5754\n",
      "Epoch 21/80\n",
      "117/117 [==============================] - 178s 2s/step - loss: 0.1489 - accuracy: 0.9506 - val_loss: 1.6280 - val_accuracy: 0.5754\n",
      "Epoch 22/80\n",
      "117/117 [==============================] - 180s 2s/step - loss: 0.1092 - accuracy: 0.9703 - val_loss: 1.6790 - val_accuracy: 0.5840\n",
      "Epoch 23/80\n",
      "117/117 [==============================] - 183s 2s/step - loss: 0.0879 - accuracy: 0.9733 - val_loss: 1.7133 - val_accuracy: 0.5733\n",
      "Epoch 24/80\n",
      "117/117 [==============================] - 181s 2s/step - loss: 0.0955 - accuracy: 0.9733 - val_loss: 1.8720 - val_accuracy: 0.5540\n",
      "Epoch 25/80\n",
      "117/117 [==============================] - 182s 2s/step - loss: 0.0842 - accuracy: 0.9746 - val_loss: 1.7586 - val_accuracy: 0.5754\n",
      "Epoch 26/80\n",
      "117/117 [==============================] - 179s 2s/step - loss: 0.0725 - accuracy: 0.9781 - val_loss: 1.8969 - val_accuracy: 0.5497\n",
      "Epoch 27/80\n",
      "117/117 [==============================] - 190s 2s/step - loss: 0.0882 - accuracy: 0.9738 - val_loss: 1.8191 - val_accuracy: 0.5722\n",
      "Epoch 28/80\n",
      "117/117 [==============================] - 181s 2s/step - loss: 0.1175 - accuracy: 0.9551 - val_loss: 1.8738 - val_accuracy: 0.5519\n",
      "Epoch 29/80\n",
      "117/117 [==============================] - 182s 2s/step - loss: 0.1112 - accuracy: 0.9663 - val_loss: 1.7868 - val_accuracy: 0.5786\n",
      "Epoch 30/80\n",
      "117/117 [==============================] - 182s 2s/step - loss: 0.0683 - accuracy: 0.9818 - val_loss: 1.8954 - val_accuracy: 0.5893\n",
      "47/47 [==============================] - 16s 344ms/step - loss: 1.3155 - accuracy: 0.6019\n",
      "Building Localization Network with input shape: (None, 48, 48, 1)\n",
      "Building Bilinear Interpolation Layer with input shape: ((None, 48, 48, 1), (None, 2, 3))\n",
      "Epoch 1/80\n",
      "117/117 [==============================] - 192s 2s/step - loss: 1.4038 - accuracy: 0.4359 - val_loss: 1.2685 - val_accuracy: 0.4834\n",
      "Epoch 2/80\n",
      "117/117 [==============================] - 178s 2s/step - loss: 1.2365 - accuracy: 0.5123 - val_loss: 1.2174 - val_accuracy: 0.5048\n",
      "Epoch 3/80\n",
      "117/117 [==============================] - 178s 2s/step - loss: 1.1397 - accuracy: 0.5534 - val_loss: 1.1579 - val_accuracy: 0.5497\n",
      "Epoch 4/80\n",
      "117/117 [==============================] - 189s 2s/step - loss: 1.0627 - accuracy: 0.5858 - val_loss: 1.1280 - val_accuracy: 0.5551\n",
      "Epoch 5/80\n",
      "117/117 [==============================] - 188s 2s/step - loss: 1.0011 - accuracy: 0.6048 - val_loss: 1.1048 - val_accuracy: 0.5658\n",
      "Epoch 6/80\n",
      "117/117 [==============================] - 183s 2s/step - loss: 0.9553 - accuracy: 0.6312 - val_loss: 1.0759 - val_accuracy: 0.5765\n",
      "Epoch 7/80\n",
      "117/117 [==============================] - 182s 2s/step - loss: 0.8862 - accuracy: 0.6582 - val_loss: 1.0873 - val_accuracy: 0.5807\n",
      "Epoch 8/80\n",
      "117/117 [==============================] - 185s 2s/step - loss: 0.8278 - accuracy: 0.6807 - val_loss: 1.0935 - val_accuracy: 0.5711\n",
      "Epoch 9/80\n",
      "117/117 [==============================] - 182s 2s/step - loss: 0.7678 - accuracy: 0.7018 - val_loss: 1.0770 - val_accuracy: 0.5957\n",
      "Epoch 10/80\n",
      "117/117 [==============================] - 182s 2s/step - loss: 0.6851 - accuracy: 0.7314 - val_loss: 1.1228 - val_accuracy: 0.5829\n",
      "Epoch 11/80\n",
      "117/117 [==============================] - 182s 2s/step - loss: 0.6254 - accuracy: 0.7672 - val_loss: 1.1538 - val_accuracy: 0.5872\n",
      "Epoch 12/80\n",
      "117/117 [==============================] - 183s 2s/step - loss: 0.5716 - accuracy: 0.7830 - val_loss: 1.2050 - val_accuracy: 0.6000\n",
      "Epoch 13/80\n",
      "117/117 [==============================] - 183s 2s/step - loss: 0.4900 - accuracy: 0.8231 - val_loss: 1.2129 - val_accuracy: 0.6064\n",
      "Epoch 14/80\n",
      "117/117 [==============================] - 181s 2s/step - loss: 0.4361 - accuracy: 0.8399 - val_loss: 1.2849 - val_accuracy: 0.5904\n",
      "Epoch 15/80\n",
      "117/117 [==============================] - 180s 2s/step - loss: 0.3816 - accuracy: 0.8613 - val_loss: 1.3857 - val_accuracy: 0.5636\n",
      "Epoch 16/80\n",
      "117/117 [==============================] - 183s 2s/step - loss: 0.3236 - accuracy: 0.8813 - val_loss: 1.3579 - val_accuracy: 0.5679\n",
      "Epoch 17/80\n",
      "117/117 [==============================] - 184s 2s/step - loss: 0.2662 - accuracy: 0.9086 - val_loss: 1.4415 - val_accuracy: 0.5807\n",
      "Epoch 18/80\n",
      "117/117 [==============================] - 182s 2s/step - loss: 0.2388 - accuracy: 0.9201 - val_loss: 1.4193 - val_accuracy: 0.5775\n",
      "Epoch 19/80\n",
      "117/117 [==============================] - 187s 2s/step - loss: 0.2005 - accuracy: 0.9361 - val_loss: 1.5358 - val_accuracy: 0.5914\n",
      "Epoch 20/80\n",
      "117/117 [==============================] - 187s 2s/step - loss: 0.1593 - accuracy: 0.9490 - val_loss: 1.6103 - val_accuracy: 0.5775\n",
      "Epoch 21/80\n",
      "117/117 [==============================] - 184s 2s/step - loss: 0.1548 - accuracy: 0.9479 - val_loss: 1.5958 - val_accuracy: 0.5733\n",
      "Epoch 22/80\n",
      "117/117 [==============================] - 183s 2s/step - loss: 0.1363 - accuracy: 0.9559 - val_loss: 1.6525 - val_accuracy: 0.5818\n",
      "Epoch 23/80\n",
      "117/117 [==============================] - 183s 2s/step - loss: 0.1062 - accuracy: 0.9733 - val_loss: 1.6955 - val_accuracy: 0.5861\n",
      "Epoch 24/80\n",
      "117/117 [==============================] - 184s 2s/step - loss: 0.1126 - accuracy: 0.9653 - val_loss: 1.8319 - val_accuracy: 0.5615\n",
      "Epoch 25/80\n",
      "117/117 [==============================] - 184s 2s/step - loss: 0.1157 - accuracy: 0.9634 - val_loss: 1.7875 - val_accuracy: 0.5604\n",
      "Epoch 26/80\n",
      "117/117 [==============================] - 183s 2s/step - loss: 0.1319 - accuracy: 0.9570 - val_loss: 1.7395 - val_accuracy: 0.5775\n",
      "Epoch 27/80\n",
      "117/117 [==============================] - 182s 2s/step - loss: 0.0841 - accuracy: 0.9727 - val_loss: 1.8508 - val_accuracy: 0.5807\n",
      "Epoch 28/80\n",
      "117/117 [==============================] - 182s 2s/step - loss: 0.0672 - accuracy: 0.9818 - val_loss: 1.8461 - val_accuracy: 0.5701\n",
      "47/47 [==============================] - 16s 335ms/step - loss: 1.2570 - accuracy: 0.5844\n"
     ]
    }
   ],
   "source": [
    "VALIDATION_ACCURACY = []\n",
    "VALIDATION_LOSS = []\n",
    "\n",
    "save_dir = os.path.abspath(DIR)+'/cremad_60m40f_video_model/'\n",
    "fold_var = 1\n",
    "\n",
    "for train_idx, val_idx in kfold.split(X_train_60m_40f, y_train_60m_40f):\n",
    "  # with tpu_strategy.scope():\n",
    "  model=create__LRCN_with_STN() \n",
    "  model.compile(loss='sparse_categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
    "  early_stopping_callback = EarlyStopping(monitor = 'val_accuracy', patience = 15, restore_best_weights = True)\n",
    "  checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(save_dir+get_model_name(fold_var), \n",
    "        monitor='val_accuracy', \n",
    "        save_best_only=True, mode='max')\n",
    "\n",
    "  LRCN_model_training_history = model.fit(        x = X_train_60m_40f[train_idx],\n",
    "                                                  y = y_train_60m_40f[train_idx],\n",
    "                                                  validation_data=(X_train_60m_40f[val_idx],y_train_60m_40f[val_idx]),\n",
    "                                                  epochs = 80,\n",
    "                                                  batch_size = 32,\n",
    "                                                  shuffle = True,\n",
    "                                                  callbacks = [checkpoint_cb,early_stopping_callback])\n",
    "\n",
    "  model.load_weights(save_dir+\"model_\"+str(fold_var)+\".h5\")\n",
    "\t\n",
    "  results = model.evaluate(X_test, y_test)\n",
    "  results = dict(zip(model.metrics_names,results))\n",
    "\t\n",
    "  VALIDATION_ACCURACY.append(results['accuracy'])\n",
    "  VALIDATION_LOSS.append(results['loss'])\n",
    "\t\n",
    "  tf.keras.backend.clear_session()\n",
    "\t\n",
    "  fold_var += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38d20c9c-b2bc-4abc-a805-443085fe08fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Localization Network with input shape: (None, 48, 48, 1)\n",
      "Building Bilinear Interpolation Layer with input shape: ((None, 48, 48, 1), (None, 2, 3))\n",
      "Epoch 1/80\n",
      "117/117 [==============================] - 93s 759ms/step - loss: 1.3641 - accuracy: 0.4487 - val_loss: 1.2290 - val_accuracy: 0.5139\n",
      "Epoch 2/80\n",
      "117/117 [==============================] - 90s 769ms/step - loss: 1.1944 - accuracy: 0.5323 - val_loss: 1.1768 - val_accuracy: 0.5502\n",
      "Epoch 3/80\n",
      "117/117 [==============================] - 89s 765ms/step - loss: 1.0862 - accuracy: 0.5730 - val_loss: 1.1709 - val_accuracy: 0.5310\n",
      "Epoch 4/80\n",
      "117/117 [==============================] - 89s 762ms/step - loss: 1.0194 - accuracy: 0.6021 - val_loss: 1.1992 - val_accuracy: 0.5246\n",
      "Epoch 5/80\n",
      "117/117 [==============================] - 89s 764ms/step - loss: 0.9552 - accuracy: 0.6264 - val_loss: 1.1141 - val_accuracy: 0.5759\n",
      "Epoch 6/80\n",
      "117/117 [==============================] - 89s 759ms/step - loss: 0.8887 - accuracy: 0.6574 - val_loss: 1.1157 - val_accuracy: 0.5684\n",
      "Epoch 7/80\n",
      "117/117 [==============================] - 92s 785ms/step - loss: 0.8468 - accuracy: 0.6708 - val_loss: 1.1069 - val_accuracy: 0.5823\n",
      "Epoch 8/80\n",
      "117/117 [==============================] - 89s 757ms/step - loss: 0.7698 - accuracy: 0.7020 - val_loss: 1.1411 - val_accuracy: 0.5962\n",
      "Epoch 9/80\n",
      "117/117 [==============================] - 88s 754ms/step - loss: 0.7019 - accuracy: 0.7288 - val_loss: 1.1825 - val_accuracy: 0.5855\n",
      "Epoch 10/80\n",
      "117/117 [==============================] - 87s 748ms/step - loss: 0.6366 - accuracy: 0.7595 - val_loss: 1.2053 - val_accuracy: 0.5791\n",
      "Epoch 11/80\n",
      "117/117 [==============================] - 90s 772ms/step - loss: 0.6002 - accuracy: 0.7699 - val_loss: 1.2654 - val_accuracy: 0.5684\n",
      "Epoch 12/80\n",
      "117/117 [==============================] - 90s 770ms/step - loss: 0.5040 - accuracy: 0.8092 - val_loss: 1.2598 - val_accuracy: 0.5865\n",
      "Epoch 13/80\n",
      "117/117 [==============================] - 91s 775ms/step - loss: 0.4443 - accuracy: 0.8354 - val_loss: 1.2519 - val_accuracy: 0.5972\n",
      "Epoch 14/80\n",
      "117/117 [==============================] - 90s 770ms/step - loss: 0.3663 - accuracy: 0.8704 - val_loss: 1.3824 - val_accuracy: 0.5897\n",
      "Epoch 15/80\n",
      "117/117 [==============================] - 90s 768ms/step - loss: 0.3458 - accuracy: 0.8747 - val_loss: 1.4054 - val_accuracy: 0.5833\n",
      "Epoch 16/80\n",
      "117/117 [==============================] - 90s 768ms/step - loss: 0.2888 - accuracy: 0.9006 - val_loss: 1.4439 - val_accuracy: 0.6015\n",
      "Epoch 17/80\n",
      "117/117 [==============================] - 89s 763ms/step - loss: 0.2496 - accuracy: 0.9110 - val_loss: 1.5502 - val_accuracy: 0.5737\n",
      "Epoch 18/80\n",
      "117/117 [==============================] - 91s 775ms/step - loss: 0.2118 - accuracy: 0.9246 - val_loss: 1.5647 - val_accuracy: 0.5908\n",
      "Epoch 19/80\n",
      "117/117 [==============================] - 91s 774ms/step - loss: 0.1891 - accuracy: 0.9348 - val_loss: 1.6065 - val_accuracy: 0.5748\n",
      "Epoch 20/80\n",
      "117/117 [==============================] - 90s 770ms/step - loss: 0.1612 - accuracy: 0.9452 - val_loss: 1.6889 - val_accuracy: 0.5897\n",
      "Epoch 21/80\n",
      "117/117 [==============================] - 90s 771ms/step - loss: 0.1500 - accuracy: 0.9495 - val_loss: 1.7488 - val_accuracy: 0.5694\n",
      "Epoch 22/80\n",
      "117/117 [==============================] - 91s 781ms/step - loss: 0.1140 - accuracy: 0.9655 - val_loss: 1.7530 - val_accuracy: 0.5833\n",
      "Epoch 23/80\n",
      "117/117 [==============================] - 91s 779ms/step - loss: 0.1110 - accuracy: 0.9634 - val_loss: 1.8181 - val_accuracy: 0.5620\n",
      "Epoch 24/80\n",
      "117/117 [==============================] - 91s 782ms/step - loss: 0.1263 - accuracy: 0.9567 - val_loss: 1.8392 - val_accuracy: 0.5823\n",
      "Epoch 25/80\n",
      "117/117 [==============================] - 92s 786ms/step - loss: 0.0803 - accuracy: 0.9765 - val_loss: 1.8954 - val_accuracy: 0.5855\n",
      "Epoch 26/80\n",
      "117/117 [==============================] - 89s 764ms/step - loss: 0.0505 - accuracy: 0.9882 - val_loss: 1.9745 - val_accuracy: 0.5919\n",
      "Epoch 27/80\n",
      "117/117 [==============================] - 90s 767ms/step - loss: 0.0668 - accuracy: 0.9797 - val_loss: 1.9082 - val_accuracy: 0.5876\n",
      "Epoch 28/80\n",
      "117/117 [==============================] - 91s 779ms/step - loss: 0.0966 - accuracy: 0.9679 - val_loss: 1.9695 - val_accuracy: 0.5844\n",
      "Epoch 29/80\n",
      "117/117 [==============================] - 91s 776ms/step - loss: 0.0953 - accuracy: 0.9690 - val_loss: 1.9464 - val_accuracy: 0.5865\n",
      "Epoch 30/80\n",
      "117/117 [==============================] - 90s 766ms/step - loss: 0.0952 - accuracy: 0.9727 - val_loss: 1.9911 - val_accuracy: 0.5705\n",
      "Epoch 31/80\n",
      "117/117 [==============================] - 91s 781ms/step - loss: 0.0573 - accuracy: 0.9853 - val_loss: 2.0391 - val_accuracy: 0.6004\n",
      "47/47 [==============================] - 7s 152ms/step - loss: 1.4299 - accuracy: 0.5958\n",
      "Building Localization Network with input shape: (None, 48, 48, 1)\n",
      "Building Bilinear Interpolation Layer with input shape: ((None, 48, 48, 1), (None, 2, 3))\n",
      "Epoch 1/80\n",
      "117/117 [==============================] - 87s 707ms/step - loss: 1.3611 - accuracy: 0.4535 - val_loss: 1.2382 - val_accuracy: 0.5085\n",
      "Epoch 2/80\n",
      "117/117 [==============================] - 81s 695ms/step - loss: 1.2029 - accuracy: 0.5270 - val_loss: 1.1558 - val_accuracy: 0.5481\n",
      "Epoch 3/80\n",
      "117/117 [==============================] - 81s 693ms/step - loss: 1.1230 - accuracy: 0.5524 - val_loss: 1.1332 - val_accuracy: 0.5641\n",
      "Epoch 4/80\n",
      "117/117 [==============================] - 81s 693ms/step - loss: 1.0479 - accuracy: 0.5909 - val_loss: 1.0913 - val_accuracy: 0.5620\n",
      "Epoch 5/80\n",
      "117/117 [==============================] - 81s 690ms/step - loss: 0.9868 - accuracy: 0.6130 - val_loss: 1.0712 - val_accuracy: 0.5897\n",
      "Epoch 6/80\n",
      "117/117 [==============================] - 81s 691ms/step - loss: 0.9257 - accuracy: 0.6440 - val_loss: 1.0844 - val_accuracy: 0.6015\n",
      "Epoch 7/80\n",
      "117/117 [==============================] - 80s 688ms/step - loss: 0.8608 - accuracy: 0.6676 - val_loss: 1.0769 - val_accuracy: 0.5705\n",
      "Epoch 8/80\n",
      "117/117 [==============================] - 80s 688ms/step - loss: 0.7963 - accuracy: 0.6980 - val_loss: 1.0671 - val_accuracy: 0.5865\n",
      "Epoch 9/80\n",
      "117/117 [==============================] - 81s 690ms/step - loss: 0.7263 - accuracy: 0.7231 - val_loss: 1.0878 - val_accuracy: 0.5876\n",
      "Epoch 10/80\n",
      "117/117 [==============================] - 80s 686ms/step - loss: 0.6585 - accuracy: 0.7501 - val_loss: 1.1277 - val_accuracy: 0.5887\n",
      "Epoch 11/80\n",
      "117/117 [==============================] - 81s 690ms/step - loss: 0.5868 - accuracy: 0.7782 - val_loss: 1.1308 - val_accuracy: 0.6143\n",
      "Epoch 12/80\n",
      "117/117 [==============================] - 80s 685ms/step - loss: 0.5141 - accuracy: 0.8164 - val_loss: 1.1226 - val_accuracy: 0.6004\n",
      "Epoch 13/80\n",
      "117/117 [==============================] - 80s 686ms/step - loss: 0.4560 - accuracy: 0.8348 - val_loss: 1.1928 - val_accuracy: 0.6026\n",
      "Epoch 14/80\n",
      "117/117 [==============================] - 80s 685ms/step - loss: 0.3985 - accuracy: 0.8522 - val_loss: 1.2953 - val_accuracy: 0.5844\n",
      "Epoch 15/80\n",
      "117/117 [==============================] - 81s 689ms/step - loss: 0.3273 - accuracy: 0.8848 - val_loss: 1.2997 - val_accuracy: 0.5908\n",
      "Epoch 16/80\n",
      "117/117 [==============================] - 81s 691ms/step - loss: 0.2702 - accuracy: 0.9059 - val_loss: 1.4203 - val_accuracy: 0.5780\n",
      "Epoch 17/80\n",
      "117/117 [==============================] - 81s 697ms/step - loss: 0.2325 - accuracy: 0.9212 - val_loss: 1.4322 - val_accuracy: 0.5876\n",
      "Epoch 18/80\n",
      "117/117 [==============================] - 82s 704ms/step - loss: 0.1954 - accuracy: 0.9377 - val_loss: 1.4700 - val_accuracy: 0.6047\n",
      "Epoch 19/80\n",
      "117/117 [==============================] - 83s 714ms/step - loss: 0.1800 - accuracy: 0.9393 - val_loss: 1.4573 - val_accuracy: 0.6004\n",
      "Epoch 20/80\n",
      "117/117 [==============================] - 84s 719ms/step - loss: 0.1567 - accuracy: 0.9508 - val_loss: 1.5496 - val_accuracy: 0.5844\n",
      "Epoch 21/80\n",
      "117/117 [==============================] - 85s 727ms/step - loss: 0.1432 - accuracy: 0.9548 - val_loss: 1.5627 - val_accuracy: 0.5812\n",
      "Epoch 22/80\n",
      "117/117 [==============================] - 88s 756ms/step - loss: 0.1171 - accuracy: 0.9669 - val_loss: 1.5991 - val_accuracy: 0.6090\n",
      "Epoch 23/80\n",
      "117/117 [==============================] - 88s 753ms/step - loss: 0.0896 - accuracy: 0.9746 - val_loss: 1.7001 - val_accuracy: 0.5972\n",
      "Epoch 24/80\n",
      "117/117 [==============================] - 87s 742ms/step - loss: 0.0848 - accuracy: 0.9759 - val_loss: 1.7185 - val_accuracy: 0.6047\n",
      "Epoch 25/80\n",
      "117/117 [==============================] - 88s 750ms/step - loss: 0.1192 - accuracy: 0.9613 - val_loss: 1.6213 - val_accuracy: 0.5908\n",
      "Epoch 26/80\n",
      "117/117 [==============================] - 85s 729ms/step - loss: 0.0812 - accuracy: 0.9781 - val_loss: 1.7748 - val_accuracy: 0.5865\n",
      "47/47 [==============================] - 7s 150ms/step - loss: 1.1978 - accuracy: 0.5783\n",
      "Building Localization Network with input shape: (None, 48, 48, 1)\n",
      "Building Bilinear Interpolation Layer with input shape: ((None, 48, 48, 1), (None, 2, 3))\n",
      "Epoch 1/80\n",
      "117/117 [==============================] - 86s 701ms/step - loss: 1.3489 - accuracy: 0.4572 - val_loss: 1.2981 - val_accuracy: 0.4957\n",
      "Epoch 2/80\n",
      "117/117 [==============================] - 80s 686ms/step - loss: 1.1891 - accuracy: 0.5259 - val_loss: 1.1806 - val_accuracy: 0.5491\n",
      "Epoch 3/80\n",
      "117/117 [==============================] - 80s 685ms/step - loss: 1.0850 - accuracy: 0.5719 - val_loss: 1.2803 - val_accuracy: 0.5053\n",
      "Epoch 4/80\n",
      "117/117 [==============================] - 80s 683ms/step - loss: 1.0301 - accuracy: 0.5989 - val_loss: 1.1514 - val_accuracy: 0.5427\n",
      "Epoch 5/80\n",
      "117/117 [==============================] - 80s 685ms/step - loss: 0.9663 - accuracy: 0.6168 - val_loss: 1.0970 - val_accuracy: 0.5737\n",
      "Epoch 6/80\n",
      "117/117 [==============================] - 80s 684ms/step - loss: 0.9143 - accuracy: 0.6414 - val_loss: 1.1267 - val_accuracy: 0.5588\n",
      "Epoch 7/80\n",
      "117/117 [==============================] - 80s 682ms/step - loss: 0.8646 - accuracy: 0.6585 - val_loss: 1.1096 - val_accuracy: 0.5705\n",
      "Epoch 8/80\n",
      "117/117 [==============================] - 80s 687ms/step - loss: 0.7936 - accuracy: 0.6956 - val_loss: 1.0798 - val_accuracy: 0.5908\n",
      "Epoch 9/80\n",
      "117/117 [==============================] - 80s 683ms/step - loss: 0.7262 - accuracy: 0.7250 - val_loss: 1.0999 - val_accuracy: 0.5780\n",
      "Epoch 10/80\n",
      "117/117 [==============================] - 80s 681ms/step - loss: 0.6687 - accuracy: 0.7381 - val_loss: 1.1490 - val_accuracy: 0.5759\n",
      "Epoch 11/80\n",
      "117/117 [==============================] - 80s 685ms/step - loss: 0.5941 - accuracy: 0.7742 - val_loss: 1.1674 - val_accuracy: 0.5812\n",
      "Epoch 12/80\n",
      "117/117 [==============================] - 80s 684ms/step - loss: 0.5347 - accuracy: 0.7996 - val_loss: 1.2202 - val_accuracy: 0.5620\n",
      "Epoch 13/80\n",
      "117/117 [==============================] - 80s 682ms/step - loss: 0.4798 - accuracy: 0.8188 - val_loss: 1.2513 - val_accuracy: 0.5694\n",
      "Epoch 14/80\n",
      "117/117 [==============================] - 80s 684ms/step - loss: 0.4046 - accuracy: 0.8536 - val_loss: 1.3165 - val_accuracy: 0.5748\n",
      "Epoch 15/80\n",
      "117/117 [==============================] - 80s 683ms/step - loss: 0.3455 - accuracy: 0.8835 - val_loss: 1.3362 - val_accuracy: 0.5769\n",
      "Epoch 16/80\n",
      "117/117 [==============================] - 80s 681ms/step - loss: 0.2901 - accuracy: 0.8974 - val_loss: 1.3712 - val_accuracy: 0.5812\n",
      "Epoch 17/80\n",
      "117/117 [==============================] - 80s 684ms/step - loss: 0.2571 - accuracy: 0.9134 - val_loss: 1.4579 - val_accuracy: 0.5726\n",
      "Epoch 18/80\n",
      "117/117 [==============================] - 80s 685ms/step - loss: 0.2146 - accuracy: 0.9292 - val_loss: 1.4687 - val_accuracy: 0.5801\n",
      "Epoch 19/80\n",
      "117/117 [==============================] - 80s 685ms/step - loss: 0.1869 - accuracy: 0.9348 - val_loss: 1.5077 - val_accuracy: 0.5769\n",
      "Epoch 20/80\n",
      "117/117 [==============================] - 80s 681ms/step - loss: 0.1536 - accuracy: 0.9508 - val_loss: 1.6232 - val_accuracy: 0.5748\n",
      "Epoch 21/80\n",
      "117/117 [==============================] - 80s 682ms/step - loss: 0.1322 - accuracy: 0.9588 - val_loss: 1.6737 - val_accuracy: 0.5780\n",
      "Epoch 22/80\n",
      "117/117 [==============================] - 82s 698ms/step - loss: 0.1378 - accuracy: 0.9543 - val_loss: 1.7533 - val_accuracy: 0.5801\n",
      "Epoch 23/80\n",
      "117/117 [==============================] - 80s 686ms/step - loss: 0.1112 - accuracy: 0.9666 - val_loss: 1.7509 - val_accuracy: 0.5556\n",
      "47/47 [==============================] - 7s 149ms/step - loss: 1.0544 - accuracy: 0.5965\n",
      "Building Localization Network with input shape: (None, 48, 48, 1)\n",
      "Building Bilinear Interpolation Layer with input shape: ((None, 48, 48, 1), (None, 2, 3))\n",
      "Epoch 1/80\n",
      "117/117 [==============================] - 88s 715ms/step - loss: 1.3699 - accuracy: 0.4496 - val_loss: 1.2341 - val_accuracy: 0.5070\n",
      "Epoch 2/80\n",
      "117/117 [==============================] - 87s 741ms/step - loss: 1.1945 - accuracy: 0.5293 - val_loss: 1.1737 - val_accuracy: 0.5283\n",
      "Epoch 3/80\n",
      "117/117 [==============================] - 108s 923ms/step - loss: 1.1123 - accuracy: 0.5629 - val_loss: 1.1048 - val_accuracy: 0.5540\n",
      "Epoch 4/80\n",
      "117/117 [==============================] - 117s 1000ms/step - loss: 1.0560 - accuracy: 0.5931 - val_loss: 1.0907 - val_accuracy: 0.5701\n",
      "Epoch 5/80\n",
      "117/117 [==============================] - 108s 921ms/step - loss: 0.9707 - accuracy: 0.6294 - val_loss: 1.0598 - val_accuracy: 0.5829\n",
      "Epoch 6/80\n",
      "117/117 [==============================] - 109s 929ms/step - loss: 0.9218 - accuracy: 0.6407 - val_loss: 1.0537 - val_accuracy: 0.5989\n",
      "Epoch 7/80\n",
      "117/117 [==============================] - 148s 1s/step - loss: 0.8643 - accuracy: 0.6735 - val_loss: 1.0504 - val_accuracy: 0.5979\n",
      "Epoch 8/80\n",
      "117/117 [==============================] - 147s 1s/step - loss: 0.8008 - accuracy: 0.6938 - val_loss: 1.0472 - val_accuracy: 0.5904\n",
      "Epoch 9/80\n",
      "117/117 [==============================] - 118s 1s/step - loss: 0.7422 - accuracy: 0.7131 - val_loss: 1.0947 - val_accuracy: 0.5840\n",
      "Epoch 10/80\n",
      "117/117 [==============================] - 135s 1s/step - loss: 0.6748 - accuracy: 0.7457 - val_loss: 1.0382 - val_accuracy: 0.5957\n",
      "Epoch 11/80\n",
      "117/117 [==============================] - 154s 1s/step - loss: 0.6360 - accuracy: 0.7625 - val_loss: 1.1035 - val_accuracy: 0.6032\n",
      "Epoch 12/80\n",
      "117/117 [==============================] - 155s 1s/step - loss: 0.5489 - accuracy: 0.7970 - val_loss: 1.1151 - val_accuracy: 0.5968\n",
      "Epoch 13/80\n",
      "117/117 [==============================] - 152s 1s/step - loss: 0.4797 - accuracy: 0.8215 - val_loss: 1.0906 - val_accuracy: 0.6128\n",
      "Epoch 14/80\n",
      "117/117 [==============================] - 124s 1s/step - loss: 0.4028 - accuracy: 0.8579 - val_loss: 1.1573 - val_accuracy: 0.6075\n",
      "Epoch 15/80\n",
      "117/117 [==============================] - 156s 1s/step - loss: 0.3341 - accuracy: 0.8830 - val_loss: 1.1976 - val_accuracy: 0.6032\n",
      "Epoch 16/80\n",
      "117/117 [==============================] - 153s 1s/step - loss: 0.2845 - accuracy: 0.9036 - val_loss: 1.2559 - val_accuracy: 0.6064\n",
      "Epoch 17/80\n",
      "117/117 [==============================] - 153s 1s/step - loss: 0.2629 - accuracy: 0.9049 - val_loss: 1.3014 - val_accuracy: 0.5861\n",
      "Epoch 18/80\n",
      "117/117 [==============================] - 150s 1s/step - loss: 0.2168 - accuracy: 0.9289 - val_loss: 1.3367 - val_accuracy: 0.6032\n",
      "Epoch 19/80\n",
      "117/117 [==============================] - 153s 1s/step - loss: 0.1782 - accuracy: 0.9372 - val_loss: 1.3887 - val_accuracy: 0.5936\n",
      "Epoch 20/80\n",
      "117/117 [==============================] - 151s 1s/step - loss: 0.1513 - accuracy: 0.9551 - val_loss: 1.4895 - val_accuracy: 0.5797\n",
      "Epoch 21/80\n",
      "117/117 [==============================] - 152s 1s/step - loss: 0.1558 - accuracy: 0.9487 - val_loss: 1.5201 - val_accuracy: 0.5947\n",
      "Epoch 22/80\n",
      "117/117 [==============================] - 151s 1s/step - loss: 0.1059 - accuracy: 0.9730 - val_loss: 1.5568 - val_accuracy: 0.5861\n",
      "Epoch 23/80\n",
      "117/117 [==============================] - 153s 1s/step - loss: 0.1056 - accuracy: 0.9661 - val_loss: 1.4412 - val_accuracy: 0.5979\n",
      "Epoch 24/80\n",
      "117/117 [==============================] - 138s 1s/step - loss: 0.0828 - accuracy: 0.9773 - val_loss: 1.5780 - val_accuracy: 0.5957\n",
      "Epoch 25/80\n",
      "117/117 [==============================] - 111s 952ms/step - loss: 0.0872 - accuracy: 0.9733 - val_loss: 1.6949 - val_accuracy: 0.5904\n",
      "Epoch 26/80\n",
      "117/117 [==============================] - 109s 935ms/step - loss: 0.0957 - accuracy: 0.9698 - val_loss: 1.6270 - val_accuracy: 0.6011\n",
      "Epoch 27/80\n",
      "117/117 [==============================] - 177s 2s/step - loss: 0.1001 - accuracy: 0.9698 - val_loss: 1.6349 - val_accuracy: 0.6032\n",
      "Epoch 28/80\n",
      "117/117 [==============================] - 196s 2s/step - loss: 0.0558 - accuracy: 0.9856 - val_loss: 1.7332 - val_accuracy: 0.6011\n",
      "47/47 [==============================] - 17s 366ms/step - loss: 1.1900 - accuracy: 0.5797\n",
      "Building Localization Network with input shape: (None, 48, 48, 1)\n",
      "Building Bilinear Interpolation Layer with input shape: ((None, 48, 48, 1), (None, 2, 3))\n",
      "Epoch 1/80\n",
      "117/117 [==============================] - 185s 2s/step - loss: 1.3621 - accuracy: 0.4462 - val_loss: 1.2294 - val_accuracy: 0.5241\n",
      "Epoch 2/80\n",
      "117/117 [==============================] - 192s 2s/step - loss: 1.2028 - accuracy: 0.5266 - val_loss: 1.1991 - val_accuracy: 0.5337\n",
      "Epoch 3/80\n",
      "117/117 [==============================] - 173s 1s/step - loss: 1.1074 - accuracy: 0.5656 - val_loss: 1.1349 - val_accuracy: 0.5508\n",
      "Epoch 4/80\n",
      "117/117 [==============================] - 186s 2s/step - loss: 1.0420 - accuracy: 0.6017 - val_loss: 1.1431 - val_accuracy: 0.5487\n",
      "Epoch 5/80\n",
      "117/117 [==============================] - 185s 2s/step - loss: 0.9839 - accuracy: 0.6204 - val_loss: 1.1141 - val_accuracy: 0.5701\n",
      "Epoch 6/80\n",
      "117/117 [==============================] - 179s 2s/step - loss: 0.9120 - accuracy: 0.6516 - val_loss: 1.0610 - val_accuracy: 0.5658\n",
      "Epoch 7/80\n",
      "117/117 [==============================] - 197s 2s/step - loss: 0.8638 - accuracy: 0.6762 - val_loss: 1.1054 - val_accuracy: 0.5882\n",
      "Epoch 8/80\n",
      "117/117 [==============================] - 120s 1s/step - loss: 0.7946 - accuracy: 0.6986 - val_loss: 1.1100 - val_accuracy: 0.5893\n",
      "Epoch 9/80\n",
      "117/117 [==============================] - 95s 813ms/step - loss: 0.7416 - accuracy: 0.7187 - val_loss: 1.0930 - val_accuracy: 0.5829\n",
      "Epoch 10/80\n",
      "117/117 [==============================] - 97s 829ms/step - loss: 0.6677 - accuracy: 0.7539 - val_loss: 1.1293 - val_accuracy: 0.5872\n",
      "Epoch 11/80\n",
      "117/117 [==============================] - 93s 800ms/step - loss: 0.6176 - accuracy: 0.7673 - val_loss: 1.1603 - val_accuracy: 0.5914\n",
      "Epoch 12/80\n",
      "117/117 [==============================] - 93s 795ms/step - loss: 0.5357 - accuracy: 0.8055 - val_loss: 1.2984 - val_accuracy: 0.5594\n",
      "Epoch 13/80\n",
      "117/117 [==============================] - 92s 789ms/step - loss: 0.4784 - accuracy: 0.8258 - val_loss: 1.2323 - val_accuracy: 0.5936\n",
      "Epoch 14/80\n",
      "117/117 [==============================] - 97s 829ms/step - loss: 0.3844 - accuracy: 0.8675 - val_loss: 1.2845 - val_accuracy: 0.5733\n",
      "Epoch 15/80\n",
      "117/117 [==============================] - 100s 845ms/step - loss: 0.3337 - accuracy: 0.8865 - val_loss: 1.2963 - val_accuracy: 0.5861\n",
      "Epoch 16/80\n",
      "117/117 [==============================] - 143s 1s/step - loss: 0.2687 - accuracy: 0.9092 - val_loss: 1.3551 - val_accuracy: 0.5904\n",
      "Epoch 17/80\n",
      "117/117 [==============================] - 163s 1s/step - loss: 0.2367 - accuracy: 0.9201 - val_loss: 1.4176 - val_accuracy: 0.5786\n",
      "Epoch 18/80\n",
      "117/117 [==============================] - 144s 1s/step - loss: 0.1960 - accuracy: 0.9383 - val_loss: 1.4583 - val_accuracy: 0.5957\n",
      "Epoch 19/80\n",
      "117/117 [==============================] - 163s 1s/step - loss: 0.1855 - accuracy: 0.9383 - val_loss: 1.5279 - val_accuracy: 0.6032\n",
      "Epoch 20/80\n",
      "117/117 [==============================] - 147s 1s/step - loss: 0.1352 - accuracy: 0.9599 - val_loss: 1.6704 - val_accuracy: 0.5840\n",
      "Epoch 21/80\n",
      "117/117 [==============================] - 150s 1s/step - loss: 0.1530 - accuracy: 0.9468 - val_loss: 1.6070 - val_accuracy: 0.5850\n",
      "Epoch 22/80\n",
      "117/117 [==============================] - 148s 1s/step - loss: 0.1144 - accuracy: 0.9687 - val_loss: 1.7643 - val_accuracy: 0.5861\n",
      "Epoch 23/80\n",
      "117/117 [==============================] - 155s 1s/step - loss: 0.0963 - accuracy: 0.9733 - val_loss: 1.7523 - val_accuracy: 0.5861\n",
      "Epoch 24/80\n",
      "117/117 [==============================] - 152s 1s/step - loss: 0.0729 - accuracy: 0.9821 - val_loss: 1.8357 - val_accuracy: 0.5968\n",
      "Epoch 25/80\n",
      "117/117 [==============================] - 153s 1s/step - loss: 0.0780 - accuracy: 0.9778 - val_loss: 1.7950 - val_accuracy: 0.5850\n",
      "Epoch 26/80\n",
      "117/117 [==============================] - 154s 1s/step - loss: 0.0848 - accuracy: 0.9725 - val_loss: 1.8367 - val_accuracy: 0.5818\n",
      "Epoch 27/80\n",
      "117/117 [==============================] - 155s 1s/step - loss: 0.1051 - accuracy: 0.9677 - val_loss: 1.8446 - val_accuracy: 0.5807\n",
      "Epoch 28/80\n",
      "117/117 [==============================] - 154s 1s/step - loss: 0.0840 - accuracy: 0.9749 - val_loss: 1.8837 - val_accuracy: 0.5893\n",
      "Epoch 29/80\n",
      "117/117 [==============================] - 158s 1s/step - loss: 0.0656 - accuracy: 0.9824 - val_loss: 1.8797 - val_accuracy: 0.5914\n",
      "Epoch 30/80\n",
      "117/117 [==============================] - 158s 1s/step - loss: 0.0559 - accuracy: 0.9842 - val_loss: 1.8832 - val_accuracy: 0.5925\n",
      "Epoch 31/80\n",
      "117/117 [==============================] - 158s 1s/step - loss: 0.0539 - accuracy: 0.9840 - val_loss: 1.9655 - val_accuracy: 0.5989\n",
      "Epoch 32/80\n",
      "117/117 [==============================] - 159s 1s/step - loss: 0.0322 - accuracy: 0.9933 - val_loss: 2.0122 - val_accuracy: 0.5850\n",
      "Epoch 33/80\n",
      "117/117 [==============================] - 162s 1s/step - loss: 0.0474 - accuracy: 0.9861 - val_loss: 2.0709 - val_accuracy: 0.5882\n",
      "Epoch 34/80\n",
      "117/117 [==============================] - 159s 1s/step - loss: 0.0702 - accuracy: 0.9781 - val_loss: 2.1583 - val_accuracy: 0.5647\n",
      "47/47 [==============================] - 14s 293ms/step - loss: 1.5142 - accuracy: 0.5750\n"
     ]
    }
   ],
   "source": [
    "VALIDATION_ACCURACY = []\n",
    "VALIDATION_LOSS = []\n",
    "\n",
    "save_dir = os.path.abspath(DIR)+'/cremad_40m60f_video_model/'\n",
    "fold_var = 1\n",
    "\n",
    "for train_idx, val_idx in kfold.split(X_train_40m_60f, y_train_40m_60f):\n",
    "  # with tpu_strategy.scope():\n",
    "  model=create__LRCN_with_STN() \n",
    "  model.compile(loss='sparse_categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
    "  early_stopping_callback = EarlyStopping(monitor = 'val_accuracy', patience = 15, restore_best_weights = True)\n",
    "  checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(save_dir+get_model_name(fold_var), \n",
    "        monitor='val_accuracy', \n",
    "        save_best_only=True, mode='max')\n",
    "\n",
    "  LRCN_model_training_history = model.fit(        x = X_train_40m_60f[train_idx],\n",
    "                                                  y = y_train_40m_60f[train_idx],\n",
    "                                                  validation_data=(X_train_40m_60f[val_idx],y_train_40m_60f[val_idx]),\n",
    "                                                  epochs = 80,\n",
    "                                                  batch_size = 32,\n",
    "                                                  shuffle = True,\n",
    "                                                  callbacks = [checkpoint_cb,early_stopping_callback])\n",
    "\n",
    "  model.load_weights(save_dir+\"model_\"+str(fold_var)+\".h5\")\n",
    "\t\n",
    "  results = model.evaluate(X_test, y_test)\n",
    "  results = dict(zip(model.metrics_names,results))\n",
    "\t\n",
    "  VALIDATION_ACCURACY.append(results['accuracy'])\n",
    "  VALIDATION_LOSS.append(results['loss'])\n",
    "\t\n",
    "  tf.keras.backend.clear_session()\n",
    "\t\n",
    "  fold_var += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4a501d-86e0-44b8-8a2c-22e62942dfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5626a7fd-dcac-47bc-bf30-41cc0b1f1228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4678, 128, 128, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_aud_50m_50f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3633c72-6c06-4270-affd-f0a39ad19b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize values\n",
    "X_train_aud_50m_50f = X_train_aud_50m_50f/255\n",
    "X_train_aud_40m_60f = X_train_aud_40m_60f/255\n",
    "X_train_aud_60m_40f = X_train_aud_60m_40f/255\n",
    "X_test_aud = X_test_aud/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efb9be73-12b7-47af-9d0b-3a671b841027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_alexnet():\n",
    "  AlexNet = Sequential()\n",
    "\n",
    "  #1st Convolutional Layer\n",
    "  AlexNet.add(Conv2D(filters=96, input_shape=(128,128,3), kernel_size=(11,11), strides=(4,4), padding='same'))\n",
    "  AlexNet.add(BatchNormalization())\n",
    "  AlexNet.add(Activation('relu'))\n",
    "  AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='same'))\n",
    "\n",
    "  #2nd Convolutional Layer\n",
    "  AlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\n",
    "  AlexNet.add(BatchNormalization())\n",
    "  AlexNet.add(Activation('relu'))\n",
    "  AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='same'))\n",
    "\n",
    "  #3rd Convolutional Layer\n",
    "  AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "  AlexNet.add(BatchNormalization())\n",
    "  AlexNet.add(Activation('relu'))\n",
    "\n",
    "  #4th Convolutional Layer\n",
    "  AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "  AlexNet.add(BatchNormalization())\n",
    "  AlexNet.add(Activation('relu'))\n",
    "\n",
    "  #5th Convolutional Layer\n",
    "  AlexNet.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "  AlexNet.add(BatchNormalization())\n",
    "  AlexNet.add(Activation('relu'))\n",
    "  AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='same'))\n",
    "\n",
    "  #Passing it to a Fully Connected layer\n",
    "  AlexNet.add(Flatten())\n",
    "  AlexNet.add(Dense(4096, input_shape=(32,32,3,)))\n",
    "  AlexNet.add(BatchNormalization())\n",
    "  AlexNet.add(Activation('relu'))\n",
    "  AlexNet.add(Dropout(0.4))\n",
    "\n",
    "  #2nd Fully Connected Layer\n",
    "  AlexNet.add(Dense(1000))\n",
    "  AlexNet.add(BatchNormalization())\n",
    "  AlexNet.add(Activation('relu'))\n",
    "  #Add Dropout\n",
    "  AlexNet.add(Dropout(0.4))\n",
    "\n",
    "  #Output Layer\n",
    "  AlexNet.add(Dense(6))\n",
    "  AlexNet.add(BatchNormalization())\n",
    "  AlexNet.add(Activation('softmax'))\n",
    "\n",
    "  return AlexNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d56e8a5-df2f-48ea-9a70-fe527f339508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 96)        34944     \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 32, 32, 96)        384       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 96)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 32, 32, 96)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 256)       614656    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 32, 32, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 32, 32, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 384)       885120    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 32, 32, 384)       1536      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 32, 32, 384)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 384)       1327488   \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 32, 32, 384)       1536      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 32, 32, 384)       0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 32, 32, 256)       884992    \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 32, 32, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 32, 32, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 262144)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              1073745920\n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 4096)              16384     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 4096)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1000)              4097000   \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 1000)              4000      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 1000)              0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 6006      \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 6)                 24        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 6)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1081622038 (4.03 GB)\n",
      "Trainable params: 1081609082 (4.03 GB)\n",
      "Non-trainable params: 12956 (50.61 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_alexnet().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff00c1a7-4843-4df8-9bce-624b843a1b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "117/117 [==============================] - 821s 7s/step - loss: 1.5011 - accuracy: 0.4007 - val_loss: 1.9553 - val_accuracy: 0.3173\n",
      "Epoch 2/80\n",
      "117/117 [==============================] - 784s 7s/step - loss: 1.3859 - accuracy: 0.4509 - val_loss: 2.0464 - val_accuracy: 0.2479\n",
      "Epoch 3/80\n",
      "117/117 [==============================] - 829s 7s/step - loss: 1.3324 - accuracy: 0.4868 - val_loss: 3.6556 - val_accuracy: 0.3472\n",
      "Epoch 4/80\n",
      "117/117 [==============================] - 827s 7s/step - loss: 1.3035 - accuracy: 0.4940 - val_loss: 2.9851 - val_accuracy: 0.3483\n",
      "Epoch 5/80\n",
      "117/117 [==============================] - 909s 8s/step - loss: 1.2495 - accuracy: 0.5237 - val_loss: 2.9249 - val_accuracy: 0.3953\n",
      "Epoch 6/80\n",
      "117/117 [==============================] - 824s 7s/step - loss: 1.2114 - accuracy: 0.5319 - val_loss: 6.5184 - val_accuracy: 0.2041\n",
      "Epoch 7/80\n",
      "117/117 [==============================] - 833s 7s/step - loss: 1.1609 - accuracy: 0.5600 - val_loss: 2.8540 - val_accuracy: 0.2489\n",
      "Epoch 8/80\n",
      "117/117 [==============================] - 877s 8s/step - loss: 1.1139 - accuracy: 0.5846 - val_loss: 1.2711 - val_accuracy: 0.5043\n",
      "Epoch 9/80\n",
      "117/117 [==============================] - 891s 8s/step - loss: 1.0414 - accuracy: 0.6212 - val_loss: 1.3503 - val_accuracy: 0.4808\n",
      "Epoch 10/80\n",
      "117/117 [==============================] - 909s 8s/step - loss: 1.0097 - accuracy: 0.6236 - val_loss: 1.4562 - val_accuracy: 0.4808\n",
      "Epoch 11/80\n",
      "117/117 [==============================] - 910s 8s/step - loss: 0.9153 - accuracy: 0.6733 - val_loss: 1.9148 - val_accuracy: 0.3750\n",
      "Epoch 12/80\n",
      "117/117 [==============================] - 913s 8s/step - loss: 0.8439 - accuracy: 0.7062 - val_loss: 1.5338 - val_accuracy: 0.4925\n",
      "Epoch 13/80\n",
      "117/117 [==============================] - 920s 8s/step - loss: 0.7627 - accuracy: 0.7402 - val_loss: 1.4547 - val_accuracy: 0.4476\n",
      "Epoch 14/80\n",
      "117/117 [==============================] - 920s 8s/step - loss: 0.6776 - accuracy: 0.7795 - val_loss: 1.6930 - val_accuracy: 0.4263\n",
      "Epoch 15/80\n",
      "117/117 [==============================] - 915s 8s/step - loss: 0.5624 - accuracy: 0.8337 - val_loss: 1.4422 - val_accuracy: 0.5043\n",
      "Epoch 16/80\n",
      "117/117 [==============================] - 948s 8s/step - loss: 0.4846 - accuracy: 0.8605 - val_loss: 1.4460 - val_accuracy: 0.5246\n",
      "Epoch 17/80\n",
      "117/117 [==============================] - 833s 7s/step - loss: 0.3794 - accuracy: 0.9115 - val_loss: 1.4369 - val_accuracy: 0.5043\n",
      "Epoch 18/80\n",
      "117/117 [==============================] - 850s 7s/step - loss: 0.3095 - accuracy: 0.9366 - val_loss: 1.6931 - val_accuracy: 0.4391\n",
      "Epoch 19/80\n",
      "117/117 [==============================] - 954s 8s/step - loss: 0.2868 - accuracy: 0.9417 - val_loss: 1.4472 - val_accuracy: 0.5118\n",
      "Epoch 20/80\n",
      "117/117 [==============================] - 895s 8s/step - loss: 0.2592 - accuracy: 0.9473 - val_loss: 1.6161 - val_accuracy: 0.4829\n",
      "Epoch 21/80\n",
      "117/117 [==============================] - 933s 8s/step - loss: 0.2108 - accuracy: 0.9671 - val_loss: 1.7655 - val_accuracy: 0.4487\n",
      "Epoch 22/80\n",
      "117/117 [==============================] - 911s 8s/step - loss: 0.1794 - accuracy: 0.9719 - val_loss: 1.4156 - val_accuracy: 0.5096\n",
      "Epoch 23/80\n",
      "117/117 [==============================] - 1481s 13s/step - loss: 0.1687 - accuracy: 0.9714 - val_loss: 1.5029 - val_accuracy: 0.4637\n",
      "Epoch 24/80\n",
      "117/117 [==============================] - 1552s 13s/step - loss: 0.1565 - accuracy: 0.9783 - val_loss: 1.4120 - val_accuracy: 0.5385\n",
      "Epoch 25/80\n",
      "117/117 [==============================] - 1398s 12s/step - loss: 0.1349 - accuracy: 0.9824 - val_loss: 1.4641 - val_accuracy: 0.5310\n",
      "Epoch 26/80\n",
      "117/117 [==============================] - 1064s 9s/step - loss: 0.1294 - accuracy: 0.9821 - val_loss: 1.4366 - val_accuracy: 0.5630\n",
      "Epoch 27/80\n",
      "117/117 [==============================] - 1086s 9s/step - loss: 0.1141 - accuracy: 0.9842 - val_loss: 1.4905 - val_accuracy: 0.5321\n",
      "Epoch 28/80\n",
      "117/117 [==============================] - 1219s 10s/step - loss: 0.1132 - accuracy: 0.9845 - val_loss: 1.6149 - val_accuracy: 0.4893\n",
      "Epoch 29/80\n",
      "117/117 [==============================] - 1282s 11s/step - loss: 0.1062 - accuracy: 0.9864 - val_loss: 1.7580 - val_accuracy: 0.4199\n",
      "Epoch 30/80\n",
      "117/117 [==============================] - 974s 8s/step - loss: 0.1206 - accuracy: 0.9810 - val_loss: 1.5860 - val_accuracy: 0.5331\n",
      "Epoch 31/80\n",
      "117/117 [==============================] - 967s 8s/step - loss: 0.1266 - accuracy: 0.9751 - val_loss: 1.5096 - val_accuracy: 0.5192\n",
      "Epoch 32/80\n",
      "117/117 [==============================] - 971s 8s/step - loss: 0.1231 - accuracy: 0.9743 - val_loss: 1.6245 - val_accuracy: 0.4979\n",
      "Epoch 33/80\n",
      "117/117 [==============================] - 1009s 9s/step - loss: 0.1199 - accuracy: 0.9762 - val_loss: 1.6887 - val_accuracy: 0.4722\n",
      "Epoch 34/80\n",
      "117/117 [==============================] - 997s 9s/step - loss: 0.1138 - accuracy: 0.9757 - val_loss: 1.6489 - val_accuracy: 0.4840\n",
      "Epoch 35/80\n",
      "117/117 [==============================] - 991s 8s/step - loss: 0.0997 - accuracy: 0.9821 - val_loss: 1.9152 - val_accuracy: 0.4519\n",
      "Epoch 36/80\n",
      "117/117 [==============================] - 1003s 9s/step - loss: 0.0952 - accuracy: 0.9821 - val_loss: 1.5621 - val_accuracy: 0.5363\n",
      "Epoch 37/80\n",
      "117/117 [==============================] - 994s 8s/step - loss: 0.0903 - accuracy: 0.9837 - val_loss: 1.5769 - val_accuracy: 0.5235\n",
      "Epoch 38/80\n",
      "117/117 [==============================] - 1016s 9s/step - loss: 0.0915 - accuracy: 0.9834 - val_loss: 1.5897 - val_accuracy: 0.5214\n",
      "Epoch 39/80\n",
      "117/117 [==============================] - 1011s 9s/step - loss: 0.0851 - accuracy: 0.9832 - val_loss: 1.7750 - val_accuracy: 0.4797\n",
      "Epoch 40/80\n",
      "117/117 [==============================] - 998s 9s/step - loss: 0.0944 - accuracy: 0.9789 - val_loss: 1.7322 - val_accuracy: 0.5107\n",
      "Epoch 41/80\n",
      "117/117 [==============================] - 1037s 9s/step - loss: 0.0897 - accuracy: 0.9789 - val_loss: 1.6758 - val_accuracy: 0.4904\n",
      "47/47 [==============================] - 57s 1s/step - loss: 1.4974 - accuracy: 0.5266\n",
      "Epoch 1/80\n",
      "117/117 [==============================] - 1087s 9s/step - loss: 1.5123 - accuracy: 0.3935 - val_loss: 2.5575 - val_accuracy: 0.2382\n",
      "Epoch 2/80\n",
      "117/117 [==============================] - 1159s 9s/step - loss: 1.3881 - accuracy: 0.4480 - val_loss: 1.5430 - val_accuracy: 0.3857\n",
      "Epoch 3/80\n",
      "117/117 [==============================] - 976s 8s/step - loss: 1.3431 - accuracy: 0.4769 - val_loss: 2.0044 - val_accuracy: 0.3184\n",
      "Epoch 4/80\n",
      "117/117 [==============================] - 1035s 9s/step - loss: 1.2994 - accuracy: 0.4967 - val_loss: 3.8510 - val_accuracy: 0.3900\n",
      "Epoch 5/80\n",
      "117/117 [==============================] - 1034s 9s/step - loss: 1.2470 - accuracy: 0.5164 - val_loss: 2.2694 - val_accuracy: 0.3034\n",
      "Epoch 6/80\n",
      "117/117 [==============================] - 1018s 9s/step - loss: 1.2046 - accuracy: 0.5295 - val_loss: 2.8590 - val_accuracy: 0.3632\n",
      "Epoch 7/80\n",
      "117/117 [==============================] - 1019s 9s/step - loss: 1.1587 - accuracy: 0.5648 - val_loss: 2.5385 - val_accuracy: 0.2639\n",
      "Epoch 8/80\n",
      "117/117 [==============================] - 1021s 9s/step - loss: 1.1129 - accuracy: 0.5811 - val_loss: 2.0528 - val_accuracy: 0.3878\n",
      "Epoch 9/80\n",
      "117/117 [==============================] - 1031s 9s/step - loss: 1.0399 - accuracy: 0.6161 - val_loss: 1.8610 - val_accuracy: 0.3782\n",
      "Epoch 10/80\n",
      "117/117 [==============================] - 1054s 9s/step - loss: 0.9697 - accuracy: 0.6528 - val_loss: 1.7067 - val_accuracy: 0.3985\n",
      "Epoch 11/80\n",
      "117/117 [==============================] - 1011s 9s/step - loss: 0.8952 - accuracy: 0.6787 - val_loss: 2.9276 - val_accuracy: 0.3665\n",
      "Epoch 12/80\n",
      "117/117 [==============================] - 1021s 9s/step - loss: 0.8235 - accuracy: 0.7108 - val_loss: 2.1057 - val_accuracy: 0.3643\n",
      "Epoch 13/80\n",
      "117/117 [==============================] - 1027s 9s/step - loss: 0.7297 - accuracy: 0.7589 - val_loss: 1.7161 - val_accuracy: 0.4466\n",
      "Epoch 14/80\n",
      "117/117 [==============================] - 1048s 9s/step - loss: 0.6252 - accuracy: 0.8054 - val_loss: 1.5053 - val_accuracy: 0.4626\n",
      "Epoch 15/80\n",
      "117/117 [==============================] - 1053s 9s/step - loss: 0.5235 - accuracy: 0.8450 - val_loss: 1.4635 - val_accuracy: 0.5000\n",
      "Epoch 16/80\n",
      "117/117 [==============================] - 1040s 9s/step - loss: 0.4345 - accuracy: 0.8848 - val_loss: 1.4101 - val_accuracy: 0.5118\n",
      "Epoch 17/80\n",
      "117/117 [==============================] - 1014s 9s/step - loss: 0.3441 - accuracy: 0.9257 - val_loss: 1.4679 - val_accuracy: 0.5032\n",
      "Epoch 18/80\n",
      "117/117 [==============================] - 1038s 9s/step - loss: 0.3230 - accuracy: 0.9257 - val_loss: 1.4703 - val_accuracy: 0.5150\n",
      "Epoch 19/80\n",
      "117/117 [==============================] - 1020s 9s/step - loss: 0.2725 - accuracy: 0.9463 - val_loss: 1.6030 - val_accuracy: 0.4679\n",
      "Epoch 20/80\n",
      " 15/117 [==>...........................] - ETA: 13:53 - loss: 0.2576 - accuracy: 0.9542"
     ]
    }
   ],
   "source": [
    "VALIDATION_ACCURACY_SPEECH = []\n",
    "VALIDATION_LOSS_SPEECH= []\n",
    "\n",
    "save_dir = os.path.abspath(DIR)+'/cremad_60m40f_audio_model/'\n",
    "fold_var = 1\n",
    "\n",
    "for train_idx, val_idx in kfold.split(X_train_aud_60m_40f, y_train_60m_40f):\n",
    "  # with tpu_strategy.scope()\n",
    "  model=model_alexnet() \n",
    "  model.compile(loss='sparse_categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
    "  early_stopping_callback = EarlyStopping(monitor = 'val_accuracy', patience = 15, restore_best_weights = True)\n",
    "  checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(save_dir+get_model_name(fold_var), \n",
    "        monitor='val_accuracy', \n",
    "        save_best_only=True, mode='max')\n",
    "\n",
    "  LRCN_model_training_history = model.fit(        x = X_train_aud_60m_40f[train_idx],\n",
    "                                                  y = y_train_60m_40f[train_idx],\n",
    "                                                  validation_data=(X_train_aud_60m_40f[val_idx], y_train_60m_40f[val_idx]),\n",
    "                                                  epochs = 80,\n",
    "                                                  batch_size = 32,\n",
    "                                                  shuffle = True,\n",
    "                                                  callbacks = [checkpoint_cb,early_stopping_callback])\n",
    "\n",
    "  model.load_weights(save_dir+\"model_\"+str(fold_var)+\".h5\")\n",
    "\t\n",
    "  results = model.evaluate(X_test_aud, y_test)\n",
    "  results = dict(zip(model.metrics_names,results))\n",
    "\t\n",
    "  VALIDATION_ACCURACY_SPEECH.append(results['accuracy'])\n",
    "  VALIDATION_LOSS_SPEECH.append(results['loss'])\n",
    "\t\n",
    "  tf.keras.backend.clear_session()\n",
    "\t\n",
    "  fold_var += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
