{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fbd0864-3b2a-4342-a57e-61dc124a7a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:32:59.184086: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import random as rd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "import pickle\n",
    "import dlib\n",
    "\n",
    "from deepface import DeepFace\n",
    "from deepface.basemodels import VGGFace, OpenFace, Facenet, FbDeepFace, DeepID\n",
    "from deepface.extendedmodels import Age, Gender, Race, Emotion\n",
    "#from deepface.modules import verification\n",
    "from deepface.commons import functions, distance as dst\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Input,Conv2D,MaxPooling2D,Dropout,LSTM,\\\n",
    "                            TimeDistributed,Flatten,Dense,Bidirectional,ConvLSTM2D,MaxPooling3D,AveragePooling2D,Lambda,\\\n",
    "                            Activation,BatchNormalization\n",
    "\n",
    "from tensorflow import keras\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46c3c1da-f574-4d48-a095-82a2e4d5cc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_constant = 27\n",
    "np.random.seed(seed_constant)\n",
    "rd.seed(seed_constant)\n",
    "tf.random.set_seed(seed_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a01fed8-96b6-4beb-b02a-4538a49e2774",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = '/var/scratch/mpa326/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7939a2b-09a1-49f9-88f3-690565eca4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "dbfile = open('/var/scratch/mpa326/Ravdess_code/Video Features/video_train_50m_50f', 'rb')     \n",
    "df = pickle.load(dbfile)\n",
    "\n",
    "y_train_50m_50f = df['labels']\n",
    "gender_train_50m_50f = df['genders']\n",
    "X_train_50m_50f=df['features']\n",
    "paths_train_50m_50f = df['video_files_paths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a188922c-46ae-400f-988d-f3beb1518d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = open('/var/scratch/mpa326/Ravdess_code/Video Features/video_train_40m_60f', 'rb')     \n",
    "df = pickle.load(dbfile)\n",
    "\n",
    "y_train_40m_60f = df['labels']\n",
    "gender_train_40m_60f = df['genders']\n",
    "X_train_40m_60f=df['features']\n",
    "paths_train_40m_60f = df['video_files_paths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "753bf114-430b-4a82-ab4f-c3ca6b3b28ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = open('/var/scratch/mpa326/Ravdess_code/Video Features/video_train_60m_40f', 'rb')     \n",
    "df = pickle.load(dbfile)\n",
    "\n",
    "y_train_60m_40f = df['labels']\n",
    "gender_train_60m_40f = df['genders']\n",
    "X_train_60m_40f=df['features']\n",
    "paths_train_60m_40f = df['video_files_paths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d67e0268-ea8c-4242-a549-5c840fdd63ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = open('/var/scratch/mpa326/Ravdess_code/Video Features/video_test_common','rb')\n",
    "df = pickle.load(dbfile)\n",
    "\n",
    "y_test = df['labels']\n",
    "gender_test = df['genders']\n",
    "X_test=df['features']\n",
    "paths_test = df['video_files_paths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff31cbb1-7869-4584-aa31-b6fed27af229",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = open('/var/scratch/mpa326/Ravdess_code/Audio Features/audio_train_50m_50f', 'rb')     \n",
    "df = pickle.load(dbfile)\n",
    "X_train_aud_50m_50f=df['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ba6d6bb-2ce8-42cb-93b4-0d4564f60335",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = open('/var/scratch/mpa326/Ravdess_code/Audio Features/audio_train_40m_60f', 'rb')     \n",
    "df = pickle.load(dbfile)\n",
    "X_train_aud_40m_60f=df['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "82d5d573-fb13-4575-9496-7913c47e6f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = open('/var/scratch/mpa326/Ravdess_code/Audio Features/audio_train_60m_40f', 'rb')     \n",
    "df = pickle.load(dbfile)\n",
    "X_train_aud_60m_40f=df['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0ce849f-fbe2-4256-8919-1d6aa0bca2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = open('/var/scratch/mpa326/Ravdess_code/Audio Features/audio_test_common', 'rb')     \n",
    "df = pickle.load(dbfile)\n",
    "X_test_aud=df['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24e87253-f033-49be-8bdf-f623f30915ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X_train_50m_50f, X_train_aud_50m_50f, y_train_50m_50f, gender_train_50m_50f = shuffle(X_train_50m_50f, X_train_aud_50m_50f, y_train_50m_50f, gender_train_50m_50f, random_state=27)\n",
    "X_train_50m_50f, X_train_aud_50m_50f, y_train_50m_50f, gender_train_50m_50f = shuffle(X_train_50m_50f, X_train_aud_50m_50f, y_train_50m_50f, gender_train_50m_50f, random_state=7)\n",
    "X_train_50m_50f, X_train_aud_50m_50f, y_train_50m_50f, gender_train_50m_50f = shuffle(X_train_50m_50f, X_train_aud_50m_50f, y_train_50m_50f, gender_train_50m_50f, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "daf89790-cbd0-459b-bc3f-a1010bbe5174",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_40m_60f, X_train_aud_40m_60f, y_train_40m_60f, gender_train_40m_60f = shuffle(X_train_40m_60f, X_train_aud_40m_60f, y_train_40m_60f, gender_train_40m_60f, random_state=27)\n",
    "X_train_40m_60f, X_train_aud_40m_60f, y_train_40m_60f, gender_train_40m_60f = shuffle(X_train_40m_60f, X_train_aud_40m_60f, y_train_40m_60f, gender_train_40m_60f, random_state=7)\n",
    "X_train_40m_60f, X_train_aud_40m_60f, y_train_40m_60f, gender_train_40m_60f = shuffle(X_train_40m_60f, X_train_aud_40m_60f, y_train_40m_60f, gender_train_40m_60f, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46b22c0e-bde1-401f-a9cd-a270be230fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_60m_40f, X_train_aud_60m_40f, y_train_60m_40f, gender_train_60m_40f = shuffle(X_train_60m_40f, X_train_aud_60m_40f, y_train_60m_40f, gender_train_60m_40f, random_state=27)\n",
    "X_train_60m_40f, X_train_aud_60m_40f, y_train_60m_40f, gender_train_60m_40f = shuffle(X_train_60m_40f, X_train_aud_60m_40f, y_train_60m_40f, gender_train_60m_40f, random_state=7)\n",
    "X_train_60m_40f, X_train_aud_60m_40f, y_train_60m_40f, gender_train_60m_40f = shuffle(X_train_60m_40f, X_train_aud_60m_40f, y_train_60m_40f, gender_train_60m_40f, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c433867-ac6d-4b19-b9de-5da415915ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_test_aud, y_test, gender_test = shuffle(X_test, X_test_aud, y_test, gender_test, random_state=27)\n",
    "X_test, X_test_aud, y_test, gender_test = shuffle(X_test, X_test_aud, y_test, gender_test, random_state=7)\n",
    "X_test, X_test_aud, y_test, gender_test = shuffle(X_test, X_test_aud, y_test, gender_test, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e133146-b8c5-476b-87f7-fab7fec60141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_2\n",
      "average_pooling2d\n",
      "conv2d_3\n",
      "conv2d_4\n",
      "average_pooling2d_1\n",
      "flatten\n",
      "dense\n",
      "dropout\n",
      "dense_1\n",
      "dropout_1\n",
      "dense_2\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "emotion=Emotion.loadModel()\n",
    "for layer in emotion.layers:\n",
    "    print(layer.name)\n",
    "features_emotion=Model(inputs=emotion.input, outputs=emotion.get_layer('dense_1').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "735ee4f4-5732-4683-bc91-3898b9d63153",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = np.ones((960,20,48,48))\n",
    "for i in range(960):\n",
    "  for j in range(20):\n",
    "    img=X_train_50m_50f[i][j]\n",
    "    img=img.astype(np.float32)\n",
    "    # df_[i][j]=cv2.resize(img,(48, 48))/255\n",
    "    df_[i][j]=img/255\n",
    "X_train_50m_50f=df_\n",
    "df_=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42509a17-4bdf-4140-a016-eba0b0a81468",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = np.ones((960,20,48,48))\n",
    "for i in range(960):\n",
    "  for j in range(20):\n",
    "    img=X_train_40m_60f[i][j]\n",
    "    img=img.astype(np.float32)\n",
    "    # df_[i][j]=cv2.resize(img,(48, 48))/255\n",
    "    df_[i][j]=img/255\n",
    "X_train_40m_60f=df_\n",
    "df_=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a715f706-96d7-40dd-8949-7881848bf910",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = np.ones((960,20,48,48))\n",
    "for i in range(960):\n",
    "  for j in range(20):\n",
    "    img=X_train_60m_40f[i][j]\n",
    "    img=img.astype(np.float32)\n",
    "    # df_[i][j]=cv2.resize(img,(48, 48))/255\n",
    "    df_[i][j]=img/255\n",
    "X_train_60m_40f=df_\n",
    "df_=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7855aee-8d95-4b1b-b904-b363c3a86c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = np.ones((288,20,48,48))\n",
    "for i in range(288):\n",
    "  for j in range(20):\n",
    "    img=X_test[i][j]\n",
    "    img=img.astype(np.float32)\n",
    "    # df_[i][j]=cv2.resize(img,(48, 48))/255\n",
    "    df_[i][j]=img/255\n",
    "X_test=df_\n",
    "df_=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56d0a726-9c5c-42f8-bf58-6000124da806",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_emotion.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba3f02a3-8f1c-4787-abad-6cb654413286",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Localization(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Localization, self).__init__()\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(20, [5, 5], activation='relu')\n",
    "        self.pool2 = tf.keras.layers.MaxPool2D()\n",
    "        self.conv2 = tf.keras.layers.Conv2D(20, [5, 5], activation='relu')\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc1 = tf.keras.layers.Dense(20, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(6, activation=None, bias_initializer=tf.keras.initializers.constant([1.0, 0.0, 0.0, 0.0, 1.0, 0.0]), kernel_initializer='zeros')\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        print(\"Building Localization Network with input shape:\", input_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [None, 2, 3]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        theta = self.fc2(x)\n",
    "        theta = tf.keras.layers.Reshape((2, 3))(theta)\n",
    "        return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfa716f2-a6ba-4924-9b96-e6288296c272",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BilinearInterpolation(tf.keras.layers.Layer):\n",
    "    def __init__(self, height=40, width=40):\n",
    "        super(BilinearInterpolation, self).__init__()\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [None, self.height, self.width, 1]\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            'height': self.height,\n",
    "            'width': self.width,\n",
    "        }\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        print(\"Building Bilinear Interpolation Layer with input shape:\", input_shape)\n",
    "\n",
    "    def advance_indexing(self, inputs, x, y):\n",
    "        '''\n",
    "        Numpy like advance indexing is not supported in tensorflow, hence, this function is a hack around the same method\n",
    "        '''        \n",
    "        shape = tf.shape(inputs)\n",
    "        batch_size, _, _ = shape[0], shape[1], shape[2]\n",
    "        \n",
    "        batch_idx = tf.range(0, batch_size)\n",
    "        batch_idx = tf.reshape(batch_idx, (batch_size, 1, 1))\n",
    "        b = tf.tile(batch_idx, (1, self.height, self.width))\n",
    "        indices = tf.stack([b, y, x], 3)\n",
    "        return tf.gather_nd(inputs, indices)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        images, theta = inputs\n",
    "        homogenous_coordinates = self.grid_generator(batch=tf.shape(images)[0])\n",
    "        return self.interpolate(images, homogenous_coordinates, theta)\n",
    "\n",
    "    def grid_generator(self, batch):\n",
    "        x = tf.linspace(-1, 1, self.width)\n",
    "        y = tf.linspace(-1, 1, self.height)\n",
    "            \n",
    "        xx, yy = tf.meshgrid(x, y)\n",
    "        xx = tf.reshape(xx, (-1,))\n",
    "        yy = tf.reshape(yy, (-1,))\n",
    "        homogenous_coordinates = tf.stack([xx, yy, tf.ones_like(xx)])\n",
    "        homogenous_coordinates = tf.expand_dims(homogenous_coordinates, axis=0)\n",
    "        homogenous_coordinates = tf.tile(homogenous_coordinates, [batch, 1, 1])\n",
    "        homogenous_coordinates = tf.cast(homogenous_coordinates, dtype=tf.float32)\n",
    "        return homogenous_coordinates\n",
    "    \n",
    "    def interpolate(self, images, homogenous_coordinates, theta):\n",
    "\n",
    "        with tf.name_scope(\"Transformation\"):\n",
    "            transformed = tf.matmul(theta, homogenous_coordinates)\n",
    "            transformed = tf.transpose(transformed, perm=[0, 2, 1])\n",
    "            transformed = tf.reshape(transformed, [-1, self.height, self.width, 2])\n",
    "                \n",
    "            x_transformed = transformed[:, :, :, 0]\n",
    "            y_transformed = transformed[:, :, :, 1]\n",
    "                \n",
    "            x = ((x_transformed + 1.) * tf.cast(self.width, dtype=tf.float32)) * 0.5\n",
    "            y = ((y_transformed + 1.) * tf.cast(self.height, dtype=tf.float32)) * 0.5\n",
    "\n",
    "        with tf.name_scope(\"VariableCasting\"):\n",
    "            x0 = tf.cast(tf.math.floor(x), dtype=tf.int32)\n",
    "            x1 = x0 + 1\n",
    "            y0 = tf.cast(tf.math.floor(y), dtype=tf.int32)\n",
    "            y1 = y0 + 1\n",
    "\n",
    "            x0 = tf.clip_by_value(x0, 0, self.width-1)\n",
    "            x1 = tf.clip_by_value(x1, 0, self.width-1)\n",
    "            y0 = tf.clip_by_value(y0, 0, self.height-1)\n",
    "            y1 = tf.clip_by_value(y1, 0, self.height-1)\n",
    "            x = tf.clip_by_value(x, 0, tf.cast(self.width, dtype=tf.float32)-1.0)\n",
    "            y = tf.clip_by_value(y, 0, tf.cast(self.height, dtype=tf.float32)-1)\n",
    "\n",
    "        with tf.name_scope(\"AdvanceIndexing\"):\n",
    "            Ia = self.advance_indexing(images, x0, y0)\n",
    "            Ib = self.advance_indexing(images, x0, y1)\n",
    "            Ic = self.advance_indexing(images, x1, y0)\n",
    "            Id = self.advance_indexing(images, x1, y1)\n",
    "\n",
    "        with tf.name_scope(\"Interpolation\"):\n",
    "            x0 = tf.cast(x0, dtype=tf.float32)\n",
    "            x1 = tf.cast(x1, dtype=tf.float32)\n",
    "            y0 = tf.cast(y0, dtype=tf.float32)\n",
    "            y1 = tf.cast(y1, dtype=tf.float32)\n",
    "                            \n",
    "            wa = (x1-x) * (y1-y)\n",
    "            wb = (x1-x) * (y-y0)\n",
    "            wc = (x-x0) * (y1-y)\n",
    "            wd = (x-x0) * (y-y0)\n",
    "\n",
    "            wa = tf.expand_dims(wa, axis=3)\n",
    "            wb = tf.expand_dims(wb, axis=3)\n",
    "            wc = tf.expand_dims(wc, axis=3)\n",
    "            wd = tf.expand_dims(wd, axis=3)\n",
    "                        \n",
    "        return tf.math.add_n([wa*Ia + wb*Ib + wc*Ic + wd*Id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56e005c7-629c-42ba-8340-21efa69905f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_en = [\"neutral\", \"calm\", \"happy\", \"sad\", \"angry\", \"fearful\", \"disgust\", \"surprised\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9aeb84d2-afb8-41d7-9a85-422d8456bc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create__LRCN_with_STN() :\n",
    "  image = tf.keras.layers.Input(shape=(20,48,48,1))\n",
    "  theta = TimeDistributed(Localization())(image)\n",
    "  x = TimeDistributed(BilinearInterpolation(height=48, width=48))([image, theta])\n",
    "  features=TimeDistributed(features_emotion)(x)\n",
    "  lstm=Bidirectional(LSTM(200, activation='tanh',input_shape=(20, 1024),dropout=.3))(features)\n",
    "  out=Dense(len(emotions_en), activation = 'softmax')(lstm)\n",
    "\n",
    "  return tf.keras.models.Model(inputs=image, outputs=out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a348656-961e-437a-bdb6-15d9f7bb78b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(k):\n",
    "    return 'model_'+str(k)+'.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d7d4e76-3092-4bcc-905d-c2ff13d26cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "seed = 7\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5fdc0470-240f-47d8-b434-159f93df3a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "658a234e-fb55-4b24-b8b6-dcb70e31d541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_alexnet():\n",
    "  AlexNet = Sequential()\n",
    "\n",
    "  #1st Convolutional Layer\n",
    "  AlexNet.add(Conv2D(filters=96, input_shape=(128,128,3), kernel_size=(11,11), strides=(4,4), padding='same'))\n",
    "  AlexNet.add(BatchNormalization())\n",
    "  AlexNet.add(Activation('relu'))\n",
    "  AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='same'))\n",
    "\n",
    "  #2nd Convolutional Layer\n",
    "  AlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\n",
    "  AlexNet.add(BatchNormalization())\n",
    "  AlexNet.add(Activation('relu'))\n",
    "  AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='same'))\n",
    "\n",
    "  #3rd Convolutional Layer\n",
    "  AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "  AlexNet.add(BatchNormalization())\n",
    "  AlexNet.add(Activation('relu'))\n",
    "\n",
    "  #4th Convolutional Layer\n",
    "  AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "  AlexNet.add(BatchNormalization())\n",
    "  AlexNet.add(Activation('relu'))\n",
    "\n",
    "  #5th Convolutional Layer\n",
    "  AlexNet.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "  AlexNet.add(BatchNormalization())\n",
    "  AlexNet.add(Activation('relu'))\n",
    "  AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='same'))\n",
    "\n",
    "  #Passing it to a Fully Connected layer\n",
    "  AlexNet.add(Flatten())\n",
    "  AlexNet.add(Dense(4096, input_shape=(32,32,3,)))\n",
    "  AlexNet.add(BatchNormalization())\n",
    "  AlexNet.add(Activation('relu'))\n",
    "  AlexNet.add(Dropout(0.4))\n",
    "\n",
    "  # #2nd Fully Connected Layer\n",
    "  # AlexNet.add(Dense(4096))\n",
    "  # AlexNet.add(BatchNormalization())\n",
    "  # AlexNet.add(Activation('relu'))\n",
    "  # #Add Dropout\n",
    "  # AlexNet.add(Dropout(0.4))\n",
    "\n",
    "  #3rd Fully Connected Layer\n",
    "  AlexNet.add(Dense(1000))\n",
    "  AlexNet.add(BatchNormalization())\n",
    "  AlexNet.add(Activation('relu'))\n",
    "  #Add Dropout\n",
    "  AlexNet.add(Dropout(0.4))\n",
    "\n",
    "  #Output Layer\n",
    "  AlexNet.add(Dense(8))\n",
    "  AlexNet.add(BatchNormalization())\n",
    "  AlexNet.add(Activation('softmax'))\n",
    "\n",
    "  return AlexNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cac8489c-e62e-4f9a-a0d7-4e8ba085d84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LATE FUSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "421edb3c-4d82-4399-ab4e-f9b25717a2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_indice = 3\n",
    "audio_indice = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0d93d50-485c-4d53-a834-ef655374fc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:33:56.882661: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 4294967296 exceeds 10% of free system memory.\n",
      "2024-08-08 20:33:57.736676: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 4294967296 exceeds 10% of free system memory.\n",
      "2024-08-08 20:33:58.895362: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 4294967296 exceeds 10% of free system memory.\n",
      "2024-08-08 20:34:41.263607: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 4294967296 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "save_dir = os.path.abspath(DIR)+'/ravdess_50m50f_audio_model/'\n",
    "model_audio = model_alexnet()\n",
    "model_audio.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=[\"accuracy\"])\n",
    "model_audio.load_weights(save_dir +\"model_\"+str(audio_indice)+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a9cd79ae-c206-4a8b-82bf-0f113bfcea6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Localization Network with input shape: (None, 48, 48, 1)\n",
      "Building Bilinear Interpolation Layer with input shape: ((None, 48, 48, 1), (None, 2, 3))\n"
     ]
    }
   ],
   "source": [
    "save_dir = os.path.abspath(DIR)+'/ravdess_50m50f_video_model/'\n",
    "\n",
    "model_video = create__LRCN_with_STN()\n",
    "model_video.compile(loss='sparese_categorical_crossentropy', optimizer='Adam', metrics=[\"accuracy\"])\n",
    "model_video.load_weights(save_dir+\"model_\"+str(video_indice)+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56ced0b9-2aec-4811-a28e-bb35b625a1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_video_model=Model(inputs=model_video.input, outputs=model_video.get_layer('bidirectional').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31e3bd93-a006-4869-a8dd-1257bf8f7269",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-08 20:35:10.685049: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 176947200 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 15s 315ms/step\n"
     ]
    }
   ],
   "source": [
    "features_video=features_video_model.predict(X_train_50m_50f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0cc8b517-6737-4365-bf30-d26d0aedec1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 400)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ece4896d-9c2c-41b0-a84a-78cdbfef1f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_audio_model=Model(inputs=model_audio.input, outputs=model_audio.get_layer('dropout_3').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72fd10fc-9dc6-42b2-b260-9cd60361f057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 52s 2s/step\n"
     ]
    }
   ],
   "source": [
    "features_audio=features_audio_model.predict(X_train_aud_50m_50f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff7647b0-a2c9-43e7-829c-fcff8112e91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 1000)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "489c7a2a-b05a-419f-84c3-1e06a9cd87cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_data_train=np.concatenate((features_video,features_audio),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "443550ac-3c9e-421d-999b-364556ebf753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(960, 1400)\n",
      "[[-7.4953324e-01  2.6307213e-01 -3.1220677e-01 ...  0.0000000e+00\n",
      "   1.3266525e+00  0.0000000e+00]\n",
      " [ 1.8515849e-01 -1.1131900e-01 -2.6439235e-01 ...  0.0000000e+00\n",
      "   1.4309967e-01  3.6613369e-01]\n",
      " [ 1.3563527e-01  8.5230398e-01 -4.9928925e-04 ...  1.4416392e+00\n",
      "   3.2065475e-01  1.4489424e-01]\n",
      " ...\n",
      " [ 5.6693667e-01 -1.6385494e-01 -1.4361385e-03 ...  0.0000000e+00\n",
      "   1.2457469e+00  2.5211527e+00]\n",
      " [-6.3650429e-02  9.0852320e-02 -4.6145919e-04 ...  0.0000000e+00\n",
      "   2.5686688e+00  2.5723717e+00]\n",
      " [-3.0029687e-01 -1.0286822e-01 -4.1443235e-01 ...  1.5334773e+00\n",
      "   0.0000000e+00  1.3635838e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(fused_data_train.shape)\n",
    "print(fused_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22b8e2b4-37bd-4eeb-bbe8-8c7a285fb38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 3s 328ms/step\n"
     ]
    }
   ],
   "source": [
    "features_video_test=features_video_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e6841f8e-3c52-4bb7-9144-4901bd70a213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 13s 1s/step\n"
     ]
    }
   ],
   "source": [
    "features_audio_test=features_audio_model.predict(X_test_aud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "38c5f458-6cb5-4835-9a38-e2aa418d59d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_data_test = np.concatenate((features_video_test, features_audio_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e5630380-367d-4b1e-88ca-ed3d634c82e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 1400)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fused_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "32f20c3d-f316-4691-b892-4ca7ca50f58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "fused_data_train = sc.fit_transform(fused_data_train)\n",
    "fused_data_test = sc.transform(fused_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "46dedf57-9d5e-450a-a073-1118fc0cae73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components to retain 95% variance: 201\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def find_n_components(data, variance_threshold=0.95):\n",
    "    \"\"\"\n",
    "    Determine the number of components to retain a specified amount of variance.\n",
    "\n",
    "    Parameters:\n",
    "    - data: array-like, shape (n_samples, n_features)\n",
    "      The data to perform PCA on.\n",
    "    - variance_threshold: float, optional (default=0.95)\n",
    "      The amount of variance that needs to be retained. Should be between 0 and 1.\n",
    "\n",
    "    Returns:\n",
    "    - n_components: int\n",
    "      The number of components to retain the specified amount of variance.\n",
    "    \"\"\"\n",
    "    pca = PCA()\n",
    "    pca.fit(data)\n",
    "    \n",
    "    # Calculate cumulative variance\n",
    "    cumulative_variance = pca.explained_variance_ratio_.cumsum()\n",
    "    \n",
    "    # Find the number of components that satisfy the variance threshold\n",
    "    n_components = (cumulative_variance >= variance_threshold).argmax() + 1\n",
    "    \n",
    "    return n_components\n",
    "\n",
    "# Example usage:\n",
    "# Assuming fused_data_train is your training dataset\n",
    "n_components = find_n_components(fused_data_train, variance_threshold=0.95)\n",
    "print(f\"Number of components to retain 95% variance: {n_components}\")\n",
    "\n",
    "# Applying PCA with the determined number of components\n",
    "lda = PCA(n_components=n_components)\n",
    "fused_data_train = lda.fit_transform(fused_data_train)\n",
    "fused_data_test = lda.transform(fused_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3a26f8bf-23c4-4a8e-84a5-25ce41238c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# lda = PCA(n_components=800)\n",
    "# fused_data_train = lda.fit_transform(fused_data_train, y_train_60m_40f)\n",
    "# fused_data_test = lda.transform(fused_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7cada6ce-2050-45da-bb92-e796039ee72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 201)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fused_data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d17283a0-1a4d-41f3-80c4-3538651474b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_modal_NN():\n",
    "  model=Sequential()\n",
    "  model.add(Input(shape=(201)))\n",
    "  \n",
    "  model.add(Dense(2096))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dropout(0.4))\n",
    "\n",
    "  model.add(Dense(1024))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dropout(0.4))\n",
    "\n",
    "  model.add(Dense(8))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Activation('softmax'))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d75701ae-700e-45b3-99c3-46b7267f959f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 201)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fused_data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6a8084f8-70d0-4187-9224-1ca3d3d48a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "192/192 [==============================] - 8s 26ms/step - loss: 1.1327 - accuracy: 0.7109 - val_loss: 0.7163 - val_accuracy: 0.8021\n",
      "Epoch 2/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 1.0090 - accuracy: 0.8047 - val_loss: 0.7064 - val_accuracy: 0.8177\n",
      "Epoch 3/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.9749 - accuracy: 0.7969 - val_loss: 0.7015 - val_accuracy: 0.7917\n",
      "Epoch 4/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.9091 - accuracy: 0.8086 - val_loss: 0.6610 - val_accuracy: 0.8125\n",
      "Epoch 5/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.8241 - accuracy: 0.8529 - val_loss: 0.6273 - val_accuracy: 0.8385\n",
      "Epoch 6/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.8541 - accuracy: 0.8216 - val_loss: 0.6291 - val_accuracy: 0.8125\n",
      "Epoch 7/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.7647 - accuracy: 0.8620 - val_loss: 0.6420 - val_accuracy: 0.8021\n",
      "Epoch 8/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.7791 - accuracy: 0.8490 - val_loss: 0.6100 - val_accuracy: 0.8125\n",
      "Epoch 9/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.7624 - accuracy: 0.8646 - val_loss: 0.5985 - val_accuracy: 0.8125\n",
      "Epoch 10/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.7179 - accuracy: 0.8724 - val_loss: 0.6231 - val_accuracy: 0.8073\n",
      "Epoch 11/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.6724 - accuracy: 0.8828 - val_loss: 0.6101 - val_accuracy: 0.8125\n",
      "Epoch 12/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.6463 - accuracy: 0.8893 - val_loss: 0.5892 - val_accuracy: 0.8177\n",
      "Epoch 13/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.6929 - accuracy: 0.8568 - val_loss: 0.5715 - val_accuracy: 0.8333\n",
      "Epoch 14/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.6570 - accuracy: 0.8776 - val_loss: 0.5316 - val_accuracy: 0.7969\n",
      "Epoch 15/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.6236 - accuracy: 0.8724 - val_loss: 0.5654 - val_accuracy: 0.8333\n",
      "Epoch 16/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.6446 - accuracy: 0.8724 - val_loss: 0.5324 - val_accuracy: 0.8281\n",
      "Epoch 17/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.6217 - accuracy: 0.8828 - val_loss: 0.5531 - val_accuracy: 0.8073\n",
      "Epoch 18/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.6177 - accuracy: 0.8854 - val_loss: 0.5875 - val_accuracy: 0.8073\n",
      "Epoch 19/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.5826 - accuracy: 0.8971 - val_loss: 0.5406 - val_accuracy: 0.8229\n",
      "Epoch 20/80\n",
      "192/192 [==============================] - 2s 13ms/step - loss: 0.5621 - accuracy: 0.9036 - val_loss: 0.5235 - val_accuracy: 0.8542\n",
      "Epoch 21/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.5375 - accuracy: 0.9010 - val_loss: 0.4996 - val_accuracy: 0.8385\n",
      "Epoch 22/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.5270 - accuracy: 0.9206 - val_loss: 0.5014 - val_accuracy: 0.8438\n",
      "Epoch 23/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.5235 - accuracy: 0.9232 - val_loss: 0.4900 - val_accuracy: 0.8333\n",
      "Epoch 24/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.4991 - accuracy: 0.9115 - val_loss: 0.4728 - val_accuracy: 0.8385\n",
      "Epoch 25/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.4731 - accuracy: 0.9336 - val_loss: 0.4721 - val_accuracy: 0.8438\n",
      "Epoch 26/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.4885 - accuracy: 0.9154 - val_loss: 0.4680 - val_accuracy: 0.8385\n",
      "Epoch 27/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.4949 - accuracy: 0.9089 - val_loss: 0.4841 - val_accuracy: 0.8438\n",
      "Epoch 28/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.4921 - accuracy: 0.9062 - val_loss: 0.4753 - val_accuracy: 0.8385\n",
      "Epoch 29/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.4679 - accuracy: 0.9102 - val_loss: 0.4734 - val_accuracy: 0.8438\n",
      "Epoch 30/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.4851 - accuracy: 0.9062 - val_loss: 0.4850 - val_accuracy: 0.8177\n",
      "Epoch 31/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.4592 - accuracy: 0.9167 - val_loss: 0.4798 - val_accuracy: 0.8333\n",
      "Epoch 32/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.3883 - accuracy: 0.9661 - val_loss: 0.5088 - val_accuracy: 0.8229\n",
      "Epoch 33/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.4025 - accuracy: 0.9362 - val_loss: 0.4804 - val_accuracy: 0.8385\n",
      "Epoch 34/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.4126 - accuracy: 0.9297 - val_loss: 0.4877 - val_accuracy: 0.8177\n",
      "Epoch 35/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.4046 - accuracy: 0.9505 - val_loss: 0.5321 - val_accuracy: 0.8021\n",
      "Epoch 36/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.4243 - accuracy: 0.9284 - val_loss: 0.5116 - val_accuracy: 0.8229\n",
      "Epoch 37/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.4271 - accuracy: 0.9336 - val_loss: 0.4987 - val_accuracy: 0.8281\n",
      "Epoch 38/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.4142 - accuracy: 0.9388 - val_loss: 0.4789 - val_accuracy: 0.8177\n",
      "Epoch 39/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.3839 - accuracy: 0.9479 - val_loss: 0.5023 - val_accuracy: 0.8281\n",
      "Epoch 40/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.3931 - accuracy: 0.9284 - val_loss: 0.4776 - val_accuracy: 0.8229\n",
      "Epoch 41/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.3921 - accuracy: 0.9349 - val_loss: 0.4733 - val_accuracy: 0.8281\n",
      "Epoch 42/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.3813 - accuracy: 0.9349 - val_loss: 0.4770 - val_accuracy: 0.8333\n",
      "Epoch 43/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.3812 - accuracy: 0.9388 - val_loss: 0.4849 - val_accuracy: 0.8073\n",
      "Epoch 44/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.3367 - accuracy: 0.9609 - val_loss: 0.4707 - val_accuracy: 0.8333\n",
      "Epoch 45/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.3577 - accuracy: 0.9466 - val_loss: 0.4575 - val_accuracy: 0.8281\n",
      "Epoch 46/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.3272 - accuracy: 0.9544 - val_loss: 0.4859 - val_accuracy: 0.8125\n",
      "Epoch 47/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.3503 - accuracy: 0.9518 - val_loss: 0.5219 - val_accuracy: 0.8125\n",
      "Epoch 48/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.3609 - accuracy: 0.9362 - val_loss: 0.4629 - val_accuracy: 0.8177\n",
      "Epoch 49/80\n",
      "192/192 [==============================] - 3s 16ms/step - loss: 0.3322 - accuracy: 0.9466 - val_loss: 0.4541 - val_accuracy: 0.8281\n",
      "Epoch 50/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.3329 - accuracy: 0.9414 - val_loss: 0.4665 - val_accuracy: 0.8177\n",
      "Epoch 51/80\n",
      "192/192 [==============================] - 3s 16ms/step - loss: 0.3676 - accuracy: 0.9414 - val_loss: 0.5136 - val_accuracy: 0.8125\n",
      "Epoch 52/80\n",
      "192/192 [==============================] - 3s 17ms/step - loss: 0.3265 - accuracy: 0.9466 - val_loss: 0.5044 - val_accuracy: 0.8125\n",
      "Epoch 53/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.3692 - accuracy: 0.9232 - val_loss: 0.5435 - val_accuracy: 0.7865\n",
      "Epoch 54/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.3150 - accuracy: 0.9557 - val_loss: 0.5065 - val_accuracy: 0.8125\n",
      "Epoch 55/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.2895 - accuracy: 0.9648 - val_loss: 0.5025 - val_accuracy: 0.8125\n",
      "Epoch 56/80\n",
      "192/192 [==============================] - 3s 16ms/step - loss: 0.3488 - accuracy: 0.9336 - val_loss: 0.4821 - val_accuracy: 0.8125\n",
      "Epoch 57/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.2865 - accuracy: 0.9609 - val_loss: 0.4540 - val_accuracy: 0.8333\n",
      "Epoch 58/80\n",
      "192/192 [==============================] - 3s 16ms/step - loss: 0.3231 - accuracy: 0.9518 - val_loss: 0.4542 - val_accuracy: 0.8385\n",
      "Epoch 59/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.2998 - accuracy: 0.9596 - val_loss: 0.4793 - val_accuracy: 0.8177\n",
      "Epoch 60/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.2984 - accuracy: 0.9544 - val_loss: 0.4746 - val_accuracy: 0.8177\n",
      "Epoch 61/80\n",
      "192/192 [==============================] - 3s 16ms/step - loss: 0.2816 - accuracy: 0.9505 - val_loss: 0.4721 - val_accuracy: 0.8021\n",
      "Epoch 62/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.3160 - accuracy: 0.9505 - val_loss: 0.4389 - val_accuracy: 0.8333\n",
      "Epoch 63/80\n",
      "192/192 [==============================] - 3s 16ms/step - loss: 0.2817 - accuracy: 0.9518 - val_loss: 0.4568 - val_accuracy: 0.8229\n",
      "Epoch 64/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.2672 - accuracy: 0.9596 - val_loss: 0.5087 - val_accuracy: 0.8438\n",
      "Epoch 65/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.2677 - accuracy: 0.9609 - val_loss: 0.5551 - val_accuracy: 0.8229\n",
      "Epoch 66/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.2823 - accuracy: 0.9492 - val_loss: 0.5018 - val_accuracy: 0.8281\n",
      "Epoch 67/80\n",
      "192/192 [==============================] - 3s 16ms/step - loss: 0.2507 - accuracy: 0.9701 - val_loss: 0.5066 - val_accuracy: 0.8073\n",
      "Epoch 68/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.3031 - accuracy: 0.9427 - val_loss: 0.4709 - val_accuracy: 0.8333\n",
      "Epoch 69/80\n",
      "192/192 [==============================] - 3s 16ms/step - loss: 0.3041 - accuracy: 0.9427 - val_loss: 0.4394 - val_accuracy: 0.8594\n",
      "Epoch 70/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.2632 - accuracy: 0.9674 - val_loss: 0.4410 - val_accuracy: 0.8281\n",
      "Epoch 71/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.2441 - accuracy: 0.9622 - val_loss: 0.4536 - val_accuracy: 0.8542\n",
      "Epoch 72/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.2644 - accuracy: 0.9635 - val_loss: 0.4640 - val_accuracy: 0.8385\n",
      "Epoch 73/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.2916 - accuracy: 0.9427 - val_loss: 0.4698 - val_accuracy: 0.8229\n",
      "Epoch 74/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.2641 - accuracy: 0.9596 - val_loss: 0.5074 - val_accuracy: 0.8229\n",
      "Epoch 75/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.2636 - accuracy: 0.9544 - val_loss: 0.5333 - val_accuracy: 0.8021\n",
      "Epoch 76/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.2679 - accuracy: 0.9557 - val_loss: 0.5045 - val_accuracy: 0.8125\n",
      "Epoch 77/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.2255 - accuracy: 0.9661 - val_loss: 0.5118 - val_accuracy: 0.8177\n",
      "Epoch 78/80\n",
      "192/192 [==============================] - 3s 16ms/step - loss: 0.2414 - accuracy: 0.9648 - val_loss: 0.5221 - val_accuracy: 0.8229\n",
      "Epoch 79/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.2422 - accuracy: 0.9557 - val_loss: 0.5348 - val_accuracy: 0.8385\n",
      "Epoch 80/80\n",
      "192/192 [==============================] - 3s 16ms/step - loss: 0.2219 - accuracy: 0.9661 - val_loss: 0.4969 - val_accuracy: 0.8229\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.7816 - accuracy: 0.7847\n",
      "Epoch 1/80\n",
      "192/192 [==============================] - 5s 16ms/step - loss: 1.2151 - accuracy: 0.6432 - val_loss: 0.0732 - val_accuracy: 1.0000\n",
      "Epoch 2/80\n",
      "192/192 [==============================] - 3s 16ms/step - loss: 1.0661 - accuracy: 0.7344 - val_loss: 0.0854 - val_accuracy: 1.0000\n",
      "Epoch 3/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.9803 - accuracy: 0.7969 - val_loss: 0.0888 - val_accuracy: 1.0000\n",
      "Epoch 4/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.9877 - accuracy: 0.7682 - val_loss: 0.0725 - val_accuracy: 1.0000\n",
      "Epoch 5/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.9525 - accuracy: 0.7760 - val_loss: 0.0806 - val_accuracy: 1.0000\n",
      "Epoch 6/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.9250 - accuracy: 0.7839 - val_loss: 0.0595 - val_accuracy: 1.0000\n",
      "Epoch 7/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.8418 - accuracy: 0.8268 - val_loss: 0.0682 - val_accuracy: 1.0000\n",
      "Epoch 8/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.8750 - accuracy: 0.8021 - val_loss: 0.0416 - val_accuracy: 1.0000\n",
      "Epoch 9/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.7864 - accuracy: 0.8229 - val_loss: 0.0490 - val_accuracy: 1.0000\n",
      "Epoch 10/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.7370 - accuracy: 0.8581 - val_loss: 0.0447 - val_accuracy: 1.0000\n",
      "Epoch 11/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.7321 - accuracy: 0.8464 - val_loss: 0.0381 - val_accuracy: 1.0000\n",
      "Epoch 12/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.7517 - accuracy: 0.8438 - val_loss: 0.0439 - val_accuracy: 1.0000\n",
      "Epoch 13/80\n",
      "192/192 [==============================] - 3s 16ms/step - loss: 0.7378 - accuracy: 0.8294 - val_loss: 0.0342 - val_accuracy: 1.0000\n",
      "Epoch 14/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.6837 - accuracy: 0.8490 - val_loss: 0.0330 - val_accuracy: 1.0000\n",
      "Epoch 15/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.6431 - accuracy: 0.8659 - val_loss: 0.0316 - val_accuracy: 1.0000\n",
      "Epoch 16/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.6213 - accuracy: 0.8906 - val_loss: 0.0305 - val_accuracy: 1.0000\n",
      "Epoch 17/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.6463 - accuracy: 0.8581 - val_loss: 0.0264 - val_accuracy: 1.0000\n",
      "Epoch 18/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.6291 - accuracy: 0.8802 - val_loss: 0.0214 - val_accuracy: 1.0000\n",
      "Epoch 19/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.5655 - accuracy: 0.8919 - val_loss: 0.0268 - val_accuracy: 1.0000\n",
      "Epoch 20/80\n",
      "192/192 [==============================] - 3s 16ms/step - loss: 0.6206 - accuracy: 0.8724 - val_loss: 0.0204 - val_accuracy: 1.0000\n",
      "Epoch 21/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.5841 - accuracy: 0.8854 - val_loss: 0.0195 - val_accuracy: 1.0000\n",
      "Epoch 22/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.6181 - accuracy: 0.8685 - val_loss: 0.0237 - val_accuracy: 1.0000\n",
      "Epoch 23/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.5709 - accuracy: 0.9023 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
      "Epoch 24/80\n",
      "192/192 [==============================] - 3s 16ms/step - loss: 0.5561 - accuracy: 0.8958 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 25/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.6234 - accuracy: 0.8633 - val_loss: 0.0330 - val_accuracy: 1.0000\n",
      "Epoch 26/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.5419 - accuracy: 0.9010 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
      "Epoch 27/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.5474 - accuracy: 0.8802 - val_loss: 0.0154 - val_accuracy: 1.0000\n",
      "Epoch 28/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.5029 - accuracy: 0.9076 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
      "Epoch 29/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.4735 - accuracy: 0.9258 - val_loss: 0.0179 - val_accuracy: 1.0000\n",
      "Epoch 30/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.4883 - accuracy: 0.9154 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
      "Epoch 31/80\n",
      "192/192 [==============================] - 3s 16ms/step - loss: 0.5299 - accuracy: 0.8854 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
      "Epoch 32/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.4758 - accuracy: 0.9271 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
      "Epoch 33/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.4827 - accuracy: 0.9128 - val_loss: 0.0145 - val_accuracy: 1.0000\n",
      "Epoch 34/80\n",
      "192/192 [==============================] - 3s 13ms/step - loss: 0.4811 - accuracy: 0.9102 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 35/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.4941 - accuracy: 0.9036 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
      "Epoch 36/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.4271 - accuracy: 0.9310 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
      "Epoch 37/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.4443 - accuracy: 0.9206 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
      "Epoch 38/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.4295 - accuracy: 0.9076 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
      "Epoch 39/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.4269 - accuracy: 0.9206 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
      "Epoch 40/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.4724 - accuracy: 0.9128 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
      "Epoch 41/80\n",
      "192/192 [==============================] - 3s 16ms/step - loss: 0.4624 - accuracy: 0.8984 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
      "Epoch 42/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.4373 - accuracy: 0.9141 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
      "Epoch 43/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.4330 - accuracy: 0.9154 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
      "Epoch 44/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.4392 - accuracy: 0.9167 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
      "Epoch 45/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.4172 - accuracy: 0.9206 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
      "Epoch 46/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.4230 - accuracy: 0.9180 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
      "Epoch 47/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.4486 - accuracy: 0.9128 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
      "Epoch 48/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.4451 - accuracy: 0.9062 - val_loss: 0.0147 - val_accuracy: 1.0000\n",
      "Epoch 49/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.3936 - accuracy: 0.9271 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 50/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.3905 - accuracy: 0.9388 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 51/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.3622 - accuracy: 0.9310 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
      "Epoch 52/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.3531 - accuracy: 0.9401 - val_loss: 0.0117 - val_accuracy: 1.0000\n",
      "Epoch 53/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.3579 - accuracy: 0.9401 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
      "Epoch 54/80\n",
      "192/192 [==============================] - 3s 16ms/step - loss: 0.3994 - accuracy: 0.9141 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 55/80\n",
      "192/192 [==============================] - 3s 16ms/step - loss: 0.3285 - accuracy: 0.9440 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 56/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.3596 - accuracy: 0.9310 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
      "Epoch 57/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.3484 - accuracy: 0.9388 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 58/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.4191 - accuracy: 0.9167 - val_loss: 0.0104 - val_accuracy: 1.0000\n",
      "Epoch 59/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.3996 - accuracy: 0.9258 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
      "Epoch 60/80\n",
      "192/192 [==============================] - 3s 16ms/step - loss: 0.3974 - accuracy: 0.9141 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
      "Epoch 61/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.3882 - accuracy: 0.9310 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 62/80\n",
      "192/192 [==============================] - 3s 13ms/step - loss: 0.3085 - accuracy: 0.9583 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 63/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.3458 - accuracy: 0.9401 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 64/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.3944 - accuracy: 0.9232 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 65/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.3116 - accuracy: 0.9505 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
      "Epoch 66/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.3411 - accuracy: 0.9284 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 67/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.3588 - accuracy: 0.9349 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 68/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.3589 - accuracy: 0.9310 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 69/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.3356 - accuracy: 0.9349 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 70/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.3763 - accuracy: 0.9271 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 71/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.3312 - accuracy: 0.9440 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 72/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.2963 - accuracy: 0.9544 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 73/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.3409 - accuracy: 0.9401 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 74/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.3314 - accuracy: 0.9414 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 75/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.3429 - accuracy: 0.9297 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 76/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.3255 - accuracy: 0.9323 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 77/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.3557 - accuracy: 0.9245 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 78/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.2854 - accuracy: 0.9479 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 79/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.2698 - accuracy: 0.9544 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 80/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.3557 - accuracy: 0.9323 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "9/9 [==============================] - 1s 6ms/step - loss: 0.7127 - accuracy: 0.7882\n",
      "Epoch 1/80\n",
      "192/192 [==============================] - 6s 18ms/step - loss: 1.2169 - accuracy: 0.6615 - val_loss: 0.2788 - val_accuracy: 0.9583\n",
      "Epoch 2/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 1.0561 - accuracy: 0.7565 - val_loss: 0.2419 - val_accuracy: 0.9792\n",
      "Epoch 3/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.9836 - accuracy: 0.7826 - val_loss: 0.2878 - val_accuracy: 0.9635\n",
      "Epoch 4/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.9605 - accuracy: 0.8021 - val_loss: 0.2850 - val_accuracy: 0.9531\n",
      "Epoch 5/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.8885 - accuracy: 0.8294 - val_loss: 0.2843 - val_accuracy: 0.9583\n",
      "Epoch 6/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.8745 - accuracy: 0.8294 - val_loss: 0.2670 - val_accuracy: 0.9635\n",
      "Epoch 7/80\n",
      "192/192 [==============================] - 3s 13ms/step - loss: 0.8410 - accuracy: 0.8151 - val_loss: 0.2691 - val_accuracy: 0.9583\n",
      "Epoch 8/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.7961 - accuracy: 0.8529 - val_loss: 0.2351 - val_accuracy: 0.9635\n",
      "Epoch 9/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.7621 - accuracy: 0.8464 - val_loss: 0.2327 - val_accuracy: 0.9427\n",
      "Epoch 10/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.7385 - accuracy: 0.8477 - val_loss: 0.1976 - val_accuracy: 0.9635\n",
      "Epoch 11/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.7178 - accuracy: 0.8477 - val_loss: 0.2294 - val_accuracy: 0.9375\n",
      "Epoch 12/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.7123 - accuracy: 0.8555 - val_loss: 0.2429 - val_accuracy: 0.9271\n",
      "Epoch 13/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.7169 - accuracy: 0.8672 - val_loss: 0.2905 - val_accuracy: 0.9115\n",
      "Epoch 14/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.6776 - accuracy: 0.8568 - val_loss: 0.2747 - val_accuracy: 0.9375\n",
      "Epoch 15/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.7002 - accuracy: 0.8424 - val_loss: 0.2814 - val_accuracy: 0.9219\n",
      "Epoch 16/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.6408 - accuracy: 0.8711 - val_loss: 0.3113 - val_accuracy: 0.9219\n",
      "Epoch 17/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.6547 - accuracy: 0.8568 - val_loss: 0.2801 - val_accuracy: 0.9271\n",
      "Epoch 18/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.6381 - accuracy: 0.8685 - val_loss: 0.2787 - val_accuracy: 0.9427\n",
      "Epoch 19/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.5805 - accuracy: 0.8932 - val_loss: 0.2976 - val_accuracy: 0.9271\n",
      "Epoch 20/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.6208 - accuracy: 0.8633 - val_loss: 0.2633 - val_accuracy: 0.9323\n",
      "Epoch 21/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.5449 - accuracy: 0.8971 - val_loss: 0.2693 - val_accuracy: 0.9167\n",
      "Epoch 22/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.5724 - accuracy: 0.8880 - val_loss: 0.2983 - val_accuracy: 0.9115\n",
      "Epoch 23/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.5422 - accuracy: 0.9167 - val_loss: 0.2647 - val_accuracy: 0.9375\n",
      "Epoch 24/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.5397 - accuracy: 0.9062 - val_loss: 0.2853 - val_accuracy: 0.9219\n",
      "Epoch 25/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.5274 - accuracy: 0.9062 - val_loss: 0.2607 - val_accuracy: 0.9271\n",
      "Epoch 26/80\n",
      "192/192 [==============================] - 3s 16ms/step - loss: 0.5079 - accuracy: 0.9128 - val_loss: 0.2548 - val_accuracy: 0.9219\n",
      "Epoch 27/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.5191 - accuracy: 0.8984 - val_loss: 0.3061 - val_accuracy: 0.9219\n",
      "Epoch 28/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.4846 - accuracy: 0.9115 - val_loss: 0.2768 - val_accuracy: 0.9427\n",
      "Epoch 29/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.4993 - accuracy: 0.9036 - val_loss: 0.3026 - val_accuracy: 0.9115\n",
      "Epoch 30/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.4974 - accuracy: 0.9141 - val_loss: 0.2735 - val_accuracy: 0.9115\n",
      "Epoch 31/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.4874 - accuracy: 0.8971 - val_loss: 0.2906 - val_accuracy: 0.9115\n",
      "Epoch 32/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.4451 - accuracy: 0.9062 - val_loss: 0.2849 - val_accuracy: 0.9167\n",
      "Epoch 33/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.5165 - accuracy: 0.9089 - val_loss: 0.2996 - val_accuracy: 0.9323\n",
      "Epoch 34/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.4660 - accuracy: 0.9128 - val_loss: 0.2890 - val_accuracy: 0.9375\n",
      "Epoch 35/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.4440 - accuracy: 0.9167 - val_loss: 0.2831 - val_accuracy: 0.9323\n",
      "Epoch 36/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.4477 - accuracy: 0.9128 - val_loss: 0.2976 - val_accuracy: 0.9115\n",
      "Epoch 37/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.4733 - accuracy: 0.9141 - val_loss: 0.2843 - val_accuracy: 0.9167\n",
      "Epoch 38/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.4192 - accuracy: 0.9336 - val_loss: 0.2838 - val_accuracy: 0.9115\n",
      "Epoch 39/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.4162 - accuracy: 0.9323 - val_loss: 0.2899 - val_accuracy: 0.9010\n",
      "Epoch 40/80\n",
      "192/192 [==============================] - 3s 13ms/step - loss: 0.4218 - accuracy: 0.9193 - val_loss: 0.2983 - val_accuracy: 0.9062\n",
      "Epoch 41/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.4122 - accuracy: 0.9388 - val_loss: 0.2772 - val_accuracy: 0.9167\n",
      "Epoch 42/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.4855 - accuracy: 0.8945 - val_loss: 0.2748 - val_accuracy: 0.9115\n",
      "Epoch 43/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.4091 - accuracy: 0.9349 - val_loss: 0.2960 - val_accuracy: 0.8958\n",
      "Epoch 44/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.3546 - accuracy: 0.9479 - val_loss: 0.2454 - val_accuracy: 0.9219\n",
      "Epoch 45/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.3692 - accuracy: 0.9336 - val_loss: 0.2534 - val_accuracy: 0.9167\n",
      "Epoch 46/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.3727 - accuracy: 0.9414 - val_loss: 0.3029 - val_accuracy: 0.9010\n",
      "Epoch 47/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.3957 - accuracy: 0.9271 - val_loss: 0.3236 - val_accuracy: 0.8906\n",
      "Epoch 48/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.3723 - accuracy: 0.9479 - val_loss: 0.3235 - val_accuracy: 0.8750\n",
      "Epoch 49/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.3573 - accuracy: 0.9544 - val_loss: 0.3244 - val_accuracy: 0.8906\n",
      "Epoch 50/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.4032 - accuracy: 0.9232 - val_loss: 0.3367 - val_accuracy: 0.8906\n",
      "Epoch 51/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.4696 - accuracy: 0.9154 - val_loss: 0.2972 - val_accuracy: 0.9062\n",
      "Epoch 52/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.3830 - accuracy: 0.9284 - val_loss: 0.2552 - val_accuracy: 0.9323\n",
      "Epoch 53/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.4049 - accuracy: 0.9258 - val_loss: 0.3139 - val_accuracy: 0.9062\n",
      "Epoch 54/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.3985 - accuracy: 0.9089 - val_loss: 0.3193 - val_accuracy: 0.8854\n",
      "Epoch 55/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.3903 - accuracy: 0.9232 - val_loss: 0.3320 - val_accuracy: 0.8854\n",
      "Epoch 56/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.3339 - accuracy: 0.9492 - val_loss: 0.2980 - val_accuracy: 0.8854\n",
      "Epoch 57/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.3337 - accuracy: 0.9375 - val_loss: 0.3135 - val_accuracy: 0.9010\n",
      "Epoch 58/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.3254 - accuracy: 0.9479 - val_loss: 0.2778 - val_accuracy: 0.9115\n",
      "Epoch 59/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.2972 - accuracy: 0.9557 - val_loss: 0.2898 - val_accuracy: 0.9062\n",
      "Epoch 60/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.3438 - accuracy: 0.9427 - val_loss: 0.3048 - val_accuracy: 0.9062\n",
      "Epoch 61/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.3160 - accuracy: 0.9375 - val_loss: 0.3330 - val_accuracy: 0.8854\n",
      "Epoch 62/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.3600 - accuracy: 0.9245 - val_loss: 0.2829 - val_accuracy: 0.9062\n",
      "Epoch 63/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.3107 - accuracy: 0.9544 - val_loss: 0.2849 - val_accuracy: 0.9010\n",
      "Epoch 64/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.3285 - accuracy: 0.9388 - val_loss: 0.3010 - val_accuracy: 0.9062\n",
      "Epoch 65/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.2878 - accuracy: 0.9453 - val_loss: 0.3103 - val_accuracy: 0.9010\n",
      "Epoch 66/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.3028 - accuracy: 0.9388 - val_loss: 0.2704 - val_accuracy: 0.9062\n",
      "Epoch 67/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.3303 - accuracy: 0.9401 - val_loss: 0.2775 - val_accuracy: 0.9010\n",
      "Epoch 68/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.3459 - accuracy: 0.9258 - val_loss: 0.2982 - val_accuracy: 0.9010\n",
      "Epoch 69/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.2896 - accuracy: 0.9453 - val_loss: 0.2649 - val_accuracy: 0.9010\n",
      "Epoch 70/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.3064 - accuracy: 0.9440 - val_loss: 0.2866 - val_accuracy: 0.9010\n",
      "Epoch 71/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.2958 - accuracy: 0.9479 - val_loss: 0.2363 - val_accuracy: 0.9062\n",
      "Epoch 72/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.3444 - accuracy: 0.9245 - val_loss: 0.2625 - val_accuracy: 0.9062\n",
      "Epoch 73/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.2820 - accuracy: 0.9518 - val_loss: 0.2784 - val_accuracy: 0.9167\n",
      "Epoch 74/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.2965 - accuracy: 0.9427 - val_loss: 0.2834 - val_accuracy: 0.9115\n",
      "Epoch 75/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.2698 - accuracy: 0.9609 - val_loss: 0.2671 - val_accuracy: 0.9115\n",
      "Epoch 76/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.2848 - accuracy: 0.9414 - val_loss: 0.2878 - val_accuracy: 0.9167\n",
      "Epoch 77/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.2719 - accuracy: 0.9466 - val_loss: 0.2807 - val_accuracy: 0.9219\n",
      "Epoch 78/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.2538 - accuracy: 0.9688 - val_loss: 0.2940 - val_accuracy: 0.9219\n",
      "Epoch 79/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.2786 - accuracy: 0.9583 - val_loss: 0.3026 - val_accuracy: 0.9115\n",
      "Epoch 80/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.2899 - accuracy: 0.9505 - val_loss: 0.2953 - val_accuracy: 0.9062\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7316 - accuracy: 0.7778\n",
      "Epoch 1/80\n",
      "192/192 [==============================] - 4s 13ms/step - loss: 1.2056 - accuracy: 0.6471 - val_loss: 0.0759 - val_accuracy: 1.0000\n",
      "Epoch 2/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 1.0920 - accuracy: 0.7122 - val_loss: 0.0795 - val_accuracy: 1.0000\n",
      "Epoch 3/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 1.0234 - accuracy: 0.7552 - val_loss: 0.0891 - val_accuracy: 1.0000\n",
      "Epoch 4/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.9474 - accuracy: 0.7852 - val_loss: 0.0748 - val_accuracy: 1.0000\n",
      "Epoch 5/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.9025 - accuracy: 0.8203 - val_loss: 0.0710 - val_accuracy: 1.0000\n",
      "Epoch 6/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.9009 - accuracy: 0.8320 - val_loss: 0.0615 - val_accuracy: 1.0000\n",
      "Epoch 7/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.8233 - accuracy: 0.8359 - val_loss: 0.0524 - val_accuracy: 1.0000\n",
      "Epoch 8/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.8425 - accuracy: 0.8229 - val_loss: 0.0506 - val_accuracy: 1.0000\n",
      "Epoch 9/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.7773 - accuracy: 0.8464 - val_loss: 0.0457 - val_accuracy: 1.0000\n",
      "Epoch 10/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.7732 - accuracy: 0.8359 - val_loss: 0.0352 - val_accuracy: 1.0000\n",
      "Epoch 11/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.7603 - accuracy: 0.8359 - val_loss: 0.0359 - val_accuracy: 1.0000\n",
      "Epoch 12/80\n",
      "192/192 [==============================] - 3s 17ms/step - loss: 0.7138 - accuracy: 0.8763 - val_loss: 0.0312 - val_accuracy: 1.0000\n",
      "Epoch 13/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.6946 - accuracy: 0.8646 - val_loss: 0.0278 - val_accuracy: 1.0000\n",
      "Epoch 14/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.7361 - accuracy: 0.8294 - val_loss: 0.0343 - val_accuracy: 1.0000\n",
      "Epoch 15/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.6623 - accuracy: 0.8698 - val_loss: 0.0293 - val_accuracy: 1.0000\n",
      "Epoch 16/80\n",
      "192/192 [==============================] - 4s 20ms/step - loss: 0.6937 - accuracy: 0.8490 - val_loss: 0.0229 - val_accuracy: 1.0000\n",
      "Epoch 17/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.6637 - accuracy: 0.8672 - val_loss: 0.0218 - val_accuracy: 1.0000\n",
      "Epoch 18/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.6452 - accuracy: 0.8633 - val_loss: 0.0215 - val_accuracy: 1.0000\n",
      "Epoch 19/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.6497 - accuracy: 0.8607 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
      "Epoch 20/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.6185 - accuracy: 0.8711 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
      "Epoch 21/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.5810 - accuracy: 0.8776 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
      "Epoch 22/80\n",
      "192/192 [==============================] - 3s 17ms/step - loss: 0.5802 - accuracy: 0.8776 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
      "Epoch 23/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.6134 - accuracy: 0.8763 - val_loss: 0.0141 - val_accuracy: 1.0000\n",
      "Epoch 24/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.5335 - accuracy: 0.8945 - val_loss: 0.0134 - val_accuracy: 1.0000\n",
      "Epoch 25/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.5993 - accuracy: 0.8867 - val_loss: 0.0153 - val_accuracy: 1.0000\n",
      "Epoch 26/80\n",
      "192/192 [==============================] - 4s 18ms/step - loss: 0.5743 - accuracy: 0.8789 - val_loss: 0.0136 - val_accuracy: 1.0000\n",
      "Epoch 27/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.5323 - accuracy: 0.8919 - val_loss: 0.0158 - val_accuracy: 1.0000\n",
      "Epoch 28/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.5196 - accuracy: 0.8932 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
      "Epoch 29/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.4926 - accuracy: 0.9036 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
      "Epoch 30/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.4927 - accuracy: 0.8971 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
      "Epoch 31/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.4992 - accuracy: 0.8984 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 32/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.5388 - accuracy: 0.8815 - val_loss: 0.0139 - val_accuracy: 1.0000\n",
      "Epoch 33/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.5097 - accuracy: 0.9076 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "Epoch 34/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.5185 - accuracy: 0.8854 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 35/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.4853 - accuracy: 0.9089 - val_loss: 0.0171 - val_accuracy: 1.0000\n",
      "Epoch 36/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.4973 - accuracy: 0.9023 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
      "Epoch 37/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.5010 - accuracy: 0.8919 - val_loss: 0.0192 - val_accuracy: 1.0000\n",
      "Epoch 38/80\n",
      "192/192 [==============================] - 4s 20ms/step - loss: 0.4480 - accuracy: 0.9245 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
      "Epoch 39/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.4577 - accuracy: 0.9089 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
      "Epoch 40/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.4477 - accuracy: 0.9167 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
      "Epoch 41/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.4343 - accuracy: 0.9076 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
      "Epoch 42/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.4299 - accuracy: 0.9258 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
      "Epoch 43/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.4516 - accuracy: 0.9089 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
      "Epoch 44/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.4591 - accuracy: 0.9023 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
      "Epoch 45/80\n",
      "192/192 [==============================] - 4s 18ms/step - loss: 0.4031 - accuracy: 0.9271 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
      "Epoch 46/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.4299 - accuracy: 0.9115 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
      "Epoch 47/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.3798 - accuracy: 0.9284 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
      "Epoch 48/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.3890 - accuracy: 0.9245 - val_loss: 0.0100 - val_accuracy: 1.0000\n",
      "Epoch 49/80\n",
      "192/192 [==============================] - 4s 18ms/step - loss: 0.4064 - accuracy: 0.9232 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 50/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.3677 - accuracy: 0.9297 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 51/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.3830 - accuracy: 0.9284 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 52/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.3908 - accuracy: 0.9206 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "Epoch 53/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.3946 - accuracy: 0.9336 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 54/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.3934 - accuracy: 0.9258 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
      "Epoch 55/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.3873 - accuracy: 0.9219 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
      "Epoch 56/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.3832 - accuracy: 0.9336 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 57/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.3594 - accuracy: 0.9271 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
      "Epoch 58/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.3629 - accuracy: 0.9375 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 59/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.4123 - accuracy: 0.9076 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 60/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.3844 - accuracy: 0.9232 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
      "Epoch 61/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.3678 - accuracy: 0.9336 - val_loss: 0.0082 - val_accuracy: 1.0000\n",
      "Epoch 62/80\n",
      "192/192 [==============================] - 2s 13ms/step - loss: 0.3587 - accuracy: 0.9323 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 63/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.3615 - accuracy: 0.9271 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 64/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.3481 - accuracy: 0.9323 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 65/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.3405 - accuracy: 0.9271 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 66/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.3565 - accuracy: 0.9336 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 67/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.3377 - accuracy: 0.9323 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 68/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.3091 - accuracy: 0.9388 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
      "Epoch 69/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.3387 - accuracy: 0.9310 - val_loss: 0.0080 - val_accuracy: 1.0000\n",
      "Epoch 70/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.3767 - accuracy: 0.9258 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 71/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.4022 - accuracy: 0.9362 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 72/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.3336 - accuracy: 0.9414 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
      "Epoch 73/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.3150 - accuracy: 0.9323 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
      "Epoch 74/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.3079 - accuracy: 0.9479 - val_loss: 0.0072 - val_accuracy: 1.0000\n",
      "Epoch 75/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.2954 - accuracy: 0.9479 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 76/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.3212 - accuracy: 0.9427 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 77/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.2769 - accuracy: 0.9648 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 78/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.3041 - accuracy: 0.9427 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 79/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.3278 - accuracy: 0.9440 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 80/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.3194 - accuracy: 0.9271 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 0.7607 - accuracy: 0.7743\n",
      "Epoch 1/80\n",
      "192/192 [==============================] - 4s 13ms/step - loss: 1.2189 - accuracy: 0.6133 - val_loss: 0.0634 - val_accuracy: 1.0000\n",
      "Epoch 2/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 1.0823 - accuracy: 0.7083 - val_loss: 0.0869 - val_accuracy: 1.0000\n",
      "Epoch 3/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 1.0157 - accuracy: 0.7708 - val_loss: 0.0680 - val_accuracy: 1.0000\n",
      "Epoch 4/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.9950 - accuracy: 0.7656 - val_loss: 0.0747 - val_accuracy: 1.0000\n",
      "Epoch 5/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.9582 - accuracy: 0.7799 - val_loss: 0.0651 - val_accuracy: 1.0000\n",
      "Epoch 6/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.8914 - accuracy: 0.8138 - val_loss: 0.0615 - val_accuracy: 1.0000\n",
      "Epoch 7/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.8799 - accuracy: 0.8190 - val_loss: 0.0489 - val_accuracy: 1.0000\n",
      "Epoch 8/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.8159 - accuracy: 0.8164 - val_loss: 0.0479 - val_accuracy: 1.0000\n",
      "Epoch 9/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.7640 - accuracy: 0.8333 - val_loss: 0.0430 - val_accuracy: 1.0000\n",
      "Epoch 10/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.7674 - accuracy: 0.8424 - val_loss: 0.0451 - val_accuracy: 1.0000\n",
      "Epoch 11/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.7949 - accuracy: 0.8190 - val_loss: 0.0534 - val_accuracy: 1.0000\n",
      "Epoch 12/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.7164 - accuracy: 0.8516 - val_loss: 0.0467 - val_accuracy: 1.0000\n",
      "Epoch 13/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.6884 - accuracy: 0.8607 - val_loss: 0.0349 - val_accuracy: 1.0000\n",
      "Epoch 14/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.7152 - accuracy: 0.8451 - val_loss: 0.0338 - val_accuracy: 1.0000\n",
      "Epoch 15/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.6893 - accuracy: 0.8385 - val_loss: 0.0353 - val_accuracy: 1.0000\n",
      "Epoch 16/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.6556 - accuracy: 0.8464 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
      "Epoch 17/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.6912 - accuracy: 0.8385 - val_loss: 0.0437 - val_accuracy: 0.9896\n",
      "Epoch 18/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.6801 - accuracy: 0.8190 - val_loss: 0.0402 - val_accuracy: 0.9948\n",
      "Epoch 19/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.6506 - accuracy: 0.8346 - val_loss: 0.0233 - val_accuracy: 1.0000\n",
      "Epoch 20/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.5920 - accuracy: 0.8828 - val_loss: 0.0224 - val_accuracy: 1.0000\n",
      "Epoch 21/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.5734 - accuracy: 0.8945 - val_loss: 0.0272 - val_accuracy: 1.0000\n",
      "Epoch 22/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.6058 - accuracy: 0.8737 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
      "Epoch 23/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.5837 - accuracy: 0.8854 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 24/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.6341 - accuracy: 0.8750 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
      "Epoch 25/80\n",
      "192/192 [==============================] - 2s 11ms/step - loss: 0.5628 - accuracy: 0.8945 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
      "Epoch 26/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.5328 - accuracy: 0.8880 - val_loss: 0.0202 - val_accuracy: 1.0000\n",
      "Epoch 27/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.5772 - accuracy: 0.8737 - val_loss: 0.0196 - val_accuracy: 1.0000\n",
      "Epoch 28/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.5745 - accuracy: 0.8776 - val_loss: 0.0210 - val_accuracy: 1.0000\n",
      "Epoch 29/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.4876 - accuracy: 0.9102 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
      "Epoch 30/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.4863 - accuracy: 0.9128 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
      "Epoch 31/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.5231 - accuracy: 0.8815 - val_loss: 0.0195 - val_accuracy: 1.0000\n",
      "Epoch 32/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.5308 - accuracy: 0.8789 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
      "Epoch 33/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.4871 - accuracy: 0.9010 - val_loss: 0.0157 - val_accuracy: 1.0000\n",
      "Epoch 34/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.4788 - accuracy: 0.9102 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
      "Epoch 35/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.4783 - accuracy: 0.9102 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
      "Epoch 36/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.5062 - accuracy: 0.8841 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
      "Epoch 37/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.4584 - accuracy: 0.9141 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
      "Epoch 38/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.4374 - accuracy: 0.9102 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
      "Epoch 39/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.4605 - accuracy: 0.8997 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
      "Epoch 40/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.4971 - accuracy: 0.8854 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
      "Epoch 41/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.4174 - accuracy: 0.9297 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
      "Epoch 42/80\n",
      "192/192 [==============================] - 3s 13ms/step - loss: 0.4492 - accuracy: 0.9193 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
      "Epoch 43/80\n",
      "192/192 [==============================] - 3s 13ms/step - loss: 0.3817 - accuracy: 0.9336 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
      "Epoch 44/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.3918 - accuracy: 0.9336 - val_loss: 0.0131 - val_accuracy: 1.0000\n",
      "Epoch 45/80\n",
      "192/192 [==============================] - 3s 13ms/step - loss: 0.4487 - accuracy: 0.8984 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
      "Epoch 46/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.4598 - accuracy: 0.8997 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 47/80\n",
      "192/192 [==============================] - 3s 13ms/step - loss: 0.4292 - accuracy: 0.9258 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 48/80\n",
      "192/192 [==============================] - 3s 13ms/step - loss: 0.4054 - accuracy: 0.9049 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
      "Epoch 49/80\n",
      "192/192 [==============================] - 3s 13ms/step - loss: 0.3906 - accuracy: 0.9284 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
      "Epoch 50/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.4213 - accuracy: 0.9180 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 51/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.4264 - accuracy: 0.9180 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
      "Epoch 52/80\n",
      "192/192 [==============================] - 3s 13ms/step - loss: 0.4017 - accuracy: 0.9154 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 53/80\n",
      "192/192 [==============================] - 3s 13ms/step - loss: 0.3951 - accuracy: 0.9193 - val_loss: 0.0101 - val_accuracy: 1.0000\n",
      "Epoch 54/80\n",
      "192/192 [==============================] - 3s 13ms/step - loss: 0.3669 - accuracy: 0.9427 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
      "Epoch 55/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.3761 - accuracy: 0.9284 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "Epoch 56/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.3911 - accuracy: 0.9180 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "Epoch 57/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.3410 - accuracy: 0.9440 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
      "Epoch 58/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.3639 - accuracy: 0.9388 - val_loss: 0.0159 - val_accuracy: 0.9948\n",
      "Epoch 59/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.3728 - accuracy: 0.9219 - val_loss: 0.0130 - val_accuracy: 0.9948\n",
      "Epoch 60/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.3573 - accuracy: 0.9206 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 61/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.3669 - accuracy: 0.9284 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
      "Epoch 62/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.4296 - accuracy: 0.8997 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 63/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.3698 - accuracy: 0.9193 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 64/80\n",
      "192/192 [==============================] - 3s 18ms/step - loss: 0.3721 - accuracy: 0.9310 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
      "Epoch 65/80\n",
      "192/192 [==============================] - 3s 17ms/step - loss: 0.3325 - accuracy: 0.9440 - val_loss: 0.0104 - val_accuracy: 0.9948\n",
      "Epoch 66/80\n",
      "192/192 [==============================] - 3s 17ms/step - loss: 0.3300 - accuracy: 0.9349 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 67/80\n",
      "192/192 [==============================] - 3s 17ms/step - loss: 0.3225 - accuracy: 0.9492 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
      "Epoch 68/80\n",
      "192/192 [==============================] - 3s 16ms/step - loss: 0.3247 - accuracy: 0.9453 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 69/80\n",
      "192/192 [==============================] - 3s 16ms/step - loss: 0.3456 - accuracy: 0.9258 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 70/80\n",
      "192/192 [==============================] - 3s 16ms/step - loss: 0.3254 - accuracy: 0.9518 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 71/80\n",
      "192/192 [==============================] - 3s 16ms/step - loss: 0.3309 - accuracy: 0.9284 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 72/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.3466 - accuracy: 0.9310 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 73/80\n",
      "192/192 [==============================] - 3s 16ms/step - loss: 0.3561 - accuracy: 0.9310 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 74/80\n",
      "192/192 [==============================] - 3s 15ms/step - loss: 0.3214 - accuracy: 0.9453 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
      "Epoch 75/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.3127 - accuracy: 0.9479 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 76/80\n",
      "192/192 [==============================] - 3s 14ms/step - loss: 0.3418 - accuracy: 0.9258 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 77/80\n",
      "192/192 [==============================] - 2s 13ms/step - loss: 0.3523 - accuracy: 0.9219 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "Epoch 78/80\n",
      "192/192 [==============================] - 2s 13ms/step - loss: 0.2911 - accuracy: 0.9440 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 79/80\n",
      "192/192 [==============================] - 2s 12ms/step - loss: 0.3275 - accuracy: 0.9284 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 80/80\n",
      "192/192 [==============================] - 3s 13ms/step - loss: 0.3108 - accuracy: 0.9427 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7377 - accuracy: 0.7639\n"
     ]
    }
   ],
   "source": [
    "VALIDATION_ACCURACY_SPEECH = []\n",
    "VALIDATION_LOSS_SPEECH = []\n",
    "\n",
    "save_dir = os.path.abspath(DIR) + '/ravdess_50m50f_latefusion_PCA_n201_model/'\n",
    "fold_var = 1\n",
    "\n",
    "for train_idx, val_idx in kfold.split(fused_data_train, y_train_50m_50f):\n",
    "    model=multi_modal_NN()\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
    "\n",
    "    #early_stopping_callback = EarlyStopping(monitor = 'val_accuracy', patience = 15, restore_best_weights = True)\n",
    "\n",
    "    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(save_dir + get_model_name(fold_var), monitor='val_accuracy',save_best_only=True, mode='max')\n",
    "# Start training the model.\n",
    "    LRCN_model_training_history = model.fit(      x = fused_data_train[train_idx],\n",
    "                                                  y = y_train_50m_50f[train_idx],\n",
    "                                                  validation_data=(fused_data_train[val_idx], y_train_50m_50f[val_idx]),\n",
    "                                                  epochs = 80,\n",
    "                                                  batch_size = 4,\n",
    "                                                  shuffle = True,\n",
    "                                                  callbacks = [checkpoint_cb])\n",
    "    model.load_weights(save_dir + \"model_\" + str(fold_var) + \".h5\")\n",
    "\t\n",
    "    results = model.evaluate(fused_data_test, y_test)\n",
    "    results = dict(zip(model.metrics_names, results))\n",
    "\t\n",
    "    VALIDATION_ACCURACY_SPEECH.append(results['accuracy'])\n",
    "    VALIDATION_LOSS_SPEECH.append(results['loss'])\n",
    "\t\n",
    "    tf.keras.backend.clear_session()\n",
    "\t\n",
    "    fold_var += 1\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6288c6-6ccd-4a2f-87c5-585a928b16d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "549e4c38-6592-40fd-8ee9-2b72e7c390c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 20, 48, 48)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_60m_40f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "86d09136-1155-4a41-a4cf-bca07e116e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 128, 128, 3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_aud_60m_40f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "727b2ea2-d525-496e-8ee3-a6d92b4256c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 49152)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_flattened = np.reshape(X_train_60m_40f, (960, -1))\n",
    "\n",
    "X_train_aud_flattened = np.reshape(X_train_aud_60m_40f, (960, -1))\n",
    "X_train_aud_flattened.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ece60c9c-5d56-47f8-9eed-2e715f2f6af9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 46080)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_flattened.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2b70a0b0-40cf-4c77-b9fb-0164d5569e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 49152)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_flattened = np.reshape(X_test, (288, -1))\n",
    "\n",
    "X_test_aud_flattened = np.reshape(X_test_aud, (288, -1))\n",
    "X_test_aud_flattened.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a0e4ef2d-bd79-4370-bd92-d8d8d8807ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "video_scaler = StandardScaler().fit(X_train_flattened)\n",
    "video_data_standardized = video_scaler.fit_transform(X_train_flattened)\n",
    "video_data_standardized_test = video_scaler.fit_transform(X_test_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "916084e5-868f-4ed0-936b-5df95d4a3c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 46080)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_data_standardized_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "31a67b01-942e-46df-b1aa-47ee4fa3bccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_scaler = StandardScaler().fit(X_train_aud_flattened)\n",
    "audio_data_standardized = audio_scaler.fit_transform(X_train_aud_flattened)\n",
    "audio_data_standardized_test = audio_scaler.fit_transform(X_test_aud_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "28b4ff0a-198a-417f-b101-cb98aaf168b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 49152)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_data_standardized_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0db29459-8a86-4d54-98c4-5ad675c272b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca_video = PCA(n_components=0.95).fit(video_data_standardized)\n",
    "video_data_pca = pca_video.fit_transform(video_data_standardized)\n",
    "video_data_pca_test = pca_video.transform(video_data_standardized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b639e5ac-cae9-4317-aeb5-469bfff307c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 645)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_data_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f0b867e4-c747-4f2a-ad37-b4fd587d5f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_audio = PCA(n_components=0.95).fit(audio_data_standardized)\n",
    "audio_data_pca = pca_audio.fit_transform(audio_data_standardized)\n",
    "audio_data_pca_test = pca_audio.transform(audio_data_standardized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aab3d768-7809-45bc-8ee0-dfec912cf4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 313)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_data_pca_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7409b3cf-0c2f-4faa-956e-517cef48d72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_train_data = np.concatenate((video_data_pca, audio_data_pca), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fd2e85b5-4c83-4af7-b185-5e3781120cfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 958)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "835104e7-3403-4a98-b031-57d6fab655ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_test_data = np.concatenate((video_data_pca_test, audio_data_pca_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "515893bf-1508-46b8-a376-b9f30a936454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 958)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6cca618f-1e46-4977-8a4b-87001e3fa5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_modal_NN():\n",
    "  model=Sequential()\n",
    "  model.add(Input(shape=(958)))\n",
    "  \n",
    "  model.add(Dense(2096))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dropout(0.4))\n",
    "\n",
    "  model.add(Dense(1024))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dropout(0.4))\n",
    "\n",
    "  model.add(Dense(8))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Activation('softmax'))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e1c265c4-1674-44ee-9951-0b66f5b0562f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "192/192 [==============================] - 9s 34ms/step - loss: 2.0735 - accuracy: 0.2305 - val_loss: 1.5004 - val_accuracy: 0.5677\n",
      "Epoch 2/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 1.5786 - accuracy: 0.4375 - val_loss: 1.2848 - val_accuracy: 0.5521\n",
      "Epoch 3/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 1.4038 - accuracy: 0.4909 - val_loss: 1.2341 - val_accuracy: 0.5938\n",
      "Epoch 4/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 1.3574 - accuracy: 0.4987 - val_loss: 1.1374 - val_accuracy: 0.6615\n",
      "Epoch 5/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 1.2244 - accuracy: 0.5885 - val_loss: 1.0988 - val_accuracy: 0.6823\n",
      "Epoch 6/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 1.1255 - accuracy: 0.6523 - val_loss: 1.1017 - val_accuracy: 0.6667\n",
      "Epoch 7/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 1.0749 - accuracy: 0.6706 - val_loss: 1.1064 - val_accuracy: 0.6146\n",
      "Epoch 8/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 1.0988 - accuracy: 0.6367 - val_loss: 1.0540 - val_accuracy: 0.6510\n",
      "Epoch 9/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 1.0564 - accuracy: 0.6628 - val_loss: 1.0629 - val_accuracy: 0.6406\n",
      "Epoch 10/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 1.0079 - accuracy: 0.7005 - val_loss: 1.0408 - val_accuracy: 0.6354\n",
      "Epoch 11/80\n",
      "192/192 [==============================] - 6s 34ms/step - loss: 0.9746 - accuracy: 0.7109 - val_loss: 1.0757 - val_accuracy: 0.6354\n",
      "Epoch 12/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.9521 - accuracy: 0.7109 - val_loss: 1.0259 - val_accuracy: 0.6771\n",
      "Epoch 13/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.9405 - accuracy: 0.7227 - val_loss: 0.9943 - val_accuracy: 0.6719\n",
      "Epoch 14/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.8596 - accuracy: 0.7591 - val_loss: 1.0194 - val_accuracy: 0.6562\n",
      "Epoch 15/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.8932 - accuracy: 0.7383 - val_loss: 0.9791 - val_accuracy: 0.6719\n",
      "Epoch 16/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.8702 - accuracy: 0.7435 - val_loss: 1.0491 - val_accuracy: 0.6198\n",
      "Epoch 17/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.8663 - accuracy: 0.7682 - val_loss: 1.0719 - val_accuracy: 0.6719\n",
      "Epoch 18/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.8386 - accuracy: 0.7682 - val_loss: 1.0362 - val_accuracy: 0.6458\n",
      "Epoch 19/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.8093 - accuracy: 0.7630 - val_loss: 1.0332 - val_accuracy: 0.6302\n",
      "Epoch 20/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.7887 - accuracy: 0.7943 - val_loss: 1.0448 - val_accuracy: 0.6719\n",
      "Epoch 21/80\n",
      "192/192 [==============================] - 5s 29ms/step - loss: 0.7752 - accuracy: 0.7917 - val_loss: 1.0139 - val_accuracy: 0.6875\n",
      "Epoch 22/80\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 0.7953 - accuracy: 0.7747 - val_loss: 1.0863 - val_accuracy: 0.6719\n",
      "Epoch 23/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.7534 - accuracy: 0.7852 - val_loss: 1.0092 - val_accuracy: 0.6615\n",
      "Epoch 24/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.7643 - accuracy: 0.7852 - val_loss: 0.9551 - val_accuracy: 0.7031\n",
      "Epoch 25/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.7382 - accuracy: 0.7904 - val_loss: 0.9415 - val_accuracy: 0.6823\n",
      "Epoch 26/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.7383 - accuracy: 0.8021 - val_loss: 0.9547 - val_accuracy: 0.6823\n",
      "Epoch 27/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.7106 - accuracy: 0.8203 - val_loss: 1.0402 - val_accuracy: 0.6562\n",
      "Epoch 28/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.7756 - accuracy: 0.7786 - val_loss: 1.0098 - val_accuracy: 0.6771\n",
      "Epoch 29/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.7213 - accuracy: 0.7930 - val_loss: 0.9857 - val_accuracy: 0.6458\n",
      "Epoch 30/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.7079 - accuracy: 0.8021 - val_loss: 1.0246 - val_accuracy: 0.6354\n",
      "Epoch 31/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.7058 - accuracy: 0.7773 - val_loss: 0.9809 - val_accuracy: 0.6562\n",
      "Epoch 32/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.6738 - accuracy: 0.8099 - val_loss: 1.0023 - val_accuracy: 0.6667\n",
      "Epoch 33/80\n",
      "192/192 [==============================] - 6s 34ms/step - loss: 0.6681 - accuracy: 0.8177 - val_loss: 1.0103 - val_accuracy: 0.6615\n",
      "Epoch 34/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.6554 - accuracy: 0.8190 - val_loss: 0.9698 - val_accuracy: 0.6562\n",
      "Epoch 35/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.6911 - accuracy: 0.8021 - val_loss: 0.9927 - val_accuracy: 0.6875\n",
      "Epoch 36/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.6410 - accuracy: 0.8229 - val_loss: 1.0101 - val_accuracy: 0.6615\n",
      "Epoch 37/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.6607 - accuracy: 0.8008 - val_loss: 1.0841 - val_accuracy: 0.6146\n",
      "Epoch 38/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.6600 - accuracy: 0.8151 - val_loss: 1.0720 - val_accuracy: 0.6406\n",
      "Epoch 39/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.6612 - accuracy: 0.8112 - val_loss: 1.0214 - val_accuracy: 0.6562\n",
      "Epoch 40/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.6079 - accuracy: 0.8411 - val_loss: 1.0757 - val_accuracy: 0.6406\n",
      "Epoch 41/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.6637 - accuracy: 0.8086 - val_loss: 1.0323 - val_accuracy: 0.6823\n",
      "Epoch 42/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.6422 - accuracy: 0.8177 - val_loss: 1.0599 - val_accuracy: 0.6458\n",
      "Epoch 43/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.6115 - accuracy: 0.8451 - val_loss: 1.0451 - val_accuracy: 0.6562\n",
      "Epoch 44/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.6205 - accuracy: 0.8216 - val_loss: 1.0058 - val_accuracy: 0.6458\n",
      "Epoch 45/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.5927 - accuracy: 0.8398 - val_loss: 1.0408 - val_accuracy: 0.6615\n",
      "Epoch 46/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.5816 - accuracy: 0.8477 - val_loss: 1.0456 - val_accuracy: 0.6458\n",
      "Epoch 47/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.5680 - accuracy: 0.8372 - val_loss: 1.0259 - val_accuracy: 0.6615\n",
      "Epoch 48/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.5919 - accuracy: 0.8359 - val_loss: 1.0535 - val_accuracy: 0.6615\n",
      "Epoch 49/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.5990 - accuracy: 0.8307 - val_loss: 1.0357 - val_accuracy: 0.6667\n",
      "Epoch 50/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.5801 - accuracy: 0.8581 - val_loss: 1.0405 - val_accuracy: 0.6615\n",
      "Epoch 51/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.5735 - accuracy: 0.8503 - val_loss: 1.0370 - val_accuracy: 0.6667\n",
      "Epoch 52/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.5946 - accuracy: 0.8451 - val_loss: 0.9982 - val_accuracy: 0.6823\n",
      "Epoch 53/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5880 - accuracy: 0.8477 - val_loss: 1.0449 - val_accuracy: 0.6719\n",
      "Epoch 54/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.5969 - accuracy: 0.8372 - val_loss: 1.0409 - val_accuracy: 0.6406\n",
      "Epoch 55/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.5417 - accuracy: 0.8607 - val_loss: 1.0166 - val_accuracy: 0.6458\n",
      "Epoch 56/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5554 - accuracy: 0.8529 - val_loss: 0.9874 - val_accuracy: 0.6510\n",
      "Epoch 57/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.5136 - accuracy: 0.8607 - val_loss: 1.0345 - val_accuracy: 0.6562\n",
      "Epoch 58/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5761 - accuracy: 0.8320 - val_loss: 1.0067 - val_accuracy: 0.6510\n",
      "Epoch 59/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.5413 - accuracy: 0.8568 - val_loss: 0.9778 - val_accuracy: 0.6927\n",
      "Epoch 60/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.5462 - accuracy: 0.8698 - val_loss: 0.9786 - val_accuracy: 0.6875\n",
      "Epoch 61/80\n",
      "192/192 [==============================] - 5s 29ms/step - loss: 0.5025 - accuracy: 0.8672 - val_loss: 0.9681 - val_accuracy: 0.6719\n",
      "Epoch 62/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.4998 - accuracy: 0.8815 - val_loss: 0.9782 - val_accuracy: 0.6719\n",
      "Epoch 63/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.5441 - accuracy: 0.8594 - val_loss: 0.9920 - val_accuracy: 0.6458\n",
      "Epoch 64/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.5161 - accuracy: 0.8685 - val_loss: 1.0013 - val_accuracy: 0.6719\n",
      "Epoch 65/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5154 - accuracy: 0.8581 - val_loss: 1.0174 - val_accuracy: 0.6719\n",
      "Epoch 66/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.5014 - accuracy: 0.8711 - val_loss: 1.0309 - val_accuracy: 0.6719\n",
      "Epoch 67/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.4993 - accuracy: 0.8698 - val_loss: 1.0503 - val_accuracy: 0.6615\n",
      "Epoch 68/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.5246 - accuracy: 0.8672 - val_loss: 1.0634 - val_accuracy: 0.6302\n",
      "Epoch 69/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.4909 - accuracy: 0.8646 - val_loss: 1.0270 - val_accuracy: 0.6510\n",
      "Epoch 70/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.4852 - accuracy: 0.8659 - val_loss: 1.0818 - val_accuracy: 0.6615\n",
      "Epoch 71/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.4764 - accuracy: 0.8802 - val_loss: 1.0765 - val_accuracy: 0.6667\n",
      "Epoch 72/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.5022 - accuracy: 0.8750 - val_loss: 1.0310 - val_accuracy: 0.6823\n",
      "Epoch 73/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.4936 - accuracy: 0.8568 - val_loss: 1.0523 - val_accuracy: 0.6510\n",
      "Epoch 74/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4834 - accuracy: 0.8763 - val_loss: 1.0587 - val_accuracy: 0.6615\n",
      "Epoch 75/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.4694 - accuracy: 0.8802 - val_loss: 1.0519 - val_accuracy: 0.6562\n",
      "Epoch 76/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4645 - accuracy: 0.8828 - val_loss: 1.1021 - val_accuracy: 0.6406\n",
      "Epoch 77/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4569 - accuracy: 0.8789 - val_loss: 1.0910 - val_accuracy: 0.6458\n",
      "Epoch 78/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4387 - accuracy: 0.8919 - val_loss: 1.0563 - val_accuracy: 0.6562\n",
      "Epoch 79/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4812 - accuracy: 0.8802 - val_loss: 1.1048 - val_accuracy: 0.6719\n",
      "Epoch 80/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.4767 - accuracy: 0.8750 - val_loss: 1.0711 - val_accuracy: 0.6510\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 1.0290 - accuracy: 0.6458\n",
      "Epoch 1/80\n",
      "192/192 [==============================] - 8s 32ms/step - loss: 2.0570 - accuracy: 0.2396 - val_loss: 1.8749 - val_accuracy: 0.3646\n",
      "Epoch 2/80\n",
      "192/192 [==============================] - 4s 23ms/step - loss: 1.5951 - accuracy: 0.4323 - val_loss: 1.4048 - val_accuracy: 0.5365\n",
      "Epoch 3/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 1.3883 - accuracy: 0.5260 - val_loss: 1.2893 - val_accuracy: 0.5729\n",
      "Epoch 4/80\n",
      "192/192 [==============================] - 3s 18ms/step - loss: 1.2535 - accuracy: 0.6042 - val_loss: 1.2959 - val_accuracy: 0.5625\n",
      "Epoch 5/80\n",
      "192/192 [==============================] - 3s 18ms/step - loss: 1.2342 - accuracy: 0.5911 - val_loss: 1.2164 - val_accuracy: 0.5677\n",
      "Epoch 6/80\n",
      "192/192 [==============================] - 4s 20ms/step - loss: 1.1572 - accuracy: 0.6484 - val_loss: 1.1592 - val_accuracy: 0.6406\n",
      "Epoch 7/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 1.0715 - accuracy: 0.6862 - val_loss: 1.1575 - val_accuracy: 0.6042\n",
      "Epoch 8/80\n",
      "192/192 [==============================] - 4s 18ms/step - loss: 1.0723 - accuracy: 0.6680 - val_loss: 1.1414 - val_accuracy: 0.6406\n",
      "Epoch 9/80\n",
      "192/192 [==============================] - 3s 18ms/step - loss: 1.0035 - accuracy: 0.7005 - val_loss: 1.1042 - val_accuracy: 0.6198\n",
      "Epoch 10/80\n",
      "192/192 [==============================] - 3s 18ms/step - loss: 0.9884 - accuracy: 0.7005 - val_loss: 1.1345 - val_accuracy: 0.6406\n",
      "Epoch 11/80\n",
      "192/192 [==============================] - 4s 20ms/step - loss: 0.9790 - accuracy: 0.7266 - val_loss: 1.1535 - val_accuracy: 0.6510\n",
      "Epoch 12/80\n",
      "192/192 [==============================] - 3s 18ms/step - loss: 0.9005 - accuracy: 0.7669 - val_loss: 1.1200 - val_accuracy: 0.6146\n",
      "Epoch 13/80\n",
      "192/192 [==============================] - 3s 18ms/step - loss: 0.9264 - accuracy: 0.7344 - val_loss: 1.0894 - val_accuracy: 0.6042\n",
      "Epoch 14/80\n",
      "192/192 [==============================] - 4s 18ms/step - loss: 0.9052 - accuracy: 0.7344 - val_loss: 1.0846 - val_accuracy: 0.6198\n",
      "Epoch 15/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.8560 - accuracy: 0.7487 - val_loss: 1.1101 - val_accuracy: 0.6094\n",
      "Epoch 16/80\n",
      "192/192 [==============================] - 4s 18ms/step - loss: 0.9012 - accuracy: 0.7435 - val_loss: 1.0904 - val_accuracy: 0.6458\n",
      "Epoch 17/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.8253 - accuracy: 0.7604 - val_loss: 1.1363 - val_accuracy: 0.6250\n",
      "Epoch 18/80\n",
      "192/192 [==============================] - 3s 18ms/step - loss: 0.8106 - accuracy: 0.7773 - val_loss: 1.0634 - val_accuracy: 0.6250\n",
      "Epoch 19/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.8242 - accuracy: 0.7539 - val_loss: 1.1013 - val_accuracy: 0.6406\n",
      "Epoch 20/80\n",
      "192/192 [==============================] - 4s 18ms/step - loss: 0.8087 - accuracy: 0.7669 - val_loss: 1.0243 - val_accuracy: 0.6458\n",
      "Epoch 21/80\n",
      "192/192 [==============================] - 3s 18ms/step - loss: 0.7580 - accuracy: 0.7995 - val_loss: 1.0678 - val_accuracy: 0.6094\n",
      "Epoch 22/80\n",
      "192/192 [==============================] - 3s 18ms/step - loss: 0.7215 - accuracy: 0.7956 - val_loss: 1.1076 - val_accuracy: 0.5990\n",
      "Epoch 23/80\n",
      "192/192 [==============================] - 3s 18ms/step - loss: 0.7185 - accuracy: 0.8125 - val_loss: 1.0518 - val_accuracy: 0.6354\n",
      "Epoch 24/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.7574 - accuracy: 0.7917 - val_loss: 1.0968 - val_accuracy: 0.6302\n",
      "Epoch 25/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.7689 - accuracy: 0.7826 - val_loss: 1.0946 - val_accuracy: 0.6042\n",
      "Epoch 26/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.7162 - accuracy: 0.8125 - val_loss: 1.0762 - val_accuracy: 0.6042\n",
      "Epoch 27/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.7094 - accuracy: 0.8034 - val_loss: 1.0353 - val_accuracy: 0.6458\n",
      "Epoch 28/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.6820 - accuracy: 0.8047 - val_loss: 1.0540 - val_accuracy: 0.6510\n",
      "Epoch 29/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.6968 - accuracy: 0.7878 - val_loss: 1.0931 - val_accuracy: 0.6302\n",
      "Epoch 30/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.6728 - accuracy: 0.7956 - val_loss: 1.1070 - val_accuracy: 0.6042\n",
      "Epoch 31/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.7024 - accuracy: 0.8086 - val_loss: 1.1005 - val_accuracy: 0.6094\n",
      "Epoch 32/80\n",
      "192/192 [==============================] - 5s 29ms/step - loss: 0.6792 - accuracy: 0.8086 - val_loss: 1.0729 - val_accuracy: 0.6458\n",
      "Epoch 33/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.6907 - accuracy: 0.7995 - val_loss: 1.0852 - val_accuracy: 0.6354\n",
      "Epoch 34/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.6807 - accuracy: 0.8073 - val_loss: 1.1138 - val_accuracy: 0.6094\n",
      "Epoch 35/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.7015 - accuracy: 0.7943 - val_loss: 1.1362 - val_accuracy: 0.5833\n",
      "Epoch 36/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.6341 - accuracy: 0.8268 - val_loss: 1.0878 - val_accuracy: 0.6354\n",
      "Epoch 37/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5929 - accuracy: 0.8385 - val_loss: 1.1177 - val_accuracy: 0.6250\n",
      "Epoch 38/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.6405 - accuracy: 0.8112 - val_loss: 1.0865 - val_accuracy: 0.6354\n",
      "Epoch 39/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.6212 - accuracy: 0.8359 - val_loss: 1.0792 - val_accuracy: 0.6094\n",
      "Epoch 40/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.6722 - accuracy: 0.8138 - val_loss: 1.0964 - val_accuracy: 0.5729\n",
      "Epoch 41/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.5877 - accuracy: 0.8451 - val_loss: 1.0806 - val_accuracy: 0.6198\n",
      "Epoch 42/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.6181 - accuracy: 0.8229 - val_loss: 1.0681 - val_accuracy: 0.6198\n",
      "Epoch 43/80\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.5594 - accuracy: 0.8542 - val_loss: 1.1116 - val_accuracy: 0.6094\n",
      "Epoch 44/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.6019 - accuracy: 0.8424 - val_loss: 1.0856 - val_accuracy: 0.6198\n",
      "Epoch 45/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.5767 - accuracy: 0.8385 - val_loss: 1.1075 - val_accuracy: 0.6406\n",
      "Epoch 46/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.5605 - accuracy: 0.8594 - val_loss: 1.1097 - val_accuracy: 0.6250\n",
      "Epoch 47/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5853 - accuracy: 0.8451 - val_loss: 1.0899 - val_accuracy: 0.6354\n",
      "Epoch 48/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.6010 - accuracy: 0.8255 - val_loss: 1.0964 - val_accuracy: 0.6354\n",
      "Epoch 49/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.5678 - accuracy: 0.8685 - val_loss: 1.1021 - val_accuracy: 0.6458\n",
      "Epoch 50/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.5431 - accuracy: 0.8607 - val_loss: 1.1388 - val_accuracy: 0.6198\n",
      "Epoch 51/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.5327 - accuracy: 0.8438 - val_loss: 1.1058 - val_accuracy: 0.6562\n",
      "Epoch 52/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.5566 - accuracy: 0.8359 - val_loss: 1.1331 - val_accuracy: 0.6458\n",
      "Epoch 53/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5717 - accuracy: 0.8346 - val_loss: 1.0870 - val_accuracy: 0.6667\n",
      "Epoch 54/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.5323 - accuracy: 0.8685 - val_loss: 1.0934 - val_accuracy: 0.6510\n",
      "Epoch 55/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.5394 - accuracy: 0.8685 - val_loss: 1.1113 - val_accuracy: 0.6406\n",
      "Epoch 56/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5629 - accuracy: 0.8424 - val_loss: 1.1348 - val_accuracy: 0.5990\n",
      "Epoch 57/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5314 - accuracy: 0.8620 - val_loss: 1.0725 - val_accuracy: 0.6458\n",
      "Epoch 58/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.5709 - accuracy: 0.8438 - val_loss: 1.1548 - val_accuracy: 0.6250\n",
      "Epoch 59/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.5187 - accuracy: 0.8659 - val_loss: 1.1393 - val_accuracy: 0.6562\n",
      "Epoch 60/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.5109 - accuracy: 0.8711 - val_loss: 1.1559 - val_accuracy: 0.6250\n",
      "Epoch 61/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.5057 - accuracy: 0.8529 - val_loss: 1.1354 - val_accuracy: 0.6198\n",
      "Epoch 62/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.4782 - accuracy: 0.8841 - val_loss: 1.1681 - val_accuracy: 0.6146\n",
      "Epoch 63/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5963 - accuracy: 0.8242 - val_loss: 1.1887 - val_accuracy: 0.6042\n",
      "Epoch 64/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.5483 - accuracy: 0.8477 - val_loss: 1.1933 - val_accuracy: 0.6354\n",
      "Epoch 65/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.4760 - accuracy: 0.8789 - val_loss: 1.1735 - val_accuracy: 0.6146\n",
      "Epoch 66/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.5240 - accuracy: 0.8503 - val_loss: 1.1485 - val_accuracy: 0.6250\n",
      "Epoch 67/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.4820 - accuracy: 0.8763 - val_loss: 1.1666 - val_accuracy: 0.6094\n",
      "Epoch 68/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.4576 - accuracy: 0.8906 - val_loss: 1.1089 - val_accuracy: 0.6406\n",
      "Epoch 69/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.4714 - accuracy: 0.8698 - val_loss: 1.1321 - val_accuracy: 0.6250\n",
      "Epoch 70/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.5073 - accuracy: 0.8607 - val_loss: 1.1544 - val_accuracy: 0.6250\n",
      "Epoch 71/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.4960 - accuracy: 0.8568 - val_loss: 1.1338 - val_accuracy: 0.6094\n",
      "Epoch 72/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.5088 - accuracy: 0.8672 - val_loss: 1.1183 - val_accuracy: 0.6302\n",
      "Epoch 73/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.5211 - accuracy: 0.8542 - val_loss: 1.1157 - val_accuracy: 0.6458\n",
      "Epoch 74/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.4670 - accuracy: 0.8737 - val_loss: 1.0966 - val_accuracy: 0.6615\n",
      "Epoch 75/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4629 - accuracy: 0.8763 - val_loss: 1.0881 - val_accuracy: 0.6354\n",
      "Epoch 76/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.4929 - accuracy: 0.8568 - val_loss: 1.1448 - val_accuracy: 0.6198\n",
      "Epoch 77/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.4277 - accuracy: 0.8971 - val_loss: 1.1564 - val_accuracy: 0.6354\n",
      "Epoch 78/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.4924 - accuracy: 0.8581 - val_loss: 1.1725 - val_accuracy: 0.6510\n",
      "Epoch 79/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.4275 - accuracy: 0.8854 - val_loss: 1.1809 - val_accuracy: 0.6302\n",
      "Epoch 80/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4173 - accuracy: 0.8841 - val_loss: 1.1981 - val_accuracy: 0.6302\n",
      "9/9 [==============================] - 0s 11ms/step - loss: 1.0712 - accuracy: 0.6354\n",
      "Epoch 1/80\n",
      "192/192 [==============================] - 9s 29ms/step - loss: 2.0052 - accuracy: 0.2474 - val_loss: 1.9011 - val_accuracy: 0.3646\n",
      "Epoch 2/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 1.5328 - accuracy: 0.4740 - val_loss: 1.5704 - val_accuracy: 0.4479\n",
      "Epoch 3/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 1.3857 - accuracy: 0.5000 - val_loss: 1.5278 - val_accuracy: 0.4219\n",
      "Epoch 4/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 1.2578 - accuracy: 0.5599 - val_loss: 1.3430 - val_accuracy: 0.5885\n",
      "Epoch 5/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 1.1908 - accuracy: 0.6146 - val_loss: 1.3351 - val_accuracy: 0.5260\n",
      "Epoch 6/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 1.1327 - accuracy: 0.6445 - val_loss: 1.2560 - val_accuracy: 0.5885\n",
      "Epoch 7/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 1.0753 - accuracy: 0.6732 - val_loss: 1.2485 - val_accuracy: 0.5625\n",
      "Epoch 8/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 1.0634 - accuracy: 0.6836 - val_loss: 1.2368 - val_accuracy: 0.5885\n",
      "Epoch 9/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.9983 - accuracy: 0.7057 - val_loss: 1.2419 - val_accuracy: 0.5573\n",
      "Epoch 10/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.9537 - accuracy: 0.7318 - val_loss: 1.2185 - val_accuracy: 0.5781\n",
      "Epoch 11/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.9424 - accuracy: 0.7461 - val_loss: 1.1937 - val_accuracy: 0.5573\n",
      "Epoch 12/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.9079 - accuracy: 0.7344 - val_loss: 1.2281 - val_accuracy: 0.5573\n",
      "Epoch 13/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.8700 - accuracy: 0.7565 - val_loss: 1.2016 - val_accuracy: 0.5990\n",
      "Epoch 14/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.9149 - accuracy: 0.7357 - val_loss: 1.2492 - val_accuracy: 0.5781\n",
      "Epoch 15/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.8445 - accuracy: 0.7656 - val_loss: 1.2221 - val_accuracy: 0.5781\n",
      "Epoch 16/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.8787 - accuracy: 0.7487 - val_loss: 1.3279 - val_accuracy: 0.5312\n",
      "Epoch 17/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.8429 - accuracy: 0.7552 - val_loss: 1.2796 - val_accuracy: 0.5417\n",
      "Epoch 18/80\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.8296 - accuracy: 0.7526 - val_loss: 1.2499 - val_accuracy: 0.5729\n",
      "Epoch 19/80\n",
      "192/192 [==============================] - 5s 29ms/step - loss: 0.7874 - accuracy: 0.7891 - val_loss: 1.2746 - val_accuracy: 0.5885\n",
      "Epoch 20/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.7759 - accuracy: 0.7812 - val_loss: 1.2363 - val_accuracy: 0.5938\n",
      "Epoch 21/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.7645 - accuracy: 0.7812 - val_loss: 1.2453 - val_accuracy: 0.5885\n",
      "Epoch 22/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.7282 - accuracy: 0.7904 - val_loss: 1.2797 - val_accuracy: 0.5677\n",
      "Epoch 23/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.7061 - accuracy: 0.8060 - val_loss: 1.2280 - val_accuracy: 0.6198\n",
      "Epoch 24/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.7024 - accuracy: 0.8086 - val_loss: 1.2416 - val_accuracy: 0.5990\n",
      "Epoch 25/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.7316 - accuracy: 0.8151 - val_loss: 1.2675 - val_accuracy: 0.5781\n",
      "Epoch 26/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.6989 - accuracy: 0.8047 - val_loss: 1.2499 - val_accuracy: 0.5677\n",
      "Epoch 27/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.7340 - accuracy: 0.7917 - val_loss: 1.2241 - val_accuracy: 0.6042\n",
      "Epoch 28/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.6865 - accuracy: 0.7852 - val_loss: 1.2477 - val_accuracy: 0.6094\n",
      "Epoch 29/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.7020 - accuracy: 0.7956 - val_loss: 1.2775 - val_accuracy: 0.5729\n",
      "Epoch 30/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.7007 - accuracy: 0.7930 - val_loss: 1.2846 - val_accuracy: 0.5729\n",
      "Epoch 31/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.7015 - accuracy: 0.7982 - val_loss: 1.2664 - val_accuracy: 0.5521\n",
      "Epoch 32/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.6470 - accuracy: 0.8294 - val_loss: 1.3132 - val_accuracy: 0.5417\n",
      "Epoch 33/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.6635 - accuracy: 0.8255 - val_loss: 1.3118 - val_accuracy: 0.5573\n",
      "Epoch 34/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.6174 - accuracy: 0.8464 - val_loss: 1.2450 - val_accuracy: 0.5990\n",
      "Epoch 35/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.6191 - accuracy: 0.8346 - val_loss: 1.2993 - val_accuracy: 0.5573\n",
      "Epoch 36/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.6460 - accuracy: 0.8190 - val_loss: 1.3009 - val_accuracy: 0.5938\n",
      "Epoch 37/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.5919 - accuracy: 0.8503 - val_loss: 1.3117 - val_accuracy: 0.5833\n",
      "Epoch 38/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.6338 - accuracy: 0.8333 - val_loss: 1.3059 - val_accuracy: 0.5938\n",
      "Epoch 39/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.6127 - accuracy: 0.8411 - val_loss: 1.3089 - val_accuracy: 0.5573\n",
      "Epoch 40/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.6250 - accuracy: 0.8164 - val_loss: 1.3100 - val_accuracy: 0.5625\n",
      "Epoch 41/80\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.6254 - accuracy: 0.8307 - val_loss: 1.3085 - val_accuracy: 0.5625\n",
      "Epoch 42/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.5929 - accuracy: 0.8503 - val_loss: 1.2735 - val_accuracy: 0.5885\n",
      "Epoch 43/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.6114 - accuracy: 0.8411 - val_loss: 1.4046 - val_accuracy: 0.5729\n",
      "Epoch 44/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.5859 - accuracy: 0.8372 - val_loss: 1.3377 - val_accuracy: 0.5729\n",
      "Epoch 45/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.5814 - accuracy: 0.8477 - val_loss: 1.2990 - val_accuracy: 0.6094\n",
      "Epoch 46/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.6110 - accuracy: 0.8307 - val_loss: 1.3032 - val_accuracy: 0.5677\n",
      "Epoch 47/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.5585 - accuracy: 0.8516 - val_loss: 1.3437 - val_accuracy: 0.5625\n",
      "Epoch 48/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.6057 - accuracy: 0.8281 - val_loss: 1.3474 - val_accuracy: 0.5677\n",
      "Epoch 49/80\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.5598 - accuracy: 0.8568 - val_loss: 1.3162 - val_accuracy: 0.5729\n",
      "Epoch 50/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5559 - accuracy: 0.8542 - val_loss: 1.2789 - val_accuracy: 0.5990\n",
      "Epoch 51/80\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.5445 - accuracy: 0.8516 - val_loss: 1.3187 - val_accuracy: 0.6042\n",
      "Epoch 52/80\n",
      "192/192 [==============================] - 5s 29ms/step - loss: 0.5311 - accuracy: 0.8633 - val_loss: 1.2549 - val_accuracy: 0.6042\n",
      "Epoch 53/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5311 - accuracy: 0.8815 - val_loss: 1.3026 - val_accuracy: 0.5938\n",
      "Epoch 54/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.5507 - accuracy: 0.8477 - val_loss: 1.2519 - val_accuracy: 0.5990\n",
      "Epoch 55/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.5010 - accuracy: 0.8906 - val_loss: 1.2425 - val_accuracy: 0.5990\n",
      "Epoch 56/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.6069 - accuracy: 0.8281 - val_loss: 1.2669 - val_accuracy: 0.6250\n",
      "Epoch 57/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4916 - accuracy: 0.8802 - val_loss: 1.2623 - val_accuracy: 0.6094\n",
      "Epoch 58/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5571 - accuracy: 0.8398 - val_loss: 1.2820 - val_accuracy: 0.5885\n",
      "Epoch 59/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4804 - accuracy: 0.8789 - val_loss: 1.2397 - val_accuracy: 0.5781\n",
      "Epoch 60/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.5058 - accuracy: 0.8620 - val_loss: 1.3061 - val_accuracy: 0.5885\n",
      "Epoch 61/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.5117 - accuracy: 0.8594 - val_loss: 1.2605 - val_accuracy: 0.5938\n",
      "Epoch 62/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.5407 - accuracy: 0.8529 - val_loss: 1.3026 - val_accuracy: 0.6302\n",
      "Epoch 63/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5401 - accuracy: 0.8568 - val_loss: 1.3184 - val_accuracy: 0.6042\n",
      "Epoch 64/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.5027 - accuracy: 0.8750 - val_loss: 1.3674 - val_accuracy: 0.5625\n",
      "Epoch 65/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5106 - accuracy: 0.8581 - val_loss: 1.3423 - val_accuracy: 0.5833\n",
      "Epoch 66/80\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.4934 - accuracy: 0.8724 - val_loss: 1.3927 - val_accuracy: 0.5885\n",
      "Epoch 67/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.5094 - accuracy: 0.8620 - val_loss: 1.3730 - val_accuracy: 0.5729\n",
      "Epoch 68/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.4894 - accuracy: 0.8815 - val_loss: 1.3407 - val_accuracy: 0.5833\n",
      "Epoch 69/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.5125 - accuracy: 0.8581 - val_loss: 1.3473 - val_accuracy: 0.5833\n",
      "Epoch 70/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4887 - accuracy: 0.8737 - val_loss: 1.3711 - val_accuracy: 0.5938\n",
      "Epoch 71/80\n",
      "192/192 [==============================] - 4s 23ms/step - loss: 0.4877 - accuracy: 0.8672 - val_loss: 1.3319 - val_accuracy: 0.5833\n",
      "Epoch 72/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.4817 - accuracy: 0.8646 - val_loss: 1.3145 - val_accuracy: 0.5938\n",
      "Epoch 73/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.4593 - accuracy: 0.8919 - val_loss: 1.3406 - val_accuracy: 0.6042\n",
      "Epoch 74/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4680 - accuracy: 0.8698 - val_loss: 1.4002 - val_accuracy: 0.5573\n",
      "Epoch 75/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5197 - accuracy: 0.8529 - val_loss: 1.4243 - val_accuracy: 0.5781\n",
      "Epoch 76/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.4836 - accuracy: 0.8620 - val_loss: 1.3611 - val_accuracy: 0.5729\n",
      "Epoch 77/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.4003 - accuracy: 0.9180 - val_loss: 1.3524 - val_accuracy: 0.5833\n",
      "Epoch 78/80\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.4476 - accuracy: 0.8815 - val_loss: 1.3950 - val_accuracy: 0.5729\n",
      "Epoch 79/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.4558 - accuracy: 0.8906 - val_loss: 1.4055 - val_accuracy: 0.5781\n",
      "Epoch 80/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.3985 - accuracy: 0.8997 - val_loss: 1.4181 - val_accuracy: 0.5781\n",
      "9/9 [==============================] - 1s 27ms/step - loss: 1.0253 - accuracy: 0.6771\n",
      "Epoch 1/80\n",
      "192/192 [==============================] - 9s 35ms/step - loss: 2.0892 - accuracy: 0.2318 - val_loss: 1.8534 - val_accuracy: 0.4427\n",
      "Epoch 2/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 1.5511 - accuracy: 0.4453 - val_loss: 1.4785 - val_accuracy: 0.4531\n",
      "Epoch 3/80\n",
      "192/192 [==============================] - 7s 38ms/step - loss: 1.3555 - accuracy: 0.5052 - val_loss: 1.4842 - val_accuracy: 0.5104\n",
      "Epoch 4/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 1.2902 - accuracy: 0.5625 - val_loss: 1.3458 - val_accuracy: 0.5365\n",
      "Epoch 5/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 1.1803 - accuracy: 0.6328 - val_loss: 1.3160 - val_accuracy: 0.5573\n",
      "Epoch 6/80\n",
      "192/192 [==============================] - 5s 29ms/step - loss: 1.1530 - accuracy: 0.6211 - val_loss: 1.2469 - val_accuracy: 0.6146\n",
      "Epoch 7/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 1.0975 - accuracy: 0.6497 - val_loss: 1.2604 - val_accuracy: 0.6094\n",
      "Epoch 8/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 1.0547 - accuracy: 0.6680 - val_loss: 1.2866 - val_accuracy: 0.5990\n",
      "Epoch 9/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 1.0236 - accuracy: 0.7057 - val_loss: 1.2252 - val_accuracy: 0.6302\n",
      "Epoch 10/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.9551 - accuracy: 0.7331 - val_loss: 1.2212 - val_accuracy: 0.5833\n",
      "Epoch 11/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.9669 - accuracy: 0.7122 - val_loss: 1.1741 - val_accuracy: 0.6562\n",
      "Epoch 12/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.9306 - accuracy: 0.7188 - val_loss: 1.1883 - val_accuracy: 0.6094\n",
      "Epoch 13/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.8877 - accuracy: 0.7487 - val_loss: 1.0990 - val_accuracy: 0.6302\n",
      "Epoch 14/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.8538 - accuracy: 0.7682 - val_loss: 1.0932 - val_accuracy: 0.6302\n",
      "Epoch 15/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.8564 - accuracy: 0.7409 - val_loss: 1.1433 - val_accuracy: 0.6094\n",
      "Epoch 16/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.8573 - accuracy: 0.7578 - val_loss: 1.1577 - val_accuracy: 0.5990\n",
      "Epoch 17/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.8230 - accuracy: 0.7734 - val_loss: 1.1479 - val_accuracy: 0.6302\n",
      "Epoch 18/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.8381 - accuracy: 0.7552 - val_loss: 1.1228 - val_accuracy: 0.6302\n",
      "Epoch 19/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.7789 - accuracy: 0.7878 - val_loss: 1.1272 - val_accuracy: 0.6146\n",
      "Epoch 20/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.7899 - accuracy: 0.7786 - val_loss: 1.1211 - val_accuracy: 0.6198\n",
      "Epoch 21/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.7633 - accuracy: 0.7656 - val_loss: 1.0716 - val_accuracy: 0.6406\n",
      "Epoch 22/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.7866 - accuracy: 0.7878 - val_loss: 1.0592 - val_accuracy: 0.6615\n",
      "Epoch 23/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.7953 - accuracy: 0.7760 - val_loss: 1.0662 - val_accuracy: 0.6458\n",
      "Epoch 24/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.7268 - accuracy: 0.8060 - val_loss: 1.0879 - val_accuracy: 0.6406\n",
      "Epoch 25/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.7178 - accuracy: 0.8112 - val_loss: 1.1563 - val_accuracy: 0.6458\n",
      "Epoch 26/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.6847 - accuracy: 0.8255 - val_loss: 1.1097 - val_accuracy: 0.6406\n",
      "Epoch 27/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.6681 - accuracy: 0.8112 - val_loss: 1.0329 - val_accuracy: 0.6458\n",
      "Epoch 28/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.6758 - accuracy: 0.8177 - val_loss: 1.1033 - val_accuracy: 0.6562\n",
      "Epoch 29/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.6766 - accuracy: 0.8073 - val_loss: 1.1107 - val_accuracy: 0.6406\n",
      "Epoch 30/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.6928 - accuracy: 0.8112 - val_loss: 1.1216 - val_accuracy: 0.6458\n",
      "Epoch 31/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.6566 - accuracy: 0.8216 - val_loss: 1.1447 - val_accuracy: 0.6406\n",
      "Epoch 32/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.6606 - accuracy: 0.8151 - val_loss: 1.1298 - val_accuracy: 0.6094\n",
      "Epoch 33/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.6712 - accuracy: 0.7930 - val_loss: 1.1610 - val_accuracy: 0.6250\n",
      "Epoch 34/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.6233 - accuracy: 0.8398 - val_loss: 1.1770 - val_accuracy: 0.6510\n",
      "Epoch 35/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.6339 - accuracy: 0.8229 - val_loss: 1.1212 - val_accuracy: 0.6458\n",
      "Epoch 36/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.6308 - accuracy: 0.8268 - val_loss: 1.1704 - val_accuracy: 0.6146\n",
      "Epoch 37/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.6102 - accuracy: 0.8307 - val_loss: 1.1213 - val_accuracy: 0.6354\n",
      "Epoch 38/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.6136 - accuracy: 0.8190 - val_loss: 1.1685 - val_accuracy: 0.6354\n",
      "Epoch 39/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.6130 - accuracy: 0.8424 - val_loss: 1.1355 - val_accuracy: 0.6354\n",
      "Epoch 40/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.5481 - accuracy: 0.8594 - val_loss: 1.1287 - val_accuracy: 0.6562\n",
      "Epoch 41/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.6011 - accuracy: 0.8464 - val_loss: 1.0801 - val_accuracy: 0.6354\n",
      "Epoch 42/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5715 - accuracy: 0.8516 - val_loss: 1.0510 - val_accuracy: 0.6458\n",
      "Epoch 43/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.5670 - accuracy: 0.8633 - val_loss: 1.1054 - val_accuracy: 0.6302\n",
      "Epoch 44/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5130 - accuracy: 0.8633 - val_loss: 1.1174 - val_accuracy: 0.6094\n",
      "Epoch 45/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5554 - accuracy: 0.8529 - val_loss: 1.1143 - val_accuracy: 0.6458\n",
      "Epoch 46/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.5313 - accuracy: 0.8737 - val_loss: 1.1250 - val_accuracy: 0.6458\n",
      "Epoch 47/80\n",
      "192/192 [==============================] - 6s 28ms/step - loss: 0.5962 - accuracy: 0.8255 - val_loss: 1.1125 - val_accuracy: 0.6771\n",
      "Epoch 48/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.5923 - accuracy: 0.8346 - val_loss: 1.1567 - val_accuracy: 0.6302\n",
      "Epoch 49/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.5990 - accuracy: 0.8490 - val_loss: 1.1357 - val_accuracy: 0.6354\n",
      "Epoch 50/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.5470 - accuracy: 0.8633 - val_loss: 1.1982 - val_accuracy: 0.6042\n",
      "Epoch 51/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.5171 - accuracy: 0.8737 - val_loss: 1.1710 - val_accuracy: 0.6302\n",
      "Epoch 52/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.5439 - accuracy: 0.8490 - val_loss: 1.1665 - val_accuracy: 0.6198\n",
      "Epoch 53/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.5536 - accuracy: 0.8542 - val_loss: 1.1404 - val_accuracy: 0.6302\n",
      "Epoch 54/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.4817 - accuracy: 0.8880 - val_loss: 1.1304 - val_accuracy: 0.6458\n",
      "Epoch 55/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.5052 - accuracy: 0.8802 - val_loss: 1.2145 - val_accuracy: 0.6146\n",
      "Epoch 56/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.4716 - accuracy: 0.8789 - val_loss: 1.2236 - val_accuracy: 0.5990\n",
      "Epoch 57/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5081 - accuracy: 0.8724 - val_loss: 1.2377 - val_accuracy: 0.5781\n",
      "Epoch 58/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.5518 - accuracy: 0.8385 - val_loss: 1.2329 - val_accuracy: 0.5990\n",
      "Epoch 59/80\n",
      "192/192 [==============================] - 5s 29ms/step - loss: 0.4639 - accuracy: 0.8880 - val_loss: 1.2360 - val_accuracy: 0.6250\n",
      "Epoch 60/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.5479 - accuracy: 0.8477 - val_loss: 1.3134 - val_accuracy: 0.5833\n",
      "Epoch 61/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4939 - accuracy: 0.8659 - val_loss: 1.2514 - val_accuracy: 0.6094\n",
      "Epoch 62/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.4959 - accuracy: 0.8763 - val_loss: 1.2547 - val_accuracy: 0.6042\n",
      "Epoch 63/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.4672 - accuracy: 0.8932 - val_loss: 1.2572 - val_accuracy: 0.6146\n",
      "Epoch 64/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.5135 - accuracy: 0.8724 - val_loss: 1.1710 - val_accuracy: 0.6042\n",
      "Epoch 65/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.4770 - accuracy: 0.8841 - val_loss: 1.3161 - val_accuracy: 0.5990\n",
      "Epoch 66/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4890 - accuracy: 0.8815 - val_loss: 1.2637 - val_accuracy: 0.5938\n",
      "Epoch 67/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.5046 - accuracy: 0.8620 - val_loss: 1.2162 - val_accuracy: 0.5938\n",
      "Epoch 68/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.4798 - accuracy: 0.8815 - val_loss: 1.1717 - val_accuracy: 0.6302\n",
      "Epoch 69/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.4834 - accuracy: 0.8815 - val_loss: 1.2798 - val_accuracy: 0.6198\n",
      "Epoch 70/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.4861 - accuracy: 0.8815 - val_loss: 1.1806 - val_accuracy: 0.6354\n",
      "Epoch 71/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4648 - accuracy: 0.8776 - val_loss: 1.2119 - val_accuracy: 0.6146\n",
      "Epoch 72/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.5101 - accuracy: 0.8737 - val_loss: 1.1863 - val_accuracy: 0.6771\n",
      "Epoch 73/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.4505 - accuracy: 0.8867 - val_loss: 1.1967 - val_accuracy: 0.6354\n",
      "Epoch 74/80\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.4727 - accuracy: 0.8724 - val_loss: 1.2484 - val_accuracy: 0.6250\n",
      "Epoch 75/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.4431 - accuracy: 0.8880 - val_loss: 1.2829 - val_accuracy: 0.6302\n",
      "Epoch 76/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.4104 - accuracy: 0.9062 - val_loss: 1.1975 - val_accuracy: 0.6354\n",
      "Epoch 77/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.4494 - accuracy: 0.8919 - val_loss: 1.2749 - val_accuracy: 0.6250\n",
      "Epoch 78/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.4589 - accuracy: 0.8919 - val_loss: 1.2710 - val_accuracy: 0.6458\n",
      "Epoch 79/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4932 - accuracy: 0.8698 - val_loss: 1.3670 - val_accuracy: 0.5938\n",
      "Epoch 80/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.4271 - accuracy: 0.9036 - val_loss: 1.2979 - val_accuracy: 0.6302\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.9807 - accuracy: 0.6806\n",
      "Epoch 1/80\n",
      "192/192 [==============================] - 9s 36ms/step - loss: 2.0077 - accuracy: 0.2148 - val_loss: 1.8329 - val_accuracy: 0.2865\n",
      "Epoch 2/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 1.5662 - accuracy: 0.4674 - val_loss: 1.3260 - val_accuracy: 0.5781\n",
      "Epoch 3/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 1.3855 - accuracy: 0.5391 - val_loss: 1.2246 - val_accuracy: 0.6198\n",
      "Epoch 4/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 1.2925 - accuracy: 0.5807 - val_loss: 1.1714 - val_accuracy: 0.6667\n",
      "Epoch 5/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 1.1675 - accuracy: 0.6198 - val_loss: 1.1309 - val_accuracy: 0.6406\n",
      "Epoch 6/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 1.1227 - accuracy: 0.6497 - val_loss: 1.1236 - val_accuracy: 0.6667\n",
      "Epoch 7/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 1.0986 - accuracy: 0.6693 - val_loss: 1.1172 - val_accuracy: 0.6823\n",
      "Epoch 8/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 1.0695 - accuracy: 0.6680 - val_loss: 1.0891 - val_accuracy: 0.6615\n",
      "Epoch 9/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.9867 - accuracy: 0.7161 - val_loss: 1.0224 - val_accuracy: 0.6771\n",
      "Epoch 10/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.9864 - accuracy: 0.7148 - val_loss: 1.0512 - val_accuracy: 0.6979\n",
      "Epoch 11/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.9465 - accuracy: 0.7214 - val_loss: 0.9899 - val_accuracy: 0.7188\n",
      "Epoch 12/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.9671 - accuracy: 0.6914 - val_loss: 1.0480 - val_accuracy: 0.6927\n",
      "Epoch 13/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.8997 - accuracy: 0.7435 - val_loss: 1.1241 - val_accuracy: 0.6615\n",
      "Epoch 14/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.8676 - accuracy: 0.7318 - val_loss: 1.0711 - val_accuracy: 0.6615\n",
      "Epoch 15/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.8732 - accuracy: 0.7526 - val_loss: 0.9718 - val_accuracy: 0.7344\n",
      "Epoch 16/80\n",
      "192/192 [==============================] - 5s 29ms/step - loss: 0.8806 - accuracy: 0.7461 - val_loss: 0.9672 - val_accuracy: 0.7083\n",
      "Epoch 17/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.8443 - accuracy: 0.7839 - val_loss: 1.0050 - val_accuracy: 0.6875\n",
      "Epoch 18/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.7893 - accuracy: 0.7812 - val_loss: 0.9808 - val_accuracy: 0.7188\n",
      "Epoch 19/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.8154 - accuracy: 0.7826 - val_loss: 0.9685 - val_accuracy: 0.7344\n",
      "Epoch 20/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.7820 - accuracy: 0.7734 - val_loss: 0.9521 - val_accuracy: 0.7031\n",
      "Epoch 21/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.7509 - accuracy: 0.7943 - val_loss: 0.9902 - val_accuracy: 0.6927\n",
      "Epoch 22/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.7767 - accuracy: 0.7982 - val_loss: 0.9644 - val_accuracy: 0.6875\n",
      "Epoch 23/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.7192 - accuracy: 0.8242 - val_loss: 0.9899 - val_accuracy: 0.6771\n",
      "Epoch 24/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.7454 - accuracy: 0.7904 - val_loss: 0.9814 - val_accuracy: 0.7083\n",
      "Epoch 25/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.7149 - accuracy: 0.8086 - val_loss: 1.0003 - val_accuracy: 0.6927\n",
      "Epoch 26/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.7780 - accuracy: 0.7487 - val_loss: 1.0434 - val_accuracy: 0.6771\n",
      "Epoch 27/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.7540 - accuracy: 0.8060 - val_loss: 0.9930 - val_accuracy: 0.6823\n",
      "Epoch 28/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.6890 - accuracy: 0.8086 - val_loss: 1.0451 - val_accuracy: 0.6615\n",
      "Epoch 29/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.6821 - accuracy: 0.8268 - val_loss: 1.0750 - val_accuracy: 0.6771\n",
      "Epoch 30/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.7018 - accuracy: 0.8138 - val_loss: 1.0164 - val_accuracy: 0.7031\n",
      "Epoch 31/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.6813 - accuracy: 0.8125 - val_loss: 0.9970 - val_accuracy: 0.6979\n",
      "Epoch 32/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.6951 - accuracy: 0.8229 - val_loss: 0.9728 - val_accuracy: 0.6927\n",
      "Epoch 33/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.6125 - accuracy: 0.8424 - val_loss: 0.9653 - val_accuracy: 0.7031\n",
      "Epoch 34/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.6036 - accuracy: 0.8333 - val_loss: 1.0000 - val_accuracy: 0.6771\n",
      "Epoch 35/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.6599 - accuracy: 0.8086 - val_loss: 0.9512 - val_accuracy: 0.7240\n",
      "Epoch 36/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.6556 - accuracy: 0.8164 - val_loss: 0.9132 - val_accuracy: 0.7188\n",
      "Epoch 37/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.6105 - accuracy: 0.8385 - val_loss: 0.8915 - val_accuracy: 0.7083\n",
      "Epoch 38/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.6706 - accuracy: 0.8125 - val_loss: 0.9348 - val_accuracy: 0.7292\n",
      "Epoch 39/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5942 - accuracy: 0.8516 - val_loss: 0.9653 - val_accuracy: 0.6927\n",
      "Epoch 40/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.6520 - accuracy: 0.8268 - val_loss: 0.9855 - val_accuracy: 0.6823\n",
      "Epoch 41/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.6203 - accuracy: 0.8242 - val_loss: 0.9773 - val_accuracy: 0.6875\n",
      "Epoch 42/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.6206 - accuracy: 0.8112 - val_loss: 0.9899 - val_accuracy: 0.7083\n",
      "Epoch 43/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.6075 - accuracy: 0.8346 - val_loss: 0.9742 - val_accuracy: 0.6927\n",
      "Epoch 44/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.6320 - accuracy: 0.8216 - val_loss: 1.0020 - val_accuracy: 0.6667\n",
      "Epoch 45/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.5673 - accuracy: 0.8633 - val_loss: 1.0438 - val_accuracy: 0.7031\n",
      "Epoch 46/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.5805 - accuracy: 0.8438 - val_loss: 1.0020 - val_accuracy: 0.6875\n",
      "Epoch 47/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5969 - accuracy: 0.8385 - val_loss: 0.9663 - val_accuracy: 0.6875\n",
      "Epoch 48/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.5977 - accuracy: 0.8438 - val_loss: 1.0289 - val_accuracy: 0.6771\n",
      "Epoch 49/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.5709 - accuracy: 0.8464 - val_loss: 0.9701 - val_accuracy: 0.6979\n",
      "Epoch 50/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.5871 - accuracy: 0.8359 - val_loss: 1.0471 - val_accuracy: 0.7188\n",
      "Epoch 51/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.5714 - accuracy: 0.8464 - val_loss: 1.0079 - val_accuracy: 0.7031\n",
      "Epoch 52/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.5369 - accuracy: 0.8529 - val_loss: 1.0048 - val_accuracy: 0.7031\n",
      "Epoch 53/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5960 - accuracy: 0.8398 - val_loss: 0.9853 - val_accuracy: 0.7083\n",
      "Epoch 54/80\n",
      "192/192 [==============================] - 5s 29ms/step - loss: 0.5414 - accuracy: 0.8581 - val_loss: 1.0169 - val_accuracy: 0.7083\n",
      "Epoch 55/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.5916 - accuracy: 0.8307 - val_loss: 1.0627 - val_accuracy: 0.6823\n",
      "Epoch 56/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.4909 - accuracy: 0.8802 - val_loss: 1.0447 - val_accuracy: 0.6823\n",
      "Epoch 57/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.5343 - accuracy: 0.8490 - val_loss: 1.0261 - val_accuracy: 0.6875\n",
      "Epoch 58/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.5725 - accuracy: 0.8529 - val_loss: 1.0170 - val_accuracy: 0.7188\n",
      "Epoch 59/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.5287 - accuracy: 0.8737 - val_loss: 1.0147 - val_accuracy: 0.6979\n",
      "Epoch 60/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4746 - accuracy: 0.8867 - val_loss: 1.0912 - val_accuracy: 0.6771\n",
      "Epoch 61/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5494 - accuracy: 0.8581 - val_loss: 1.0472 - val_accuracy: 0.7083\n",
      "Epoch 62/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5893 - accuracy: 0.8490 - val_loss: 1.0407 - val_accuracy: 0.7135\n",
      "Epoch 63/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.5413 - accuracy: 0.8607 - val_loss: 1.0079 - val_accuracy: 0.7083\n",
      "Epoch 64/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.4431 - accuracy: 0.9036 - val_loss: 0.9987 - val_accuracy: 0.6927\n",
      "Epoch 65/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.4933 - accuracy: 0.8711 - val_loss: 1.0311 - val_accuracy: 0.6823\n",
      "Epoch 66/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.4615 - accuracy: 0.8867 - val_loss: 1.0396 - val_accuracy: 0.7135\n",
      "Epoch 67/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.4873 - accuracy: 0.8711 - val_loss: 1.1010 - val_accuracy: 0.6979\n",
      "Epoch 68/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.4874 - accuracy: 0.8672 - val_loss: 1.0302 - val_accuracy: 0.7344\n",
      "Epoch 69/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.4708 - accuracy: 0.8737 - val_loss: 1.0308 - val_accuracy: 0.7135\n",
      "Epoch 70/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.4633 - accuracy: 0.8984 - val_loss: 1.0429 - val_accuracy: 0.6667\n",
      "Epoch 71/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.4348 - accuracy: 0.8828 - val_loss: 1.0668 - val_accuracy: 0.6927\n",
      "Epoch 72/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.4739 - accuracy: 0.8854 - val_loss: 1.0757 - val_accuracy: 0.6823\n",
      "Epoch 73/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5017 - accuracy: 0.8646 - val_loss: 1.0877 - val_accuracy: 0.6979\n",
      "Epoch 74/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4967 - accuracy: 0.8724 - val_loss: 1.0705 - val_accuracy: 0.6719\n",
      "Epoch 75/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.4331 - accuracy: 0.8906 - val_loss: 1.0498 - val_accuracy: 0.7031\n",
      "Epoch 76/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4662 - accuracy: 0.8737 - val_loss: 1.1341 - val_accuracy: 0.6823\n",
      "Epoch 77/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.4332 - accuracy: 0.8932 - val_loss: 1.0883 - val_accuracy: 0.7135\n",
      "Epoch 78/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4618 - accuracy: 0.8776 - val_loss: 1.0842 - val_accuracy: 0.7031\n",
      "Epoch 79/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.5440 - accuracy: 0.8464 - val_loss: 1.1151 - val_accuracy: 0.6771\n",
      "Epoch 80/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.4802 - accuracy: 0.8776 - val_loss: 1.0497 - val_accuracy: 0.6927\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.9501 - accuracy: 0.6979\n"
     ]
    }
   ],
   "source": [
    "VALIDATION_ACCURACY_SPEECH = []\n",
    "VALIDATION_LOSS_SPEECH = []\n",
    "\n",
    "save_dir = os.path.abspath(DIR) + '/ravdess_60m40f_earlyfusion_PCA_n0.95_model/'\n",
    "fold_var = 1\n",
    "\n",
    "for train_idx, val_idx in kfold.split(concatenated_train_data, y_train_60m_40f):\n",
    "    model=multi_modal_NN()\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
    "\n",
    "    #early_stopping_callback = EarlyStopping(monitor = 'val_accuracy', patience = 15, restore_best_weights = True)\n",
    "\n",
    "    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(save_dir + get_model_name(fold_var), monitor='val_accuracy',save_best_only=True, mode='max')\n",
    "# Start training the model.\n",
    "    LRCN_model_training_history = model.fit(      x = concatenated_train_data[train_idx],\n",
    "                                                  y = y_train_60m_40f[train_idx],\n",
    "                                                  validation_data=(concatenated_train_data[val_idx], y_train_60m_40f[val_idx]),\n",
    "                                                  epochs = 80,\n",
    "                                                  batch_size = 4,\n",
    "                                                  shuffle = True,\n",
    "                                                  callbacks = [checkpoint_cb])\n",
    "    model.load_weights(save_dir + \"model_\" + str(fold_var) + \".h5\")\n",
    "\t\n",
    "    results = model.evaluate(concatenated_test_data, y_test)\n",
    "    results = dict(zip(model.metrics_names, results))\n",
    "\t\n",
    "    VALIDATION_ACCURACY_SPEECH.append(results['accuracy'])\n",
    "    VALIDATION_LOSS_SPEECH.append(results['loss'])\n",
    "\t\n",
    "    tf.keras.backend.clear_session()\n",
    "\t\n",
    "    fold_var += 1\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5c074525-8e31-4fa0-981c-ce0bf7103f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_alexnet_1d():\n",
    "#     model = Sequential()\n",
    "\n",
    "#     # First Fully Connected Layer\n",
    "#     model.add(Dense(4096, input_shape=(966,)))  # Input shape matches your data\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Dropout(0.4))\n",
    "\n",
    "#     # Second Fully Connected Layer\n",
    "#     model.add(Dense(4096))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Dropout(0.4))\n",
    "\n",
    "#     # Third Fully Connected Layer\n",
    "#     model.add(Dense(1000))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Activation('relu'))\n",
    "#     model.add(Dropout(0.4))\n",
    "\n",
    "#     # Output Layer\n",
    "#     model.add(Dense(8))  # Number of classes in your output\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Activation('softmax'))\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "79ca064a-f9ca-40e0-b7c9-5b4352d46274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "240/240 [==============================] - 52s 196ms/step - loss: 2.0398 - accuracy: 0.2438 - val_loss: 2.0052 - val_accuracy: 0.3924\n",
      "Epoch 2/80\n",
      "240/240 [==============================] - 47s 194ms/step - loss: 1.6784 - accuracy: 0.3865 - val_loss: 1.4859 - val_accuracy: 0.4931\n",
      "Epoch 3/80\n",
      "240/240 [==============================] - 47s 196ms/step - loss: 1.4388 - accuracy: 0.4854 - val_loss: 1.3159 - val_accuracy: 0.5556\n",
      "Epoch 4/80\n",
      "240/240 [==============================] - 47s 195ms/step - loss: 1.2934 - accuracy: 0.5479 - val_loss: 1.2600 - val_accuracy: 0.5660\n",
      "Epoch 5/80\n",
      "240/240 [==============================] - 46s 192ms/step - loss: 1.2255 - accuracy: 0.6052 - val_loss: 1.1243 - val_accuracy: 0.6389\n",
      "Epoch 6/80\n",
      "183/240 [=====================>........] - ETA: 9s - loss: 1.1469 - accuracy: 0.5997 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[140], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m model_alexnet_1d()\n\u001b[1;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m LRCN_model_training_history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m          \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconcatenated_train_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_train_50m_50f\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconcatenated_test_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m80\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                                  \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model = model_alexnet_1d()\n",
    "\n",
    "# model.compile(loss='sparse_categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
    "\n",
    "# LRCN_model_training_history = model.fit(          x = concatenated_train_data,\n",
    "#                                                   y = y_train_50m_50f,\n",
    "#                                                   validation_data=(concatenated_test_data, y_test),\n",
    "#                                                   epochs = 80,\n",
    "#                                                   batch_size = 4,\n",
    "#                                                   shuffle = True)\n",
    "                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0737e955-70b1-4088-8bad-eafb031f351a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "192/192 [==============================] - 44s 212ms/step - loss: 2.0617 - accuracy: 0.2109 - val_loss: 1.9638 - val_accuracy: 0.3281\n",
      "Epoch 2/80\n",
      "192/192 [==============================] - 39s 203ms/step - loss: 1.6796 - accuracy: 0.3737 - val_loss: 1.5894 - val_accuracy: 0.4219\n",
      "Epoch 3/80\n",
      "192/192 [==============================] - 38s 198ms/step - loss: 1.4862 - accuracy: 0.4362 - val_loss: 1.2205 - val_accuracy: 0.6094\n",
      "Epoch 4/80\n",
      "192/192 [==============================] - 36s 186ms/step - loss: 1.3309 - accuracy: 0.5443 - val_loss: 1.2101 - val_accuracy: 0.5677\n",
      "Epoch 5/80\n",
      "192/192 [==============================] - 37s 195ms/step - loss: 1.1746 - accuracy: 0.6393 - val_loss: 1.2139 - val_accuracy: 0.5938\n",
      "Epoch 6/80\n",
      "192/192 [==============================] - 37s 191ms/step - loss: 1.1388 - accuracy: 0.6302 - val_loss: 1.2338 - val_accuracy: 0.5573\n",
      "Epoch 7/80\n",
      "192/192 [==============================] - 39s 204ms/step - loss: 1.0567 - accuracy: 0.7044 - val_loss: 1.1329 - val_accuracy: 0.6250\n",
      "Epoch 8/80\n",
      "192/192 [==============================] - 37s 191ms/step - loss: 1.0613 - accuracy: 0.6758 - val_loss: 1.2516 - val_accuracy: 0.5729\n",
      "Epoch 9/80\n",
      "192/192 [==============================] - 38s 196ms/step - loss: 1.0268 - accuracy: 0.7083 - val_loss: 1.1477 - val_accuracy: 0.6146\n",
      "Epoch 10/80\n",
      "192/192 [==============================] - 38s 200ms/step - loss: 0.9845 - accuracy: 0.7318 - val_loss: 1.1690 - val_accuracy: 0.5677\n",
      "Epoch 11/80\n",
      "192/192 [==============================] - 36s 188ms/step - loss: 0.9140 - accuracy: 0.7643 - val_loss: 1.0960 - val_accuracy: 0.5885\n",
      "Epoch 12/80\n",
      "192/192 [==============================] - 37s 195ms/step - loss: 0.9160 - accuracy: 0.7305 - val_loss: 1.2141 - val_accuracy: 0.5573\n",
      "Epoch 13/80\n",
      "192/192 [==============================] - 36s 189ms/step - loss: 0.9426 - accuracy: 0.7344 - val_loss: 1.1156 - val_accuracy: 0.6094\n",
      "Epoch 14/80\n",
      "192/192 [==============================] - 39s 203ms/step - loss: 0.9148 - accuracy: 0.7305 - val_loss: 1.1739 - val_accuracy: 0.6302\n",
      "Epoch 15/80\n",
      "192/192 [==============================] - 37s 193ms/step - loss: 0.8643 - accuracy: 0.7513 - val_loss: 1.1048 - val_accuracy: 0.6094\n",
      "Epoch 16/80\n",
      "192/192 [==============================] - 37s 193ms/step - loss: 0.8960 - accuracy: 0.7526 - val_loss: 1.1704 - val_accuracy: 0.5833\n",
      "Epoch 17/80\n",
      "192/192 [==============================] - 35s 184ms/step - loss: 0.8747 - accuracy: 0.7578 - val_loss: 1.0916 - val_accuracy: 0.6042\n",
      "Epoch 18/80\n",
      "192/192 [==============================] - 36s 186ms/step - loss: 0.8492 - accuracy: 0.7721 - val_loss: 1.1501 - val_accuracy: 0.5990\n",
      "Epoch 19/80\n",
      "192/192 [==============================] - 36s 186ms/step - loss: 0.8308 - accuracy: 0.7682 - val_loss: 1.2475 - val_accuracy: 0.5833\n",
      "Epoch 20/80\n",
      "192/192 [==============================] - 36s 188ms/step - loss: 0.8167 - accuracy: 0.7630 - val_loss: 1.2064 - val_accuracy: 0.5781\n",
      "Epoch 21/80\n",
      "192/192 [==============================] - 36s 189ms/step - loss: 0.7830 - accuracy: 0.7812 - val_loss: 1.3439 - val_accuracy: 0.5677\n",
      "Epoch 22/80\n",
      "192/192 [==============================] - 36s 185ms/step - loss: 0.7782 - accuracy: 0.8099 - val_loss: 1.2637 - val_accuracy: 0.5833\n",
      "Epoch 23/80\n",
      "192/192 [==============================] - 36s 190ms/step - loss: 0.7760 - accuracy: 0.7852 - val_loss: 1.2587 - val_accuracy: 0.5938\n",
      "Epoch 24/80\n",
      "192/192 [==============================] - 36s 189ms/step - loss: 0.7601 - accuracy: 0.7930 - val_loss: 1.1824 - val_accuracy: 0.6146\n",
      "Epoch 25/80\n",
      "192/192 [==============================] - 36s 187ms/step - loss: 0.7422 - accuracy: 0.7917 - val_loss: 1.2237 - val_accuracy: 0.6302\n",
      "Epoch 26/80\n",
      "192/192 [==============================] - 37s 193ms/step - loss: 0.7304 - accuracy: 0.8138 - val_loss: 1.1989 - val_accuracy: 0.6094\n",
      "Epoch 27/80\n",
      "192/192 [==============================] - 36s 187ms/step - loss: 0.7631 - accuracy: 0.7891 - val_loss: 1.2881 - val_accuracy: 0.5833\n",
      "Epoch 28/80\n",
      "192/192 [==============================] - 37s 192ms/step - loss: 0.7383 - accuracy: 0.7995 - val_loss: 1.1948 - val_accuracy: 0.6354\n",
      "Epoch 29/80\n",
      "192/192 [==============================] - 37s 191ms/step - loss: 0.7443 - accuracy: 0.8008 - val_loss: 1.2489 - val_accuracy: 0.6094\n",
      "Epoch 30/80\n",
      "192/192 [==============================] - 37s 192ms/step - loss: 0.7484 - accuracy: 0.7917 - val_loss: 1.2180 - val_accuracy: 0.5729\n",
      "Epoch 31/80\n",
      "192/192 [==============================] - 36s 187ms/step - loss: 0.7190 - accuracy: 0.7917 - val_loss: 1.2635 - val_accuracy: 0.5625\n",
      "Epoch 32/80\n",
      "192/192 [==============================] - 36s 190ms/step - loss: 0.6470 - accuracy: 0.8346 - val_loss: 1.2324 - val_accuracy: 0.5625\n",
      "Epoch 33/80\n",
      "192/192 [==============================] - 37s 194ms/step - loss: 0.6439 - accuracy: 0.8281 - val_loss: 1.1568 - val_accuracy: 0.6354\n",
      "Epoch 34/80\n",
      "192/192 [==============================] - 36s 189ms/step - loss: 0.6388 - accuracy: 0.8516 - val_loss: 1.1980 - val_accuracy: 0.5885\n",
      "Epoch 35/80\n",
      "192/192 [==============================] - 36s 187ms/step - loss: 0.6284 - accuracy: 0.8503 - val_loss: 1.2369 - val_accuracy: 0.5938\n",
      "Epoch 36/80\n",
      "192/192 [==============================] - 36s 185ms/step - loss: 0.6397 - accuracy: 0.8268 - val_loss: 1.2648 - val_accuracy: 0.5729\n",
      "Epoch 37/80\n",
      "192/192 [==============================] - 36s 188ms/step - loss: 0.6644 - accuracy: 0.8164 - val_loss: 1.2787 - val_accuracy: 0.6042\n",
      "Epoch 38/80\n",
      "192/192 [==============================] - 36s 186ms/step - loss: 0.6416 - accuracy: 0.8438 - val_loss: 1.2553 - val_accuracy: 0.5781\n",
      "Epoch 39/80\n",
      "192/192 [==============================] - 31s 163ms/step - loss: 0.6422 - accuracy: 0.8268 - val_loss: 1.3067 - val_accuracy: 0.5990\n",
      "Epoch 40/80\n",
      "192/192 [==============================] - 28s 145ms/step - loss: 0.6043 - accuracy: 0.8385 - val_loss: 1.2602 - val_accuracy: 0.6146\n",
      "Epoch 41/80\n",
      "192/192 [==============================] - 26s 138ms/step - loss: 0.6193 - accuracy: 0.8503 - val_loss: 1.2053 - val_accuracy: 0.6094\n",
      "Epoch 42/80\n",
      "192/192 [==============================] - 37s 193ms/step - loss: 0.5969 - accuracy: 0.8581 - val_loss: 1.2363 - val_accuracy: 0.5990\n",
      "Epoch 43/80\n",
      "192/192 [==============================] - 36s 188ms/step - loss: 0.5981 - accuracy: 0.8307 - val_loss: 1.1743 - val_accuracy: 0.6042\n",
      "Epoch 44/80\n",
      "192/192 [==============================] - 36s 188ms/step - loss: 0.5789 - accuracy: 0.8398 - val_loss: 1.2355 - val_accuracy: 0.5885\n",
      "Epoch 45/80\n",
      "192/192 [==============================] - 35s 181ms/step - loss: 0.5817 - accuracy: 0.8555 - val_loss: 1.1847 - val_accuracy: 0.5729\n",
      "Epoch 46/80\n",
      "192/192 [==============================] - 36s 187ms/step - loss: 0.5634 - accuracy: 0.8424 - val_loss: 1.2452 - val_accuracy: 0.6042\n",
      "Epoch 47/80\n",
      "192/192 [==============================] - 36s 186ms/step - loss: 0.5911 - accuracy: 0.8438 - val_loss: 1.3264 - val_accuracy: 0.5781\n",
      "Epoch 48/80\n",
      "192/192 [==============================] - 37s 191ms/step - loss: 0.5727 - accuracy: 0.8503 - val_loss: 1.2259 - val_accuracy: 0.5677\n",
      "Epoch 49/80\n",
      "192/192 [==============================] - 38s 196ms/step - loss: 0.5762 - accuracy: 0.8424 - val_loss: 1.1486 - val_accuracy: 0.6406\n",
      "Epoch 50/80\n",
      "192/192 [==============================] - 35s 182ms/step - loss: 0.5441 - accuracy: 0.8633 - val_loss: 1.1817 - val_accuracy: 0.6094\n",
      "Epoch 51/80\n",
      "192/192 [==============================] - 36s 189ms/step - loss: 0.6134 - accuracy: 0.8346 - val_loss: 1.1863 - val_accuracy: 0.6198\n",
      "Epoch 52/80\n",
      "192/192 [==============================] - 36s 186ms/step - loss: 0.5855 - accuracy: 0.8464 - val_loss: 1.1845 - val_accuracy: 0.6146\n",
      "Epoch 53/80\n",
      "192/192 [==============================] - 36s 189ms/step - loss: 0.5503 - accuracy: 0.8737 - val_loss: 1.1882 - val_accuracy: 0.6042\n",
      "Epoch 54/80\n",
      "192/192 [==============================] - 36s 186ms/step - loss: 0.5157 - accuracy: 0.8750 - val_loss: 1.2118 - val_accuracy: 0.5990\n",
      "Epoch 55/80\n",
      "192/192 [==============================] - 36s 188ms/step - loss: 0.5125 - accuracy: 0.8672 - val_loss: 1.1959 - val_accuracy: 0.6094\n",
      "Epoch 56/80\n",
      "192/192 [==============================] - 36s 189ms/step - loss: 0.5676 - accuracy: 0.8568 - val_loss: 1.2175 - val_accuracy: 0.6042\n",
      "Epoch 57/80\n",
      "192/192 [==============================] - 36s 186ms/step - loss: 0.5130 - accuracy: 0.8711 - val_loss: 1.2517 - val_accuracy: 0.6094\n",
      "Epoch 58/80\n",
      "192/192 [==============================] - 36s 188ms/step - loss: 0.5385 - accuracy: 0.8763 - val_loss: 1.2510 - val_accuracy: 0.6042\n",
      "Epoch 59/80\n",
      "192/192 [==============================] - 37s 193ms/step - loss: 0.5010 - accuracy: 0.8815 - val_loss: 1.1995 - val_accuracy: 0.6094\n",
      "Epoch 60/80\n",
      "192/192 [==============================] - 36s 189ms/step - loss: 0.5288 - accuracy: 0.8594 - val_loss: 1.2734 - val_accuracy: 0.5677\n",
      "Epoch 61/80\n",
      "192/192 [==============================] - 35s 184ms/step - loss: 0.4765 - accuracy: 0.8893 - val_loss: 1.3152 - val_accuracy: 0.5677\n",
      "Epoch 62/80\n",
      "192/192 [==============================] - 37s 192ms/step - loss: 0.5208 - accuracy: 0.8633 - val_loss: 1.2581 - val_accuracy: 0.6042\n",
      "Epoch 63/80\n",
      "192/192 [==============================] - 35s 181ms/step - loss: 0.4784 - accuracy: 0.8828 - val_loss: 1.2523 - val_accuracy: 0.6250\n",
      "Epoch 64/80\n",
      "192/192 [==============================] - 36s 188ms/step - loss: 0.5008 - accuracy: 0.8711 - val_loss: 1.2724 - val_accuracy: 0.6302\n",
      "Epoch 65/80\n",
      "192/192 [==============================] - 36s 190ms/step - loss: 0.4509 - accuracy: 0.8984 - val_loss: 1.2442 - val_accuracy: 0.6042\n",
      "Epoch 66/80\n",
      "192/192 [==============================] - 35s 182ms/step - loss: 0.4399 - accuracy: 0.8971 - val_loss: 1.2539 - val_accuracy: 0.6302\n",
      "Epoch 67/80\n",
      "192/192 [==============================] - 36s 186ms/step - loss: 0.4441 - accuracy: 0.9062 - val_loss: 1.2549 - val_accuracy: 0.6250\n",
      "Epoch 68/80\n",
      "192/192 [==============================] - 37s 192ms/step - loss: 0.4116 - accuracy: 0.9141 - val_loss: 1.3114 - val_accuracy: 0.5938\n",
      "Epoch 69/80\n",
      "192/192 [==============================] - 35s 184ms/step - loss: 0.4699 - accuracy: 0.9010 - val_loss: 1.2647 - val_accuracy: 0.6094\n",
      "Epoch 70/80\n",
      "192/192 [==============================] - 37s 192ms/step - loss: 0.4441 - accuracy: 0.8971 - val_loss: 1.3224 - val_accuracy: 0.6042\n",
      "Epoch 71/80\n",
      "192/192 [==============================] - 36s 189ms/step - loss: 0.4060 - accuracy: 0.9193 - val_loss: 1.2938 - val_accuracy: 0.5938\n",
      "Epoch 72/80\n",
      "192/192 [==============================] - 35s 185ms/step - loss: 0.4595 - accuracy: 0.8919 - val_loss: 1.2715 - val_accuracy: 0.5833\n",
      "Epoch 73/80\n",
      "192/192 [==============================] - 37s 193ms/step - loss: 0.4415 - accuracy: 0.8971 - val_loss: 1.2880 - val_accuracy: 0.6146\n",
      "Epoch 74/80\n",
      "192/192 [==============================] - 36s 187ms/step - loss: 0.4467 - accuracy: 0.8971 - val_loss: 1.3701 - val_accuracy: 0.6094\n",
      "Epoch 75/80\n",
      "192/192 [==============================] - 35s 184ms/step - loss: 0.4282 - accuracy: 0.8906 - val_loss: 1.3656 - val_accuracy: 0.6042\n",
      "Epoch 76/80\n",
      "192/192 [==============================] - 36s 189ms/step - loss: 0.4735 - accuracy: 0.8841 - val_loss: 1.3467 - val_accuracy: 0.5833\n",
      "Epoch 77/80\n",
      "192/192 [==============================] - 36s 190ms/step - loss: 0.4177 - accuracy: 0.9062 - val_loss: 1.3713 - val_accuracy: 0.5990\n",
      "Epoch 78/80\n",
      "192/192 [==============================] - 35s 185ms/step - loss: 0.3882 - accuracy: 0.9206 - val_loss: 1.3903 - val_accuracy: 0.5938\n",
      "Epoch 79/80\n",
      "192/192 [==============================] - 37s 192ms/step - loss: 0.4440 - accuracy: 0.9102 - val_loss: 1.3137 - val_accuracy: 0.6146\n",
      "Epoch 80/80\n",
      "192/192 [==============================] - 37s 190ms/step - loss: 0.3756 - accuracy: 0.9206 - val_loss: 1.3845 - val_accuracy: 0.6146\n",
      "9/9 [==============================] - 1s 21ms/step - loss: 0.9337 - accuracy: 0.7014\n",
      "Epoch 1/80\n",
      "192/192 [==============================] - 42s 196ms/step - loss: 2.1127 - accuracy: 0.2148 - val_loss: 2.2935 - val_accuracy: 0.3698\n",
      "Epoch 2/80\n",
      "192/192 [==============================] - 38s 199ms/step - loss: 1.6687 - accuracy: 0.3958 - val_loss: 1.6894 - val_accuracy: 0.4375\n",
      "Epoch 3/80\n",
      "192/192 [==============================] - 38s 198ms/step - loss: 1.4900 - accuracy: 0.4688 - val_loss: 1.3221 - val_accuracy: 0.5677\n",
      "Epoch 4/80\n",
      "192/192 [==============================] - 38s 197ms/step - loss: 1.3545 - accuracy: 0.5169 - val_loss: 1.1657 - val_accuracy: 0.5833\n",
      "Epoch 5/80\n",
      "192/192 [==============================] - 34s 176ms/step - loss: 1.2581 - accuracy: 0.5469 - val_loss: 1.2258 - val_accuracy: 0.5729\n",
      "Epoch 6/80\n",
      "192/192 [==============================] - 32s 169ms/step - loss: 1.1965 - accuracy: 0.6224 - val_loss: 1.1196 - val_accuracy: 0.6146\n",
      "Epoch 7/80\n",
      "192/192 [==============================] - 26s 136ms/step - loss: 1.0940 - accuracy: 0.6784 - val_loss: 1.1039 - val_accuracy: 0.6146\n",
      "Epoch 8/80\n",
      "192/192 [==============================] - 25s 133ms/step - loss: 1.1043 - accuracy: 0.6745 - val_loss: 1.2746 - val_accuracy: 0.5781\n",
      "Epoch 9/80\n",
      "192/192 [==============================] - 30s 156ms/step - loss: 1.0352 - accuracy: 0.6888 - val_loss: 1.1423 - val_accuracy: 0.6146\n",
      "Epoch 10/80\n",
      "192/192 [==============================] - 41s 211ms/step - loss: 0.9682 - accuracy: 0.7422 - val_loss: 1.1722 - val_accuracy: 0.5625\n",
      "Epoch 11/80\n",
      "192/192 [==============================] - 43s 223ms/step - loss: 0.9470 - accuracy: 0.7331 - val_loss: 1.0955 - val_accuracy: 0.6458\n",
      "Epoch 12/80\n",
      "192/192 [==============================] - 41s 215ms/step - loss: 0.9533 - accuracy: 0.7318 - val_loss: 1.0963 - val_accuracy: 0.6458\n",
      "Epoch 13/80\n",
      "192/192 [==============================] - 42s 221ms/step - loss: 0.9491 - accuracy: 0.7461 - val_loss: 1.0262 - val_accuracy: 0.6719\n",
      "Epoch 14/80\n",
      "192/192 [==============================] - 42s 217ms/step - loss: 0.9056 - accuracy: 0.7487 - val_loss: 1.0859 - val_accuracy: 0.6302\n",
      "Epoch 15/80\n",
      "192/192 [==============================] - 41s 213ms/step - loss: 0.9202 - accuracy: 0.7122 - val_loss: 1.0840 - val_accuracy: 0.6094\n",
      "Epoch 16/80\n",
      "192/192 [==============================] - 41s 212ms/step - loss: 0.8789 - accuracy: 0.7461 - val_loss: 1.0742 - val_accuracy: 0.6146\n",
      "Epoch 17/80\n",
      "192/192 [==============================] - 41s 213ms/step - loss: 0.8867 - accuracy: 0.7578 - val_loss: 1.0623 - val_accuracy: 0.6667\n",
      "Epoch 18/80\n",
      "192/192 [==============================] - 41s 213ms/step - loss: 0.8595 - accuracy: 0.7552 - val_loss: 1.0540 - val_accuracy: 0.6406\n",
      "Epoch 19/80\n",
      "192/192 [==============================] - 43s 222ms/step - loss: 0.7682 - accuracy: 0.8021 - val_loss: 1.0197 - val_accuracy: 0.6823\n",
      "Epoch 20/80\n",
      "192/192 [==============================] - 42s 217ms/step - loss: 0.8394 - accuracy: 0.7487 - val_loss: 1.0369 - val_accuracy: 0.6406\n",
      "Epoch 21/80\n",
      "192/192 [==============================] - 40s 209ms/step - loss: 0.7816 - accuracy: 0.7826 - val_loss: 0.9955 - val_accuracy: 0.6458\n",
      "Epoch 22/80\n",
      "192/192 [==============================] - 42s 217ms/step - loss: 0.8011 - accuracy: 0.7812 - val_loss: 1.0234 - val_accuracy: 0.6510\n",
      "Epoch 23/80\n",
      "192/192 [==============================] - 41s 211ms/step - loss: 0.7541 - accuracy: 0.8008 - val_loss: 1.0822 - val_accuracy: 0.6458\n",
      "Epoch 24/80\n",
      "192/192 [==============================] - 41s 211ms/step - loss: 0.7805 - accuracy: 0.7786 - val_loss: 1.0223 - val_accuracy: 0.6615\n",
      "Epoch 25/80\n",
      "192/192 [==============================] - 40s 210ms/step - loss: 0.8686 - accuracy: 0.7240 - val_loss: 1.0764 - val_accuracy: 0.6354\n",
      "Epoch 26/80\n",
      "192/192 [==============================] - 40s 208ms/step - loss: 0.7458 - accuracy: 0.7799 - val_loss: 1.0019 - val_accuracy: 0.6719\n",
      "Epoch 27/80\n",
      "192/192 [==============================] - 42s 217ms/step - loss: 0.7713 - accuracy: 0.7747 - val_loss: 0.9646 - val_accuracy: 0.6719\n",
      "Epoch 28/80\n",
      "192/192 [==============================] - 41s 214ms/step - loss: 0.6900 - accuracy: 0.8008 - val_loss: 1.0124 - val_accuracy: 0.6458\n",
      "Epoch 29/80\n",
      "192/192 [==============================] - 40s 210ms/step - loss: 0.6874 - accuracy: 0.8255 - val_loss: 1.0107 - val_accuracy: 0.6510\n",
      "Epoch 30/80\n",
      "192/192 [==============================] - 43s 226ms/step - loss: 0.6926 - accuracy: 0.8125 - val_loss: 1.0172 - val_accuracy: 0.6927\n",
      "Epoch 31/80\n",
      "192/192 [==============================] - 40s 207ms/step - loss: 0.7194 - accuracy: 0.8086 - val_loss: 1.0326 - val_accuracy: 0.6354\n",
      "Epoch 32/80\n",
      "192/192 [==============================] - 41s 212ms/step - loss: 0.6798 - accuracy: 0.8268 - val_loss: 1.0330 - val_accuracy: 0.6562\n",
      "Epoch 33/80\n",
      "192/192 [==============================] - 42s 216ms/step - loss: 0.6631 - accuracy: 0.8190 - val_loss: 1.0588 - val_accuracy: 0.6562\n",
      "Epoch 34/80\n",
      "192/192 [==============================] - 40s 208ms/step - loss: 0.7010 - accuracy: 0.8151 - val_loss: 1.0844 - val_accuracy: 0.6250\n",
      "Epoch 35/80\n",
      "192/192 [==============================] - 42s 220ms/step - loss: 0.6894 - accuracy: 0.8021 - val_loss: 1.0157 - val_accuracy: 0.6979\n",
      "Epoch 36/80\n",
      "192/192 [==============================] - 41s 214ms/step - loss: 0.6415 - accuracy: 0.8112 - val_loss: 1.0198 - val_accuracy: 0.6562\n",
      "Epoch 37/80\n",
      "192/192 [==============================] - 41s 212ms/step - loss: 0.6381 - accuracy: 0.8372 - val_loss: 1.0087 - val_accuracy: 0.6458\n",
      "Epoch 38/80\n",
      "192/192 [==============================] - 41s 212ms/step - loss: 0.6501 - accuracy: 0.8216 - val_loss: 1.0481 - val_accuracy: 0.6302\n",
      "Epoch 39/80\n",
      "192/192 [==============================] - 41s 215ms/step - loss: 0.6236 - accuracy: 0.8294 - val_loss: 1.0315 - val_accuracy: 0.6042\n",
      "Epoch 40/80\n",
      "192/192 [==============================] - 40s 211ms/step - loss: 0.6886 - accuracy: 0.8164 - val_loss: 1.0122 - val_accuracy: 0.6615\n",
      "Epoch 41/80\n",
      "192/192 [==============================] - 39s 206ms/step - loss: 0.6843 - accuracy: 0.8190 - val_loss: 1.0184 - val_accuracy: 0.6198\n",
      "Epoch 42/80\n",
      "192/192 [==============================] - 40s 206ms/step - loss: 0.6265 - accuracy: 0.8424 - val_loss: 1.0248 - val_accuracy: 0.6667\n",
      "Epoch 43/80\n",
      "192/192 [==============================] - 40s 208ms/step - loss: 0.6512 - accuracy: 0.8320 - val_loss: 1.0863 - val_accuracy: 0.6406\n",
      "Epoch 44/80\n",
      "192/192 [==============================] - 40s 210ms/step - loss: 0.5889 - accuracy: 0.8633 - val_loss: 1.1046 - val_accuracy: 0.6510\n",
      "Epoch 45/80\n",
      "192/192 [==============================] - 36s 185ms/step - loss: 0.6081 - accuracy: 0.8307 - val_loss: 1.0575 - val_accuracy: 0.6510\n",
      "Epoch 46/80\n",
      "192/192 [==============================] - 35s 185ms/step - loss: 0.6164 - accuracy: 0.8359 - val_loss: 1.0537 - val_accuracy: 0.6562\n",
      "Epoch 47/80\n",
      "192/192 [==============================] - 41s 213ms/step - loss: 0.6172 - accuracy: 0.8516 - val_loss: 1.1057 - val_accuracy: 0.6771\n",
      "Epoch 48/80\n",
      "192/192 [==============================] - 40s 210ms/step - loss: 0.6093 - accuracy: 0.8346 - val_loss: 1.0786 - val_accuracy: 0.6615\n",
      "Epoch 49/80\n",
      "192/192 [==============================] - 41s 211ms/step - loss: 0.5576 - accuracy: 0.8646 - val_loss: 1.0718 - val_accuracy: 0.6667\n",
      "Epoch 50/80\n",
      "192/192 [==============================] - 40s 207ms/step - loss: 0.5320 - accuracy: 0.8607 - val_loss: 1.0766 - val_accuracy: 0.6406\n",
      "Epoch 51/80\n",
      "192/192 [==============================] - 41s 212ms/step - loss: 0.5214 - accuracy: 0.8711 - val_loss: 1.1533 - val_accuracy: 0.5885\n",
      "Epoch 52/80\n",
      "192/192 [==============================] - 40s 207ms/step - loss: 0.5715 - accuracy: 0.8464 - val_loss: 1.0827 - val_accuracy: 0.6458\n",
      "Epoch 53/80\n",
      "192/192 [==============================] - 40s 211ms/step - loss: 0.5485 - accuracy: 0.8815 - val_loss: 1.0485 - val_accuracy: 0.6615\n",
      "Epoch 54/80\n",
      "192/192 [==============================] - 40s 207ms/step - loss: 0.6004 - accuracy: 0.8594 - val_loss: 1.0962 - val_accuracy: 0.6458\n",
      "Epoch 55/80\n",
      "192/192 [==============================] - 41s 210ms/step - loss: 0.5259 - accuracy: 0.8659 - val_loss: 1.0762 - val_accuracy: 0.6302\n",
      "Epoch 56/80\n",
      "192/192 [==============================] - 40s 207ms/step - loss: 0.5516 - accuracy: 0.8568 - val_loss: 1.0856 - val_accuracy: 0.6354\n",
      "Epoch 57/80\n",
      "192/192 [==============================] - 41s 212ms/step - loss: 0.5115 - accuracy: 0.8711 - val_loss: 1.1152 - val_accuracy: 0.6094\n",
      "Epoch 58/80\n",
      "192/192 [==============================] - 40s 210ms/step - loss: 0.5905 - accuracy: 0.8581 - val_loss: 1.1177 - val_accuracy: 0.5833\n",
      "Epoch 59/80\n",
      "192/192 [==============================] - 40s 207ms/step - loss: 0.5325 - accuracy: 0.8685 - val_loss: 1.0404 - val_accuracy: 0.6510\n",
      "Epoch 60/80\n",
      "192/192 [==============================] - 42s 217ms/step - loss: 0.5492 - accuracy: 0.8542 - val_loss: 1.0793 - val_accuracy: 0.6406\n",
      "Epoch 61/80\n",
      "192/192 [==============================] - 41s 211ms/step - loss: 0.5153 - accuracy: 0.8750 - val_loss: 1.1621 - val_accuracy: 0.6094\n",
      "Epoch 62/80\n",
      "192/192 [==============================] - 40s 207ms/step - loss: 0.4587 - accuracy: 0.9036 - val_loss: 1.1148 - val_accuracy: 0.6094\n",
      "Epoch 63/80\n",
      "192/192 [==============================] - 40s 207ms/step - loss: 0.4982 - accuracy: 0.8815 - val_loss: 1.0574 - val_accuracy: 0.6146\n",
      "Epoch 64/80\n",
      "192/192 [==============================] - 40s 211ms/step - loss: 0.5566 - accuracy: 0.8633 - val_loss: 1.0687 - val_accuracy: 0.6250\n",
      "Epoch 65/80\n",
      "192/192 [==============================] - 41s 212ms/step - loss: 0.5089 - accuracy: 0.8815 - val_loss: 1.0935 - val_accuracy: 0.6198\n",
      "Epoch 66/80\n",
      "192/192 [==============================] - 41s 213ms/step - loss: 0.5145 - accuracy: 0.8776 - val_loss: 1.1162 - val_accuracy: 0.6302\n",
      "Epoch 67/80\n",
      "192/192 [==============================] - 41s 214ms/step - loss: 0.4941 - accuracy: 0.8776 - val_loss: 1.0244 - val_accuracy: 0.6562\n",
      "Epoch 68/80\n",
      "192/192 [==============================] - 41s 212ms/step - loss: 0.5195 - accuracy: 0.8711 - val_loss: 1.0680 - val_accuracy: 0.6562\n",
      "Epoch 69/80\n",
      "192/192 [==============================] - 41s 214ms/step - loss: 0.4861 - accuracy: 0.8893 - val_loss: 1.0558 - val_accuracy: 0.6458\n",
      "Epoch 70/80\n",
      "192/192 [==============================] - 41s 212ms/step - loss: 0.5169 - accuracy: 0.8789 - val_loss: 1.0576 - val_accuracy: 0.6562\n",
      "Epoch 71/80\n",
      "192/192 [==============================] - 41s 211ms/step - loss: 0.4370 - accuracy: 0.9167 - val_loss: 1.0464 - val_accuracy: 0.6615\n",
      "Epoch 72/80\n",
      "192/192 [==============================] - 40s 209ms/step - loss: 0.4266 - accuracy: 0.8984 - val_loss: 1.0784 - val_accuracy: 0.6667\n",
      "Epoch 73/80\n",
      "192/192 [==============================] - 40s 208ms/step - loss: 0.4837 - accuracy: 0.8906 - val_loss: 1.0925 - val_accuracy: 0.6562\n",
      "Epoch 74/80\n",
      "192/192 [==============================] - 41s 212ms/step - loss: 0.4614 - accuracy: 0.8945 - val_loss: 1.0966 - val_accuracy: 0.6354\n",
      "Epoch 75/80\n",
      "192/192 [==============================] - 41s 214ms/step - loss: 0.4542 - accuracy: 0.8867 - val_loss: 1.0715 - val_accuracy: 0.6667\n",
      "Epoch 76/80\n",
      "192/192 [==============================] - 39s 205ms/step - loss: 0.4694 - accuracy: 0.8828 - val_loss: 1.0606 - val_accuracy: 0.6562\n",
      "Epoch 77/80\n",
      "192/192 [==============================] - 41s 211ms/step - loss: 0.4600 - accuracy: 0.8802 - val_loss: 1.0904 - val_accuracy: 0.6354\n",
      "Epoch 78/80\n",
      "192/192 [==============================] - 41s 215ms/step - loss: 0.3827 - accuracy: 0.9310 - val_loss: 1.0808 - val_accuracy: 0.6823\n",
      "Epoch 79/80\n",
      "192/192 [==============================] - 40s 211ms/step - loss: 0.4198 - accuracy: 0.8971 - val_loss: 1.1029 - val_accuracy: 0.6250\n",
      "Epoch 80/80\n",
      "192/192 [==============================] - 40s 208ms/step - loss: 0.4795 - accuracy: 0.8724 - val_loss: 1.0935 - val_accuracy: 0.6302\n",
      "9/9 [==============================] - 1s 19ms/step - loss: 0.9848 - accuracy: 0.6632\n",
      "Epoch 1/80\n",
      "192/192 [==============================] - 45s 218ms/step - loss: 2.0127 - accuracy: 0.2214 - val_loss: 1.8926 - val_accuracy: 0.3542\n",
      "Epoch 2/80\n",
      "192/192 [==============================] - 41s 212ms/step - loss: 1.6930 - accuracy: 0.3620 - val_loss: 1.5908 - val_accuracy: 0.3958\n",
      "Epoch 3/80\n",
      "192/192 [==============================] - 36s 190ms/step - loss: 1.4650 - accuracy: 0.4622 - val_loss: 1.3101 - val_accuracy: 0.5208\n",
      "Epoch 4/80\n",
      "192/192 [==============================] - 40s 209ms/step - loss: 1.3527 - accuracy: 0.5065 - val_loss: 1.4054 - val_accuracy: 0.5156\n",
      "Epoch 5/80\n",
      "192/192 [==============================] - 42s 217ms/step - loss: 1.2428 - accuracy: 0.5625 - val_loss: 1.2973 - val_accuracy: 0.5573\n",
      "Epoch 6/80\n",
      "192/192 [==============================] - 43s 224ms/step - loss: 1.1973 - accuracy: 0.5859 - val_loss: 1.1185 - val_accuracy: 0.6094\n",
      "Epoch 7/80\n",
      "192/192 [==============================] - 41s 216ms/step - loss: 1.1248 - accuracy: 0.6367 - val_loss: 1.0686 - val_accuracy: 0.6354\n",
      "Epoch 8/80\n",
      "192/192 [==============================] - 42s 220ms/step - loss: 1.0614 - accuracy: 0.6693 - val_loss: 1.0377 - val_accuracy: 0.6510\n",
      "Epoch 9/80\n",
      "192/192 [==============================] - 40s 210ms/step - loss: 1.0188 - accuracy: 0.7070 - val_loss: 1.0302 - val_accuracy: 0.6250\n",
      "Epoch 10/80\n",
      "192/192 [==============================] - 40s 209ms/step - loss: 0.9758 - accuracy: 0.7357 - val_loss: 1.0624 - val_accuracy: 0.6250\n",
      "Epoch 11/80\n",
      "192/192 [==============================] - 40s 209ms/step - loss: 0.9505 - accuracy: 0.7174 - val_loss: 1.0368 - val_accuracy: 0.6458\n",
      "Epoch 12/80\n",
      "192/192 [==============================] - 41s 214ms/step - loss: 0.9658 - accuracy: 0.7148 - val_loss: 1.0340 - val_accuracy: 0.6354\n",
      "Epoch 13/80\n",
      "192/192 [==============================] - 41s 215ms/step - loss: 0.9729 - accuracy: 0.7161 - val_loss: 1.0189 - val_accuracy: 0.6667\n",
      "Epoch 14/80\n",
      "192/192 [==============================] - 40s 206ms/step - loss: 0.9298 - accuracy: 0.7174 - val_loss: 1.0486 - val_accuracy: 0.6615\n",
      "Epoch 15/80\n",
      "192/192 [==============================] - 40s 209ms/step - loss: 0.9361 - accuracy: 0.7370 - val_loss: 1.0400 - val_accuracy: 0.6562\n",
      "Epoch 16/80\n",
      "192/192 [==============================] - 40s 209ms/step - loss: 0.8606 - accuracy: 0.7734 - val_loss: 1.0980 - val_accuracy: 0.6406\n",
      "Epoch 17/80\n",
      "192/192 [==============================] - 39s 205ms/step - loss: 0.8705 - accuracy: 0.7487 - val_loss: 1.1323 - val_accuracy: 0.6250\n",
      "Epoch 18/80\n",
      "192/192 [==============================] - 40s 210ms/step - loss: 0.8634 - accuracy: 0.7461 - val_loss: 1.0529 - val_accuracy: 0.6562\n",
      "Epoch 19/80\n",
      "192/192 [==============================] - 40s 209ms/step - loss: 0.8077 - accuracy: 0.7773 - val_loss: 1.0102 - val_accuracy: 0.6719\n",
      "Epoch 20/80\n",
      "192/192 [==============================] - 41s 212ms/step - loss: 0.8437 - accuracy: 0.7773 - val_loss: 1.0203 - val_accuracy: 0.6719\n",
      "Epoch 21/80\n",
      "192/192 [==============================] - 41s 213ms/step - loss: 0.7423 - accuracy: 0.7956 - val_loss: 1.0604 - val_accuracy: 0.6771\n",
      "Epoch 22/80\n",
      "192/192 [==============================] - 39s 202ms/step - loss: 0.8038 - accuracy: 0.7656 - val_loss: 1.0629 - val_accuracy: 0.6354\n",
      "Epoch 23/80\n",
      "192/192 [==============================] - 41s 212ms/step - loss: 0.7752 - accuracy: 0.7891 - val_loss: 1.0634 - val_accuracy: 0.6615\n",
      "Epoch 24/80\n",
      "192/192 [==============================] - 39s 204ms/step - loss: 0.7822 - accuracy: 0.7799 - val_loss: 1.0366 - val_accuracy: 0.6719\n",
      "Epoch 25/80\n",
      "192/192 [==============================] - 41s 213ms/step - loss: 0.7855 - accuracy: 0.7878 - val_loss: 1.0398 - val_accuracy: 0.6927\n",
      "Epoch 26/80\n",
      "192/192 [==============================] - 40s 207ms/step - loss: 0.7491 - accuracy: 0.7917 - val_loss: 1.0302 - val_accuracy: 0.6615\n",
      "Epoch 27/80\n",
      "192/192 [==============================] - 41s 212ms/step - loss: 0.7325 - accuracy: 0.7943 - val_loss: 1.0301 - val_accuracy: 0.6719\n",
      "Epoch 28/80\n",
      "192/192 [==============================] - 40s 209ms/step - loss: 0.7090 - accuracy: 0.8203 - val_loss: 1.0268 - val_accuracy: 0.6823\n",
      "Epoch 29/80\n",
      "192/192 [==============================] - 39s 202ms/step - loss: 0.7550 - accuracy: 0.7878 - val_loss: 1.1352 - val_accuracy: 0.6094\n",
      "Epoch 30/80\n",
      "192/192 [==============================] - 38s 199ms/step - loss: 0.7460 - accuracy: 0.7799 - val_loss: 1.0944 - val_accuracy: 0.6458\n",
      "Epoch 31/80\n",
      "192/192 [==============================] - 38s 200ms/step - loss: 0.7074 - accuracy: 0.8164 - val_loss: 1.1055 - val_accuracy: 0.6354\n",
      "Epoch 32/80\n",
      "192/192 [==============================] - 38s 198ms/step - loss: 0.6592 - accuracy: 0.8229 - val_loss: 1.1432 - val_accuracy: 0.5729\n",
      "Epoch 33/80\n",
      "192/192 [==============================] - 39s 203ms/step - loss: 0.7308 - accuracy: 0.8099 - val_loss: 1.0940 - val_accuracy: 0.6094\n",
      "Epoch 34/80\n",
      "192/192 [==============================] - 40s 208ms/step - loss: 0.6875 - accuracy: 0.8242 - val_loss: 1.2478 - val_accuracy: 0.5885\n",
      "Epoch 35/80\n",
      "192/192 [==============================] - 40s 209ms/step - loss: 0.6633 - accuracy: 0.8138 - val_loss: 1.1352 - val_accuracy: 0.6302\n",
      "Epoch 36/80\n",
      "192/192 [==============================] - 40s 207ms/step - loss: 0.6574 - accuracy: 0.8411 - val_loss: 1.1633 - val_accuracy: 0.6094\n",
      "Epoch 37/80\n",
      "192/192 [==============================] - 39s 205ms/step - loss: 0.6518 - accuracy: 0.8451 - val_loss: 1.0698 - val_accuracy: 0.6250\n",
      "Epoch 38/80\n",
      "192/192 [==============================] - 39s 203ms/step - loss: 0.6400 - accuracy: 0.8177 - val_loss: 1.1086 - val_accuracy: 0.6354\n",
      "Epoch 39/80\n",
      "192/192 [==============================] - 40s 206ms/step - loss: 0.6208 - accuracy: 0.8411 - val_loss: 1.1000 - val_accuracy: 0.6250\n",
      "Epoch 40/80\n",
      "192/192 [==============================] - 37s 191ms/step - loss: 0.6473 - accuracy: 0.8138 - val_loss: 1.1440 - val_accuracy: 0.6302\n",
      "Epoch 41/80\n",
      "192/192 [==============================] - 37s 191ms/step - loss: 0.6552 - accuracy: 0.8294 - val_loss: 1.1541 - val_accuracy: 0.6510\n",
      "Epoch 42/80\n",
      "192/192 [==============================] - 40s 209ms/step - loss: 0.7115 - accuracy: 0.8138 - val_loss: 1.1404 - val_accuracy: 0.6042\n",
      "Epoch 43/80\n",
      "192/192 [==============================] - 40s 210ms/step - loss: 0.6051 - accuracy: 0.8555 - val_loss: 1.1482 - val_accuracy: 0.6354\n",
      "Epoch 44/80\n",
      "192/192 [==============================] - 41s 212ms/step - loss: 0.5605 - accuracy: 0.8594 - val_loss: 1.0705 - val_accuracy: 0.6354\n",
      "Epoch 45/80\n",
      "192/192 [==============================] - 40s 208ms/step - loss: 0.5732 - accuracy: 0.8555 - val_loss: 1.0970 - val_accuracy: 0.6198\n",
      "Epoch 46/80\n",
      "192/192 [==============================] - 39s 204ms/step - loss: 0.5863 - accuracy: 0.8581 - val_loss: 1.0811 - val_accuracy: 0.6510\n",
      "Epoch 47/80\n",
      "192/192 [==============================] - 40s 209ms/step - loss: 0.5795 - accuracy: 0.8464 - val_loss: 1.0913 - val_accuracy: 0.6406\n",
      "Epoch 48/80\n",
      "192/192 [==============================] - 39s 206ms/step - loss: 0.5937 - accuracy: 0.8555 - val_loss: 1.1687 - val_accuracy: 0.6042\n",
      "Epoch 49/80\n",
      "192/192 [==============================] - 41s 211ms/step - loss: 0.5546 - accuracy: 0.8620 - val_loss: 1.0879 - val_accuracy: 0.6458\n",
      "Epoch 50/80\n",
      "192/192 [==============================] - 40s 209ms/step - loss: 0.6076 - accuracy: 0.8281 - val_loss: 0.9791 - val_accuracy: 0.6667\n",
      "Epoch 51/80\n",
      "192/192 [==============================] - 39s 204ms/step - loss: 0.6463 - accuracy: 0.8255 - val_loss: 1.0282 - val_accuracy: 0.6406\n",
      "Epoch 52/80\n",
      "192/192 [==============================] - 40s 207ms/step - loss: 0.5424 - accuracy: 0.8698 - val_loss: 0.9922 - val_accuracy: 0.6667\n",
      "Epoch 53/80\n",
      "192/192 [==============================] - 40s 207ms/step - loss: 0.5650 - accuracy: 0.8581 - val_loss: 1.0224 - val_accuracy: 0.6771\n",
      "Epoch 54/80\n",
      "192/192 [==============================] - 40s 210ms/step - loss: 0.5483 - accuracy: 0.8477 - val_loss: 1.0450 - val_accuracy: 0.6562\n",
      "Epoch 55/80\n",
      "192/192 [==============================] - 40s 206ms/step - loss: 0.5520 - accuracy: 0.8555 - val_loss: 0.9783 - val_accuracy: 0.6562\n",
      "Epoch 56/80\n",
      "192/192 [==============================] - 40s 207ms/step - loss: 0.4975 - accuracy: 0.8854 - val_loss: 0.9708 - val_accuracy: 0.6615\n",
      "Epoch 57/80\n",
      "192/192 [==============================] - 39s 205ms/step - loss: 0.4901 - accuracy: 0.8802 - val_loss: 1.0034 - val_accuracy: 0.6510\n",
      "Epoch 58/80\n",
      "192/192 [==============================] - 39s 203ms/step - loss: 0.4642 - accuracy: 0.8906 - val_loss: 1.0275 - val_accuracy: 0.6615\n",
      "Epoch 59/80\n",
      "192/192 [==============================] - 40s 207ms/step - loss: 0.5044 - accuracy: 0.8672 - val_loss: 1.1130 - val_accuracy: 0.6562\n",
      "Epoch 60/80\n",
      "192/192 [==============================] - 39s 204ms/step - loss: 0.5444 - accuracy: 0.8542 - val_loss: 1.0656 - val_accuracy: 0.6510\n",
      "Epoch 61/80\n",
      "192/192 [==============================] - 41s 212ms/step - loss: 0.5076 - accuracy: 0.8828 - val_loss: 1.0605 - val_accuracy: 0.6562\n",
      "Epoch 62/80\n",
      "192/192 [==============================] - 39s 204ms/step - loss: 0.4812 - accuracy: 0.8906 - val_loss: 1.0270 - val_accuracy: 0.6562\n",
      "Epoch 63/80\n",
      "192/192 [==============================] - 39s 204ms/step - loss: 0.4648 - accuracy: 0.8984 - val_loss: 1.0202 - val_accuracy: 0.6510\n",
      "Epoch 64/80\n",
      "192/192 [==============================] - 40s 205ms/step - loss: 0.4737 - accuracy: 0.8880 - val_loss: 1.0872 - val_accuracy: 0.6667\n",
      "Epoch 65/80\n",
      "192/192 [==============================] - 39s 205ms/step - loss: 0.4512 - accuracy: 0.9062 - val_loss: 1.1405 - val_accuracy: 0.6615\n",
      "Epoch 66/80\n",
      "192/192 [==============================] - 41s 211ms/step - loss: 0.5016 - accuracy: 0.8711 - val_loss: 1.1645 - val_accuracy: 0.6406\n",
      "Epoch 67/80\n",
      "192/192 [==============================] - 39s 203ms/step - loss: 0.5353 - accuracy: 0.8646 - val_loss: 1.1445 - val_accuracy: 0.5938\n",
      "Epoch 68/80\n",
      "192/192 [==============================] - 40s 210ms/step - loss: 0.5114 - accuracy: 0.8815 - val_loss: 1.1150 - val_accuracy: 0.6510\n",
      "Epoch 69/80\n",
      "192/192 [==============================] - 40s 208ms/step - loss: 0.4149 - accuracy: 0.9115 - val_loss: 1.1164 - val_accuracy: 0.6146\n",
      "Epoch 70/80\n",
      "192/192 [==============================] - 40s 208ms/step - loss: 0.4944 - accuracy: 0.8750 - val_loss: 1.1376 - val_accuracy: 0.6302\n",
      "Epoch 71/80\n",
      "192/192 [==============================] - 40s 206ms/step - loss: 0.4712 - accuracy: 0.8854 - val_loss: 1.0921 - val_accuracy: 0.6302\n",
      "Epoch 72/80\n",
      "192/192 [==============================] - 40s 207ms/step - loss: 0.4912 - accuracy: 0.8971 - val_loss: 1.0453 - val_accuracy: 0.6198\n",
      "Epoch 73/80\n",
      "192/192 [==============================] - 40s 207ms/step - loss: 0.4583 - accuracy: 0.8841 - val_loss: 1.0137 - val_accuracy: 0.6406\n",
      "Epoch 74/80\n",
      "192/192 [==============================] - 41s 213ms/step - loss: 0.4220 - accuracy: 0.9049 - val_loss: 1.0223 - val_accuracy: 0.6510\n",
      "Epoch 75/80\n",
      "192/192 [==============================] - 41s 214ms/step - loss: 0.4163 - accuracy: 0.9076 - val_loss: 1.0448 - val_accuracy: 0.5990\n",
      "Epoch 76/80\n",
      "192/192 [==============================] - 40s 208ms/step - loss: 0.4380 - accuracy: 0.8854 - val_loss: 1.0732 - val_accuracy: 0.6042\n",
      "Epoch 77/80\n",
      "192/192 [==============================] - 39s 205ms/step - loss: 0.4013 - accuracy: 0.9049 - val_loss: 1.0824 - val_accuracy: 0.6198\n",
      "Epoch 78/80\n",
      "192/192 [==============================] - 39s 206ms/step - loss: 0.3966 - accuracy: 0.9062 - val_loss: 1.1006 - val_accuracy: 0.6146\n",
      "Epoch 79/80\n",
      "192/192 [==============================] - 35s 181ms/step - loss: 0.3986 - accuracy: 0.9180 - val_loss: 1.1078 - val_accuracy: 0.5885\n",
      "Epoch 80/80\n",
      "192/192 [==============================] - 39s 203ms/step - loss: 0.4308 - accuracy: 0.9010 - val_loss: 1.1112 - val_accuracy: 0.6458\n",
      "9/9 [==============================] - 1s 40ms/step - loss: 1.0604 - accuracy: 0.6285\n",
      "Epoch 1/80\n",
      "192/192 [==============================] - 45s 216ms/step - loss: 2.0282 - accuracy: 0.2174 - val_loss: 2.1432 - val_accuracy: 0.3125\n",
      "Epoch 2/80\n",
      "192/192 [==============================] - 43s 225ms/step - loss: 1.6769 - accuracy: 0.3659 - val_loss: 1.5471 - val_accuracy: 0.5156\n",
      "Epoch 3/80\n",
      "192/192 [==============================] - 42s 219ms/step - loss: 1.4490 - accuracy: 0.4674 - val_loss: 1.4550 - val_accuracy: 0.5469\n",
      "Epoch 4/80\n",
      "192/192 [==============================] - 41s 216ms/step - loss: 1.3117 - accuracy: 0.5443 - val_loss: 1.2501 - val_accuracy: 0.5573\n",
      "Epoch 5/80\n",
      "192/192 [==============================] - 43s 223ms/step - loss: 1.2287 - accuracy: 0.5885 - val_loss: 1.2141 - val_accuracy: 0.6094\n",
      "Epoch 6/80\n",
      "192/192 [==============================] - 42s 218ms/step - loss: 1.1909 - accuracy: 0.5924 - val_loss: 1.1855 - val_accuracy: 0.6198\n",
      "Epoch 7/80\n",
      "192/192 [==============================] - 42s 222ms/step - loss: 1.0942 - accuracy: 0.6458 - val_loss: 1.2070 - val_accuracy: 0.6354\n",
      "Epoch 8/80\n",
      "192/192 [==============================] - 41s 213ms/step - loss: 1.1149 - accuracy: 0.6276 - val_loss: 1.1058 - val_accuracy: 0.6354\n",
      "Epoch 9/80\n",
      "192/192 [==============================] - 39s 205ms/step - loss: 1.0108 - accuracy: 0.7070 - val_loss: 1.0719 - val_accuracy: 0.6198\n",
      "Epoch 10/80\n",
      "192/192 [==============================] - 41s 216ms/step - loss: 0.9921 - accuracy: 0.7331 - val_loss: 1.0327 - val_accuracy: 0.6458\n",
      "Epoch 11/80\n",
      "192/192 [==============================] - 39s 204ms/step - loss: 0.9834 - accuracy: 0.7214 - val_loss: 1.0928 - val_accuracy: 0.6146\n",
      "Epoch 12/80\n",
      "192/192 [==============================] - 40s 206ms/step - loss: 0.9504 - accuracy: 0.7227 - val_loss: 1.0927 - val_accuracy: 0.6198\n",
      "Epoch 13/80\n",
      "192/192 [==============================] - 40s 206ms/step - loss: 0.9273 - accuracy: 0.7253 - val_loss: 1.0703 - val_accuracy: 0.6250\n",
      "Epoch 14/80\n",
      "192/192 [==============================] - 40s 209ms/step - loss: 0.9371 - accuracy: 0.7188 - val_loss: 1.0879 - val_accuracy: 0.6354\n",
      "Epoch 15/80\n",
      "192/192 [==============================] - 40s 210ms/step - loss: 0.8764 - accuracy: 0.7539 - val_loss: 1.0977 - val_accuracy: 0.6458\n",
      "Epoch 16/80\n",
      "192/192 [==============================] - 39s 205ms/step - loss: 0.8909 - accuracy: 0.7513 - val_loss: 1.0754 - val_accuracy: 0.6094\n",
      "Epoch 17/80\n",
      "192/192 [==============================] - 41s 213ms/step - loss: 0.8504 - accuracy: 0.7591 - val_loss: 1.0777 - val_accuracy: 0.6562\n",
      "Epoch 18/80\n",
      "192/192 [==============================] - 40s 207ms/step - loss: 0.8485 - accuracy: 0.7630 - val_loss: 0.9889 - val_accuracy: 0.6510\n",
      "Epoch 19/80\n",
      "192/192 [==============================] - 42s 216ms/step - loss: 0.8384 - accuracy: 0.7539 - val_loss: 1.0094 - val_accuracy: 0.6615\n",
      "Epoch 20/80\n",
      "192/192 [==============================] - 41s 212ms/step - loss: 0.8106 - accuracy: 0.7656 - val_loss: 1.0725 - val_accuracy: 0.5938\n",
      "Epoch 21/80\n",
      "192/192 [==============================] - 40s 211ms/step - loss: 0.7467 - accuracy: 0.7982 - val_loss: 1.1325 - val_accuracy: 0.6198\n",
      "Epoch 22/80\n",
      "192/192 [==============================] - 40s 208ms/step - loss: 0.7951 - accuracy: 0.7734 - val_loss: 1.0526 - val_accuracy: 0.6615\n",
      "Epoch 23/80\n",
      "192/192 [==============================] - 41s 212ms/step - loss: 0.8283 - accuracy: 0.7643 - val_loss: 1.0194 - val_accuracy: 0.6719\n",
      "Epoch 24/80\n",
      "192/192 [==============================] - 39s 205ms/step - loss: 0.7319 - accuracy: 0.7969 - val_loss: 1.0284 - val_accuracy: 0.6562\n",
      "Epoch 25/80\n",
      "192/192 [==============================] - 40s 210ms/step - loss: 0.7633 - accuracy: 0.7773 - val_loss: 1.0585 - val_accuracy: 0.6198\n",
      "Epoch 26/80\n",
      "192/192 [==============================] - 40s 207ms/step - loss: 0.7349 - accuracy: 0.7969 - val_loss: 1.0881 - val_accuracy: 0.6667\n",
      "Epoch 27/80\n",
      "192/192 [==============================] - 40s 204ms/step - loss: 0.7150 - accuracy: 0.8021 - val_loss: 1.0622 - val_accuracy: 0.6562\n",
      "Epoch 28/80\n",
      "192/192 [==============================] - 39s 206ms/step - loss: 0.6646 - accuracy: 0.8255 - val_loss: 1.0661 - val_accuracy: 0.6510\n",
      "Epoch 29/80\n",
      "192/192 [==============================] - 41s 213ms/step - loss: 0.6691 - accuracy: 0.8060 - val_loss: 0.9961 - val_accuracy: 0.6875\n",
      "Epoch 30/80\n",
      "192/192 [==============================] - 40s 209ms/step - loss: 0.6559 - accuracy: 0.8359 - val_loss: 1.0855 - val_accuracy: 0.6562\n",
      "Epoch 31/80\n",
      "192/192 [==============================] - 41s 211ms/step - loss: 0.6859 - accuracy: 0.8151 - val_loss: 1.0619 - val_accuracy: 0.6406\n",
      "Epoch 32/80\n",
      "192/192 [==============================] - 40s 209ms/step - loss: 0.7182 - accuracy: 0.7930 - val_loss: 1.0694 - val_accuracy: 0.6562\n",
      "Epoch 33/80\n",
      "192/192 [==============================] - 40s 210ms/step - loss: 0.7066 - accuracy: 0.8203 - val_loss: 1.0131 - val_accuracy: 0.6667\n",
      "Epoch 34/80\n",
      "192/192 [==============================] - 39s 205ms/step - loss: 0.6954 - accuracy: 0.7969 - val_loss: 0.9584 - val_accuracy: 0.6823\n",
      "Epoch 35/80\n",
      "192/192 [==============================] - 40s 210ms/step - loss: 0.6779 - accuracy: 0.8086 - val_loss: 1.0022 - val_accuracy: 0.6667\n",
      "Epoch 36/80\n",
      "192/192 [==============================] - 37s 191ms/step - loss: 0.6962 - accuracy: 0.8112 - val_loss: 0.9750 - val_accuracy: 0.6615\n",
      "Epoch 37/80\n",
      "192/192 [==============================] - 36s 188ms/step - loss: 0.6836 - accuracy: 0.8125 - val_loss: 1.0627 - val_accuracy: 0.6771\n",
      "Epoch 38/80\n",
      "192/192 [==============================] - 40s 207ms/step - loss: 0.6241 - accuracy: 0.8568 - val_loss: 1.0159 - val_accuracy: 0.6719\n",
      "Epoch 39/80\n",
      "192/192 [==============================] - 40s 207ms/step - loss: 0.6018 - accuracy: 0.8464 - val_loss: 0.9721 - val_accuracy: 0.6771\n",
      "Epoch 40/80\n",
      "192/192 [==============================] - 42s 217ms/step - loss: 0.6322 - accuracy: 0.8229 - val_loss: 0.9692 - val_accuracy: 0.6979\n",
      "Epoch 41/80\n",
      "192/192 [==============================] - 40s 206ms/step - loss: 0.6091 - accuracy: 0.8542 - val_loss: 1.0333 - val_accuracy: 0.6719\n",
      "Epoch 42/80\n",
      "192/192 [==============================] - 40s 210ms/step - loss: 0.6175 - accuracy: 0.8320 - val_loss: 1.0517 - val_accuracy: 0.6615\n",
      "Epoch 43/80\n",
      "192/192 [==============================] - 41s 214ms/step - loss: 0.5762 - accuracy: 0.8659 - val_loss: 1.0050 - val_accuracy: 0.6562\n",
      "Epoch 44/80\n",
      "192/192 [==============================] - 40s 211ms/step - loss: 0.6075 - accuracy: 0.8477 - val_loss: 1.0233 - val_accuracy: 0.6875\n",
      "Epoch 45/80\n",
      "192/192 [==============================] - 40s 210ms/step - loss: 0.5521 - accuracy: 0.8698 - val_loss: 1.0465 - val_accuracy: 0.6979\n",
      "Epoch 46/80\n",
      "192/192 [==============================] - 40s 209ms/step - loss: 0.5862 - accuracy: 0.8529 - val_loss: 1.0352 - val_accuracy: 0.6615\n",
      "Epoch 47/80\n",
      "192/192 [==============================] - 41s 212ms/step - loss: 0.5245 - accuracy: 0.8607 - val_loss: 1.0187 - val_accuracy: 0.6562\n",
      "Epoch 48/80\n",
      "192/192 [==============================] - 40s 207ms/step - loss: 0.5212 - accuracy: 0.8750 - val_loss: 1.0040 - val_accuracy: 0.6875\n",
      "Epoch 49/80\n",
      "192/192 [==============================] - 41s 215ms/step - loss: 0.5503 - accuracy: 0.8646 - val_loss: 1.0564 - val_accuracy: 0.6615\n",
      "Epoch 50/80\n",
      "192/192 [==============================] - 41s 211ms/step - loss: 0.5601 - accuracy: 0.8659 - val_loss: 1.0689 - val_accuracy: 0.6615\n",
      "Epoch 51/80\n",
      "192/192 [==============================] - 40s 210ms/step - loss: 0.5449 - accuracy: 0.8698 - val_loss: 1.0152 - val_accuracy: 0.6771\n",
      "Epoch 52/80\n",
      "192/192 [==============================] - 40s 207ms/step - loss: 0.5177 - accuracy: 0.8841 - val_loss: 1.1145 - val_accuracy: 0.6562\n",
      "Epoch 53/80\n",
      "192/192 [==============================] - 41s 214ms/step - loss: 0.5365 - accuracy: 0.8646 - val_loss: 1.0065 - val_accuracy: 0.7031\n",
      "Epoch 54/80\n",
      "192/192 [==============================] - 41s 215ms/step - loss: 0.5157 - accuracy: 0.8607 - val_loss: 1.1007 - val_accuracy: 0.6510\n",
      "Epoch 55/80\n",
      "192/192 [==============================] - 39s 206ms/step - loss: 0.5138 - accuracy: 0.8867 - val_loss: 1.0432 - val_accuracy: 0.6510\n",
      "Epoch 56/80\n",
      "192/192 [==============================] - 41s 211ms/step - loss: 0.5256 - accuracy: 0.8685 - val_loss: 1.0432 - val_accuracy: 0.6823\n",
      "Epoch 57/80\n",
      "192/192 [==============================] - 41s 213ms/step - loss: 0.5301 - accuracy: 0.8646 - val_loss: 1.0980 - val_accuracy: 0.6667\n",
      "Epoch 58/80\n",
      "192/192 [==============================] - 40s 210ms/step - loss: 0.5300 - accuracy: 0.8659 - val_loss: 1.1201 - val_accuracy: 0.6510\n",
      "Epoch 59/80\n",
      "192/192 [==============================] - 41s 210ms/step - loss: 0.5669 - accuracy: 0.8581 - val_loss: 1.1262 - val_accuracy: 0.6667\n",
      "Epoch 60/80\n",
      "192/192 [==============================] - 40s 210ms/step - loss: 0.5400 - accuracy: 0.8568 - val_loss: 1.0932 - val_accuracy: 0.6771\n",
      "Epoch 61/80\n",
      "192/192 [==============================] - 40s 211ms/step - loss: 0.5255 - accuracy: 0.8659 - val_loss: 1.0857 - val_accuracy: 0.6510\n",
      "Epoch 62/80\n",
      "192/192 [==============================] - 40s 207ms/step - loss: 0.4936 - accuracy: 0.8932 - val_loss: 1.0486 - val_accuracy: 0.6458\n",
      "Epoch 63/80\n",
      "192/192 [==============================] - 40s 208ms/step - loss: 0.5053 - accuracy: 0.8763 - val_loss: 1.0918 - val_accuracy: 0.6927\n",
      "Epoch 64/80\n",
      "192/192 [==============================] - 40s 208ms/step - loss: 0.4829 - accuracy: 0.8880 - val_loss: 1.1295 - val_accuracy: 0.6406\n",
      "Epoch 65/80\n",
      "192/192 [==============================] - 39s 205ms/step - loss: 0.5034 - accuracy: 0.8659 - val_loss: 1.1361 - val_accuracy: 0.6302\n",
      "Epoch 66/80\n",
      "192/192 [==============================] - 40s 209ms/step - loss: 0.5127 - accuracy: 0.8815 - val_loss: 1.1212 - val_accuracy: 0.6354\n",
      "Epoch 67/80\n",
      "192/192 [==============================] - 39s 206ms/step - loss: 0.4592 - accuracy: 0.8867 - val_loss: 1.0593 - val_accuracy: 0.6406\n",
      "Epoch 68/80\n",
      "192/192 [==============================] - 39s 204ms/step - loss: 0.4460 - accuracy: 0.8893 - val_loss: 1.1546 - val_accuracy: 0.6354\n",
      "Epoch 69/80\n",
      "192/192 [==============================] - 40s 208ms/step - loss: 0.4759 - accuracy: 0.8776 - val_loss: 1.0773 - val_accuracy: 0.6302\n",
      "Epoch 70/80\n",
      "192/192 [==============================] - 41s 213ms/step - loss: 0.4928 - accuracy: 0.8867 - val_loss: 1.0472 - val_accuracy: 0.6510\n",
      "Epoch 71/80\n",
      "192/192 [==============================] - 40s 210ms/step - loss: 0.5222 - accuracy: 0.8698 - val_loss: 1.0562 - val_accuracy: 0.6458\n",
      "Epoch 72/80\n",
      "192/192 [==============================] - 40s 208ms/step - loss: 0.4799 - accuracy: 0.8750 - val_loss: 0.9770 - val_accuracy: 0.6719\n",
      "Epoch 73/80\n",
      "192/192 [==============================] - 40s 208ms/step - loss: 0.4147 - accuracy: 0.9089 - val_loss: 1.0230 - val_accuracy: 0.6406\n",
      "Epoch 74/80\n",
      "192/192 [==============================] - 39s 202ms/step - loss: 0.4134 - accuracy: 0.8958 - val_loss: 1.0634 - val_accuracy: 0.6458\n",
      "Epoch 75/80\n",
      "192/192 [==============================] - 36s 185ms/step - loss: 0.3980 - accuracy: 0.8997 - val_loss: 1.0715 - val_accuracy: 0.6615\n",
      "Epoch 76/80\n",
      "192/192 [==============================] - 40s 209ms/step - loss: 0.4334 - accuracy: 0.8997 - val_loss: 1.0750 - val_accuracy: 0.6510\n",
      "Epoch 77/80\n",
      "192/192 [==============================] - 41s 213ms/step - loss: 0.4113 - accuracy: 0.9023 - val_loss: 1.1039 - val_accuracy: 0.6354\n",
      "Epoch 78/80\n",
      "192/192 [==============================] - 40s 208ms/step - loss: 0.3992 - accuracy: 0.9141 - val_loss: 1.0662 - val_accuracy: 0.6562\n",
      "Epoch 79/80\n",
      "192/192 [==============================] - 39s 204ms/step - loss: 0.4524 - accuracy: 0.8919 - val_loss: 1.1042 - val_accuracy: 0.6562\n",
      "Epoch 80/80\n",
      "192/192 [==============================] - 40s 210ms/step - loss: 0.4065 - accuracy: 0.9049 - val_loss: 1.1400 - val_accuracy: 0.6510\n",
      "9/9 [==============================] - 1s 20ms/step - loss: 1.0504 - accuracy: 0.6250\n",
      "Epoch 1/80\n",
      "192/192 [==============================] - 46s 224ms/step - loss: 2.0794 - accuracy: 0.1979 - val_loss: 1.9895 - val_accuracy: 0.3698\n",
      "Epoch 2/80\n",
      "192/192 [==============================] - 42s 218ms/step - loss: 1.7179 - accuracy: 0.3698 - val_loss: 1.5430 - val_accuracy: 0.4531\n",
      "Epoch 3/80\n",
      "192/192 [==============================] - 43s 221ms/step - loss: 1.5132 - accuracy: 0.4557 - val_loss: 1.3067 - val_accuracy: 0.5417\n",
      "Epoch 4/80\n",
      "192/192 [==============================] - 41s 215ms/step - loss: 1.3721 - accuracy: 0.5417 - val_loss: 1.1621 - val_accuracy: 0.6094\n",
      "Epoch 5/80\n",
      "192/192 [==============================] - 41s 212ms/step - loss: 1.2629 - accuracy: 0.5703 - val_loss: 1.1766 - val_accuracy: 0.5938\n",
      "Epoch 6/80\n",
      "192/192 [==============================] - 40s 208ms/step - loss: 1.1826 - accuracy: 0.6159 - val_loss: 1.1628 - val_accuracy: 0.6042\n",
      "Epoch 7/80\n",
      "192/192 [==============================] - 41s 213ms/step - loss: 1.1276 - accuracy: 0.6315 - val_loss: 1.0509 - val_accuracy: 0.6406\n",
      "Epoch 8/80\n",
      "192/192 [==============================] - 42s 216ms/step - loss: 1.0494 - accuracy: 0.6953 - val_loss: 0.9820 - val_accuracy: 0.6823\n",
      "Epoch 9/80\n",
      "192/192 [==============================] - 40s 209ms/step - loss: 1.0188 - accuracy: 0.6888 - val_loss: 1.0073 - val_accuracy: 0.6562\n",
      "Epoch 10/80\n",
      "192/192 [==============================] - 40s 208ms/step - loss: 1.0013 - accuracy: 0.7174 - val_loss: 1.0201 - val_accuracy: 0.6510\n",
      "Epoch 11/80\n",
      "192/192 [==============================] - 40s 211ms/step - loss: 1.0118 - accuracy: 0.6979 - val_loss: 1.0910 - val_accuracy: 0.6406\n",
      "Epoch 12/80\n",
      "192/192 [==============================] - 41s 212ms/step - loss: 0.9508 - accuracy: 0.7240 - val_loss: 0.9762 - val_accuracy: 0.6823\n",
      "Epoch 13/80\n",
      "192/192 [==============================] - 40s 210ms/step - loss: 0.9178 - accuracy: 0.7565 - val_loss: 1.0248 - val_accuracy: 0.6198\n",
      "Epoch 14/80\n",
      "192/192 [==============================] - 41s 212ms/step - loss: 0.9511 - accuracy: 0.7279 - val_loss: 1.1261 - val_accuracy: 0.6562\n",
      "Epoch 15/80\n",
      "192/192 [==============================] - 40s 209ms/step - loss: 0.9354 - accuracy: 0.7344 - val_loss: 1.1112 - val_accuracy: 0.6146\n",
      "Epoch 16/80\n",
      "192/192 [==============================] - 40s 210ms/step - loss: 0.8969 - accuracy: 0.7331 - val_loss: 1.1311 - val_accuracy: 0.6250\n",
      "Epoch 17/80\n",
      "192/192 [==============================] - 39s 204ms/step - loss: 0.8872 - accuracy: 0.7539 - val_loss: 1.0672 - val_accuracy: 0.6719\n",
      "Epoch 18/80\n",
      "192/192 [==============================] - 40s 209ms/step - loss: 0.8564 - accuracy: 0.7721 - val_loss: 1.0434 - val_accuracy: 0.6406\n",
      "Epoch 19/80\n",
      "192/192 [==============================] - 41s 212ms/step - loss: 0.8233 - accuracy: 0.7643 - val_loss: 1.0525 - val_accuracy: 0.6406\n",
      "Epoch 20/80\n",
      "192/192 [==============================] - 40s 211ms/step - loss: 0.7805 - accuracy: 0.7669 - val_loss: 1.0155 - val_accuracy: 0.6406\n",
      "Epoch 21/80\n",
      "192/192 [==============================] - 40s 208ms/step - loss: 0.7832 - accuracy: 0.7799 - val_loss: 0.9606 - val_accuracy: 0.6667\n",
      "Epoch 22/80\n",
      "192/192 [==============================] - 39s 206ms/step - loss: 0.7981 - accuracy: 0.7812 - val_loss: 1.0321 - val_accuracy: 0.6667\n",
      "Epoch 23/80\n",
      "192/192 [==============================] - 41s 214ms/step - loss: 0.7839 - accuracy: 0.7943 - val_loss: 1.0180 - val_accuracy: 0.6823\n",
      "Epoch 24/80\n",
      "192/192 [==============================] - 40s 211ms/step - loss: 0.8521 - accuracy: 0.7682 - val_loss: 1.0982 - val_accuracy: 0.6510\n",
      "Epoch 25/80\n",
      "192/192 [==============================] - 41s 211ms/step - loss: 0.7826 - accuracy: 0.7812 - val_loss: 1.0619 - val_accuracy: 0.6146\n",
      "Epoch 26/80\n",
      "192/192 [==============================] - 40s 207ms/step - loss: 0.7318 - accuracy: 0.8151 - val_loss: 1.0838 - val_accuracy: 0.5938\n",
      "Epoch 27/80\n",
      "192/192 [==============================] - 40s 209ms/step - loss: 0.7614 - accuracy: 0.7786 - val_loss: 1.0185 - val_accuracy: 0.6510\n",
      "Epoch 28/80\n",
      "192/192 [==============================] - 41s 213ms/step - loss: 0.7588 - accuracy: 0.7852 - val_loss: 1.0567 - val_accuracy: 0.6354\n",
      "Epoch 29/80\n",
      "192/192 [==============================] - 41s 213ms/step - loss: 0.6842 - accuracy: 0.8008 - val_loss: 1.0371 - val_accuracy: 0.6510\n",
      "Epoch 30/80\n",
      "192/192 [==============================] - 40s 207ms/step - loss: 0.6854 - accuracy: 0.8177 - val_loss: 0.9836 - val_accuracy: 0.6510\n",
      "Epoch 31/80\n",
      "192/192 [==============================] - 39s 205ms/step - loss: 0.6945 - accuracy: 0.8125 - val_loss: 1.0125 - val_accuracy: 0.6771\n",
      "Epoch 32/80\n",
      "192/192 [==============================] - 36s 190ms/step - loss: 0.6894 - accuracy: 0.8138 - val_loss: 1.0557 - val_accuracy: 0.6510\n",
      "Epoch 33/80\n",
      "192/192 [==============================] - 32s 168ms/step - loss: 0.6693 - accuracy: 0.8112 - val_loss: 1.0566 - val_accuracy: 0.6562\n",
      "Epoch 34/80\n",
      "192/192 [==============================] - 26s 133ms/step - loss: 0.6978 - accuracy: 0.8060 - val_loss: 1.0868 - val_accuracy: 0.6198\n",
      "Epoch 35/80\n",
      "192/192 [==============================] - 26s 133ms/step - loss: 0.6828 - accuracy: 0.8034 - val_loss: 1.0698 - val_accuracy: 0.6354\n",
      "Epoch 36/80\n",
      "192/192 [==============================] - 39s 206ms/step - loss: 0.6733 - accuracy: 0.8229 - val_loss: 1.0303 - val_accuracy: 0.6875\n",
      "Epoch 37/80\n",
      "192/192 [==============================] - 38s 199ms/step - loss: 0.6407 - accuracy: 0.8177 - val_loss: 1.1289 - val_accuracy: 0.6875\n",
      "Epoch 38/80\n",
      "192/192 [==============================] - 39s 202ms/step - loss: 0.6251 - accuracy: 0.8359 - val_loss: 1.0198 - val_accuracy: 0.6458\n",
      "Epoch 39/80\n",
      "192/192 [==============================] - 38s 198ms/step - loss: 0.6201 - accuracy: 0.8542 - val_loss: 1.0402 - val_accuracy: 0.6667\n",
      "Epoch 40/80\n",
      "192/192 [==============================] - 38s 197ms/step - loss: 0.6509 - accuracy: 0.8333 - val_loss: 1.0583 - val_accuracy: 0.6354\n",
      "Epoch 41/80\n",
      "192/192 [==============================] - 37s 192ms/step - loss: 0.5685 - accuracy: 0.8581 - val_loss: 1.0779 - val_accuracy: 0.6667\n",
      "Epoch 42/80\n",
      "192/192 [==============================] - 38s 195ms/step - loss: 0.6206 - accuracy: 0.8385 - val_loss: 1.1067 - val_accuracy: 0.6406\n",
      "Epoch 43/80\n",
      "192/192 [==============================] - 38s 201ms/step - loss: 0.5524 - accuracy: 0.8750 - val_loss: 1.0949 - val_accuracy: 0.6458\n",
      "Epoch 44/80\n",
      "192/192 [==============================] - 38s 201ms/step - loss: 0.5505 - accuracy: 0.8724 - val_loss: 1.0724 - val_accuracy: 0.6510\n",
      "Epoch 45/80\n",
      "192/192 [==============================] - 38s 200ms/step - loss: 0.6513 - accuracy: 0.8268 - val_loss: 1.1258 - val_accuracy: 0.6510\n",
      "Epoch 46/80\n",
      "192/192 [==============================] - 37s 195ms/step - loss: 0.6923 - accuracy: 0.8151 - val_loss: 1.0411 - val_accuracy: 0.6510\n",
      "Epoch 47/80\n",
      "192/192 [==============================] - 38s 198ms/step - loss: 0.6260 - accuracy: 0.8516 - val_loss: 1.0085 - val_accuracy: 0.6250\n",
      "Epoch 48/80\n",
      "192/192 [==============================] - 36s 187ms/step - loss: 0.6087 - accuracy: 0.8372 - val_loss: 1.0193 - val_accuracy: 0.6302\n",
      "Epoch 49/80\n",
      "192/192 [==============================] - 38s 197ms/step - loss: 0.5540 - accuracy: 0.8854 - val_loss: 1.0379 - val_accuracy: 0.6667\n",
      "Epoch 50/80\n",
      "192/192 [==============================] - 37s 193ms/step - loss: 0.5773 - accuracy: 0.8633 - val_loss: 1.1186 - val_accuracy: 0.6510\n",
      "Epoch 51/80\n",
      "192/192 [==============================] - 36s 189ms/step - loss: 0.5754 - accuracy: 0.8411 - val_loss: 1.0506 - val_accuracy: 0.6667\n",
      "Epoch 52/80\n",
      "192/192 [==============================] - 37s 195ms/step - loss: 0.5324 - accuracy: 0.8711 - val_loss: 0.9554 - val_accuracy: 0.6875\n",
      "Epoch 53/80\n",
      "192/192 [==============================] - 37s 195ms/step - loss: 0.5442 - accuracy: 0.8646 - val_loss: 1.0103 - val_accuracy: 0.6667\n",
      "Epoch 54/80\n",
      "192/192 [==============================] - 38s 199ms/step - loss: 0.4986 - accuracy: 0.8893 - val_loss: 0.9889 - val_accuracy: 0.6719\n",
      "Epoch 55/80\n",
      "192/192 [==============================] - 38s 196ms/step - loss: 0.5614 - accuracy: 0.8503 - val_loss: 1.0286 - val_accuracy: 0.6354\n",
      "Epoch 56/80\n",
      "192/192 [==============================] - 38s 197ms/step - loss: 0.5550 - accuracy: 0.8542 - val_loss: 1.0540 - val_accuracy: 0.6354\n",
      "Epoch 57/80\n",
      "192/192 [==============================] - 39s 202ms/step - loss: 0.4732 - accuracy: 0.8971 - val_loss: 1.0309 - val_accuracy: 0.6719\n",
      "Epoch 58/80\n",
      "192/192 [==============================] - 39s 203ms/step - loss: 0.4989 - accuracy: 0.8776 - val_loss: 1.0261 - val_accuracy: 0.6406\n",
      "Epoch 59/80\n",
      "192/192 [==============================] - 39s 202ms/step - loss: 0.4617 - accuracy: 0.8867 - val_loss: 1.0467 - val_accuracy: 0.6510\n",
      "Epoch 60/80\n",
      "192/192 [==============================] - 39s 201ms/step - loss: 0.4460 - accuracy: 0.8971 - val_loss: 1.0006 - val_accuracy: 0.6562\n",
      "Epoch 61/80\n",
      "192/192 [==============================] - 38s 197ms/step - loss: 0.5315 - accuracy: 0.8698 - val_loss: 1.0290 - val_accuracy: 0.6615\n",
      "Epoch 62/80\n",
      "192/192 [==============================] - 40s 209ms/step - loss: 0.5980 - accuracy: 0.8568 - val_loss: 0.9779 - val_accuracy: 0.7083\n",
      "Epoch 63/80\n",
      "192/192 [==============================] - 38s 194ms/step - loss: 0.5223 - accuracy: 0.8659 - val_loss: 0.9382 - val_accuracy: 0.7083\n",
      "Epoch 64/80\n",
      "192/192 [==============================] - 37s 194ms/step - loss: 0.4946 - accuracy: 0.8880 - val_loss: 0.9449 - val_accuracy: 0.6979\n",
      "Epoch 65/80\n",
      "192/192 [==============================] - 39s 205ms/step - loss: 0.4303 - accuracy: 0.9049 - val_loss: 0.9643 - val_accuracy: 0.6927\n",
      "Epoch 66/80\n",
      "192/192 [==============================] - 40s 209ms/step - loss: 0.4995 - accuracy: 0.8776 - val_loss: 1.0153 - val_accuracy: 0.6771\n",
      "Epoch 67/80\n",
      "192/192 [==============================] - 42s 217ms/step - loss: 0.4633 - accuracy: 0.8971 - val_loss: 1.0144 - val_accuracy: 0.6719\n",
      "Epoch 68/80\n",
      "192/192 [==============================] - 40s 206ms/step - loss: 0.4625 - accuracy: 0.8880 - val_loss: 1.0152 - val_accuracy: 0.6667\n",
      "Epoch 69/80\n",
      "192/192 [==============================] - 42s 217ms/step - loss: 0.4636 - accuracy: 0.8893 - val_loss: 1.0273 - val_accuracy: 0.6823\n",
      "Epoch 70/80\n",
      "192/192 [==============================] - 40s 206ms/step - loss: 0.4802 - accuracy: 0.8815 - val_loss: 1.0037 - val_accuracy: 0.6719\n",
      "Epoch 71/80\n",
      "192/192 [==============================] - 39s 200ms/step - loss: 0.5052 - accuracy: 0.8802 - val_loss: 1.0076 - val_accuracy: 0.6562\n",
      "Epoch 72/80\n",
      "192/192 [==============================] - 40s 206ms/step - loss: 0.4726 - accuracy: 0.8841 - val_loss: 1.0061 - val_accuracy: 0.6771\n",
      "Epoch 73/80\n",
      "192/192 [==============================] - 40s 209ms/step - loss: 0.4584 - accuracy: 0.8854 - val_loss: 0.9939 - val_accuracy: 0.6823\n",
      "Epoch 74/80\n",
      "192/192 [==============================] - 40s 209ms/step - loss: 0.4402 - accuracy: 0.8906 - val_loss: 1.0135 - val_accuracy: 0.6615\n",
      "Epoch 75/80\n",
      "192/192 [==============================] - 40s 210ms/step - loss: 0.4166 - accuracy: 0.9206 - val_loss: 1.0872 - val_accuracy: 0.6146\n",
      "Epoch 76/80\n",
      "192/192 [==============================] - 37s 191ms/step - loss: 0.4400 - accuracy: 0.9036 - val_loss: 1.0115 - val_accuracy: 0.6771\n",
      "Epoch 77/80\n",
      "192/192 [==============================] - 35s 183ms/step - loss: 0.4365 - accuracy: 0.9023 - val_loss: 1.0085 - val_accuracy: 0.6771\n",
      "Epoch 78/80\n",
      "192/192 [==============================] - 41s 216ms/step - loss: 0.4138 - accuracy: 0.9154 - val_loss: 1.0142 - val_accuracy: 0.6823\n",
      "Epoch 79/80\n",
      "192/192 [==============================] - 41s 215ms/step - loss: 0.4717 - accuracy: 0.8841 - val_loss: 1.0672 - val_accuracy: 0.6510\n",
      "Epoch 80/80\n",
      "192/192 [==============================] - 41s 213ms/step - loss: 0.4520 - accuracy: 0.8919 - val_loss: 1.0203 - val_accuracy: 0.6771\n",
      "9/9 [==============================] - 1s 24ms/step - loss: 1.0217 - accuracy: 0.6528\n"
     ]
    }
   ],
   "source": [
    "# VALIDATION_ACCURACY_SPEECH = []\n",
    "# VALIDATION_LOSS_SPEECH = []\n",
    "\n",
    "# save_dir = os.path.abspath(DIR) + '/ravdess_50m50f_earlyfusion_PCA_n0.95_alexnet_model/'\n",
    "# fold_var = 1\n",
    "\n",
    "# for train_idx, val_idx in kfold.split(concatenated_train_data, y_train_50m_50f):\n",
    "#     model=model_alexnet_1d()\n",
    "\n",
    "#     model.compile(loss='sparse_categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
    "\n",
    "#     #early_stopping_callback = EarlyStopping(monitor = 'val_accuracy', patience = 15, restore_best_weights = True)\n",
    "\n",
    "#     checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(save_dir + get_model_name(fold_var), monitor='val_accuracy',save_best_only=True, mode='max')\n",
    "# # Start training the model.\n",
    "#     LRCN_model_training_history = model.fit(      x = concatenated_train_data[train_idx],\n",
    "#                                                   y = y_train_50m_50f[train_idx],\n",
    "#                                                   validation_data=(concatenated_train_data[val_idx], y_train_50m_50f[val_idx]),\n",
    "#                                                   epochs = 80,\n",
    "#                                                   batch_size = 4,\n",
    "#                                                   shuffle = True,\n",
    "#                                                   callbacks = [checkpoint_cb])\n",
    "#     model.load_weights(save_dir + \"model_\" + str(fold_var) + \".h5\")\n",
    "\t\n",
    "#     results = model.evaluate(concatenated_test_data, y_test)\n",
    "#     results = dict(zip(model.metrics_names, results))\n",
    "\t\n",
    "#     VALIDATION_ACCURACY_SPEECH.append(results['accuracy'])\n",
    "#     VALIDATION_LOSS_SPEECH.append(results['loss'])\n",
    "\t\n",
    "#     tf.keras.backend.clear_session()\n",
    "\t\n",
    "#     fold_var += 1\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf140757-7bdc-4223-9152-61b176876350",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intermediate Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f8898a1d-2c1b-46ab-af81-baf4c7a6e592",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "audio_indice = 1\n",
    "save_dir = os.path.abspath(DIR)+'/ravdess_60m40f_audio_model/'\n",
    "model_audio = model_alexnet()\n",
    "model_audio.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=[\"accuracy\"])\n",
    "model_audio.load_weights(save_dir +\"model_\"+str(audio_indice)+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "892f438a-a709-48c6-903c-4e3b5b63d5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Localization Network with input shape: (None, 48, 48, 1)\n",
      "Building Bilinear Interpolation Layer with input shape: ((None, 48, 48, 1), (None, 2, 3))\n"
     ]
    }
   ],
   "source": [
    "save_dir = os.path.abspath(DIR)+'/ravdess_60m40f_video_model/'\n",
    "video_indice = 5\n",
    "model_video = create__LRCN_with_STN()\n",
    "model_video.compile(loss='sparese_categorical_crossentropy', optimizer='Adam', metrics=[\"accuracy\"])\n",
    "model_video.load_weights(save_dir+\"model_\"+str(video_indice)+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "4a0b3d0b-9e57-4ce9-9a92-6a627d2778c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_video_model=Model(inputs=model_video.input, outputs=model_video.get_layer('time_distributed_2').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "033b5b4e-9b6b-432a-9541-a7b81a48572a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 14s 322ms/step\n"
     ]
    }
   ],
   "source": [
    "features_video=features_video_model.predict(X_train_60m_40f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "75e1cb8f-a3b9-4328-a9b9-a07e294cef13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 20, 1024)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1187a639-d60a-497f-87fe-6ec9d73286d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flattened = np.reshape(features_video, (960, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "32eaac2b-a2ce-4c05-97ae-bbd58d3ab64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 20480)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_flattened.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "920f6db1-5ae2-4b3a-a912-78d15acd4e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 3s 304ms/step\n"
     ]
    }
   ],
   "source": [
    "features_video_test = features_video_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "547c2ae1-7a11-4464-b762-440714cd9f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 20, 1024)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_video_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "13fc490c-056d-4bfd-8396-a6c801e5159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_flattened = np.reshape(features_video_test, (288, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "54275098-28f2-4f6b-b30d-96f54a6ae0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_audio_model=Model(inputs=model_audio.input, outputs=model_audio.get_layer('flatten').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "27a6fd00-3044-4656-b821-9f8f06a68d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 17s 532ms/step\n"
     ]
    }
   ],
   "source": [
    "features_audio=features_audio_model.predict(X_train_aud_60m_40f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b2527107-dce8-411e-8151-f721af970c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 262144)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5ee99bf9-e854-4d7b-8d94-021ba63d2175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 5s 592ms/step\n"
     ]
    }
   ],
   "source": [
    "features_audio_test = features_audio_model.predict(X_test_aud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a6dfb9af-159e-4a70-875b-da84c030a58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 262144)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_audio_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3a6e153e-1574-4f4e-8e94-178c4ce1dfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "video_scaler = StandardScaler().fit(X_train_flattened)\n",
    "video_data_standardized = video_scaler.fit_transform(X_train_flattened)\n",
    "video_data_standardized_test = video_scaler.fit_transform(X_test_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "7936ebbd-f46b-4242-ae27-542c7ff679bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_scaler = StandardScaler().fit(features_audio)\n",
    "audio_data_standardized = audio_scaler.fit_transform(features_audio)\n",
    "audio_data_standardized_test = audio_scaler.fit_transform(features_audio_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ec7bf76b-ef7e-429f-b216-069ae6c7729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca_video = PCA(n_components=0.95).fit(video_data_standardized)\n",
    "video_data_pca = pca_video.fit_transform(video_data_standardized)\n",
    "video_data_pca_test = pca_video.transform(video_data_standardized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "319d8c82-7a2e-4b6e-b491-1e05b6477739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 618)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_data_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5b2e8eb2-5baa-4f69-9bfa-7a2f570ba332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 618)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_data_pca_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b17cf154-0135-4dd8-8374-1cc2ee118009",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_audio = PCA(n_components=0.95).fit(audio_data_standardized)\n",
    "audio_data_pca = pca_audio.fit_transform(audio_data_standardized)\n",
    "audio_data_pca_test = pca_audio.transform(audio_data_standardized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8a0dbcef-fe07-4cc6-8ec4-9703f65c774a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 474)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_data_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "44f7e764-4d6e-4daa-8dad-9c6650e528b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 474)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_data_pca_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "ff64543e-d53b-4dbf-8e25-4fe3120dfd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_train_data = np.concatenate((video_data_pca, audio_data_pca), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6a20882a-b389-47c6-988d-87fc58436c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 1092)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "edcc1f3e-d454-446f-b90d-c50e79ac0fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_test_data = np.concatenate((video_data_pca_test, audio_data_pca_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3488efe3-7a15-4471-8a7c-b4a0dc792c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 1092)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "b3eb0c3f-0116-48cf-a700-8e051010023c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_modal_NN():\n",
    "  model=Sequential()\n",
    "  model.add(Input(shape=(1092)))\n",
    "  \n",
    "  model.add(Dense(2096))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dropout(0.4))\n",
    "\n",
    "  model.add(Dense(1024))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dropout(0.4))\n",
    "\n",
    "  model.add(Dense(8))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Activation('softmax'))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667cb785-2a56-4b11-b0fb-73ef0af93d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "192/192 [==============================] - 10s 36ms/step - loss: 1.7833 - accuracy: 0.3294 - val_loss: 1.0982 - val_accuracy: 0.6146\n",
      "Epoch 2/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 1.3645 - accuracy: 0.5286 - val_loss: 0.9882 - val_accuracy: 0.6667\n",
      "Epoch 3/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 1.2017 - accuracy: 0.6094 - val_loss: 0.9689 - val_accuracy: 0.7083\n",
      "Epoch 4/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 1.1953 - accuracy: 0.6133 - val_loss: 0.9512 - val_accuracy: 0.6927\n",
      "Epoch 5/80\n",
      "192/192 [==============================] - 7s 37ms/step - loss: 1.0859 - accuracy: 0.6641 - val_loss: 0.9256 - val_accuracy: 0.7396\n",
      "Epoch 6/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 1.0269 - accuracy: 0.7122 - val_loss: 0.8772 - val_accuracy: 0.7500\n",
      "Epoch 7/80\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 0.9731 - accuracy: 0.7227 - val_loss: 0.8552 - val_accuracy: 0.7500\n",
      "Epoch 8/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.9882 - accuracy: 0.6979 - val_loss: 0.8399 - val_accuracy: 0.7396\n",
      "Epoch 9/80\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 0.9811 - accuracy: 0.7044 - val_loss: 0.8037 - val_accuracy: 0.7604\n",
      "Epoch 10/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.9363 - accuracy: 0.7357 - val_loss: 0.8402 - val_accuracy: 0.7604\n",
      "Epoch 11/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.9090 - accuracy: 0.7474 - val_loss: 0.9018 - val_accuracy: 0.7135\n",
      "Epoch 12/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.8805 - accuracy: 0.7565 - val_loss: 0.8600 - val_accuracy: 0.7448\n",
      "Epoch 13/80\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 0.8498 - accuracy: 0.7656 - val_loss: 0.8165 - val_accuracy: 0.7760\n",
      "Epoch 14/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.7791 - accuracy: 0.8060 - val_loss: 0.8136 - val_accuracy: 0.7656\n",
      "Epoch 15/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.8166 - accuracy: 0.7552 - val_loss: 0.7619 - val_accuracy: 0.7500\n",
      "Epoch 16/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.8156 - accuracy: 0.7839 - val_loss: 0.8023 - val_accuracy: 0.7708\n",
      "Epoch 17/80\n",
      "192/192 [==============================] - 6s 34ms/step - loss: 0.8117 - accuracy: 0.7826 - val_loss: 0.7725 - val_accuracy: 0.7708\n",
      "Epoch 18/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.7762 - accuracy: 0.7812 - val_loss: 0.7743 - val_accuracy: 0.7552\n",
      "Epoch 19/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.7536 - accuracy: 0.7773 - val_loss: 0.7917 - val_accuracy: 0.7292\n",
      "Epoch 20/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.7332 - accuracy: 0.8047 - val_loss: 0.7826 - val_accuracy: 0.7656\n",
      "Epoch 21/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.7192 - accuracy: 0.8138 - val_loss: 0.8080 - val_accuracy: 0.7396\n",
      "Epoch 22/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.7297 - accuracy: 0.7956 - val_loss: 0.7914 - val_accuracy: 0.7396\n",
      "Epoch 23/80\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 0.7101 - accuracy: 0.8203 - val_loss: 0.7825 - val_accuracy: 0.7604\n",
      "Epoch 24/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.7086 - accuracy: 0.8047 - val_loss: 0.7589 - val_accuracy: 0.7552\n",
      "Epoch 25/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.7173 - accuracy: 0.7904 - val_loss: 0.7566 - val_accuracy: 0.7604\n",
      "Epoch 26/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.7120 - accuracy: 0.7995 - val_loss: 0.7581 - val_accuracy: 0.7708\n",
      "Epoch 27/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.6859 - accuracy: 0.7995 - val_loss: 0.8566 - val_accuracy: 0.7292\n",
      "Epoch 28/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.7192 - accuracy: 0.8177 - val_loss: 0.7918 - val_accuracy: 0.7604\n",
      "Epoch 29/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.6733 - accuracy: 0.8099 - val_loss: 0.7485 - val_accuracy: 0.7552\n",
      "Epoch 30/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.6511 - accuracy: 0.8177 - val_loss: 0.8042 - val_accuracy: 0.7292\n",
      "Epoch 31/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.6325 - accuracy: 0.8307 - val_loss: 0.7936 - val_accuracy: 0.7656\n",
      "Epoch 32/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.6133 - accuracy: 0.8372 - val_loss: 0.7654 - val_accuracy: 0.7396\n",
      "Epoch 33/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.6424 - accuracy: 0.8203 - val_loss: 0.7762 - val_accuracy: 0.7292\n",
      "Epoch 34/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.6146 - accuracy: 0.8451 - val_loss: 0.7676 - val_accuracy: 0.7240\n",
      "Epoch 35/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.6653 - accuracy: 0.8190 - val_loss: 0.7776 - val_accuracy: 0.7240\n",
      "Epoch 36/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.6143 - accuracy: 0.8307 - val_loss: 0.7901 - val_accuracy: 0.7344\n",
      "Epoch 37/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.6036 - accuracy: 0.8242 - val_loss: 0.8244 - val_accuracy: 0.7344\n",
      "Epoch 38/80\n",
      "192/192 [==============================] - 4s 18ms/step - loss: 0.6168 - accuracy: 0.8294 - val_loss: 0.8096 - val_accuracy: 0.7135\n",
      "Epoch 39/80\n",
      "192/192 [==============================] - 4s 18ms/step - loss: 0.6451 - accuracy: 0.8099 - val_loss: 0.8450 - val_accuracy: 0.7083\n",
      "Epoch 40/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.5495 - accuracy: 0.8724 - val_loss: 0.8238 - val_accuracy: 0.7188\n",
      "Epoch 41/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.5833 - accuracy: 0.8490 - val_loss: 0.7905 - val_accuracy: 0.7240\n",
      "Epoch 42/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.5870 - accuracy: 0.8542 - val_loss: 0.8140 - val_accuracy: 0.7344\n",
      "Epoch 43/80\n",
      "192/192 [==============================] - 4s 19ms/step - loss: 0.5655 - accuracy: 0.8503 - val_loss: 0.7873 - val_accuracy: 0.7344\n",
      "Epoch 44/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.5638 - accuracy: 0.8568 - val_loss: 0.8638 - val_accuracy: 0.7083\n",
      "Epoch 45/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.5729 - accuracy: 0.8451 - val_loss: 0.8310 - val_accuracy: 0.7083\n",
      "Epoch 46/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.5713 - accuracy: 0.8346 - val_loss: 0.8224 - val_accuracy: 0.7448\n",
      "Epoch 47/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.5230 - accuracy: 0.8620 - val_loss: 0.8317 - val_accuracy: 0.7344\n",
      "Epoch 48/80\n",
      "192/192 [==============================] - 7s 37ms/step - loss: 0.5688 - accuracy: 0.8555 - val_loss: 0.8373 - val_accuracy: 0.7344\n",
      "Epoch 49/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.5638 - accuracy: 0.8490 - val_loss: 0.8416 - val_accuracy: 0.7344\n",
      "Epoch 50/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5371 - accuracy: 0.8776 - val_loss: 0.8484 - val_accuracy: 0.7240\n",
      "Epoch 51/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.5523 - accuracy: 0.8633 - val_loss: 0.8288 - val_accuracy: 0.7552\n",
      "Epoch 52/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.5903 - accuracy: 0.8438 - val_loss: 0.8295 - val_accuracy: 0.7292\n",
      "Epoch 53/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.5499 - accuracy: 0.8633 - val_loss: 0.8141 - val_accuracy: 0.6979\n",
      "Epoch 54/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.5515 - accuracy: 0.8633 - val_loss: 0.8232 - val_accuracy: 0.7188\n",
      "Epoch 55/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.4944 - accuracy: 0.8815 - val_loss: 0.8035 - val_accuracy: 0.7135\n",
      "Epoch 56/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.5126 - accuracy: 0.8763 - val_loss: 0.7773 - val_accuracy: 0.7292\n",
      "Epoch 57/80\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 0.4500 - accuracy: 0.8945 - val_loss: 0.8156 - val_accuracy: 0.7188\n",
      "Epoch 58/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.5251 - accuracy: 0.8607 - val_loss: 0.8138 - val_accuracy: 0.7240\n",
      "Epoch 59/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.4847 - accuracy: 0.8685 - val_loss: 0.8125 - val_accuracy: 0.7240\n",
      "Epoch 60/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.5003 - accuracy: 0.8750 - val_loss: 0.7979 - val_accuracy: 0.7448\n",
      "Epoch 61/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4727 - accuracy: 0.8828 - val_loss: 0.7961 - val_accuracy: 0.7292\n",
      "Epoch 62/80\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 0.4678 - accuracy: 0.8776 - val_loss: 0.7904 - val_accuracy: 0.7292\n",
      "Epoch 63/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.4984 - accuracy: 0.8711 - val_loss: 0.8185 - val_accuracy: 0.7031\n",
      "Epoch 64/80\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 0.4908 - accuracy: 0.8581 - val_loss: 0.8078 - val_accuracy: 0.6979\n",
      "Epoch 65/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.4881 - accuracy: 0.8737 - val_loss: 0.8369 - val_accuracy: 0.7292\n",
      "Epoch 66/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.4870 - accuracy: 0.8802 - val_loss: 0.8168 - val_accuracy: 0.7135\n",
      "Epoch 67/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.4425 - accuracy: 0.8958 - val_loss: 0.8216 - val_accuracy: 0.7031\n",
      "Epoch 68/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.4803 - accuracy: 0.8867 - val_loss: 0.8436 - val_accuracy: 0.7031\n",
      "Epoch 69/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.4543 - accuracy: 0.8815 - val_loss: 0.8297 - val_accuracy: 0.7240\n",
      "Epoch 70/80\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 0.4464 - accuracy: 0.8919 - val_loss: 0.8756 - val_accuracy: 0.7188\n",
      "Epoch 71/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.4484 - accuracy: 0.8958 - val_loss: 0.8659 - val_accuracy: 0.7083\n",
      "Epoch 72/80\n",
      "192/192 [==============================] - 6s 34ms/step - loss: 0.4348 - accuracy: 0.8867 - val_loss: 0.8420 - val_accuracy: 0.7135\n",
      "Epoch 73/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.4587 - accuracy: 0.8919 - val_loss: 0.8800 - val_accuracy: 0.7135\n",
      "Epoch 74/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.4430 - accuracy: 0.8958 - val_loss: 0.8467 - val_accuracy: 0.7031\n",
      "Epoch 75/80\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 0.4733 - accuracy: 0.8880 - val_loss: 0.8429 - val_accuracy: 0.7188\n",
      "Epoch 76/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.4193 - accuracy: 0.8932 - val_loss: 0.8526 - val_accuracy: 0.7188\n",
      "Epoch 77/80\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 0.3908 - accuracy: 0.9102 - val_loss: 0.8773 - val_accuracy: 0.7240\n",
      "Epoch 78/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.3943 - accuracy: 0.9023 - val_loss: 0.8587 - val_accuracy: 0.7188\n",
      "Epoch 79/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.4348 - accuracy: 0.9062 - val_loss: 0.8707 - val_accuracy: 0.7083\n",
      "Epoch 80/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.4205 - accuracy: 0.9062 - val_loss: 0.8495 - val_accuracy: 0.7188\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.7686 - accuracy: 0.7500\n",
      "Epoch 1/80\n",
      "192/192 [==============================] - 10s 37ms/step - loss: 1.8025 - accuracy: 0.3242 - val_loss: 1.0134 - val_accuracy: 0.6823\n",
      "Epoch 2/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 1.3486 - accuracy: 0.5273 - val_loss: 0.8337 - val_accuracy: 0.7448\n",
      "Epoch 3/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 1.2193 - accuracy: 0.6107 - val_loss: 0.7997 - val_accuracy: 0.7760\n",
      "Epoch 4/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 1.1482 - accuracy: 0.6471 - val_loss: 0.7723 - val_accuracy: 0.7708\n",
      "Epoch 5/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 1.1114 - accuracy: 0.6562 - val_loss: 0.7546 - val_accuracy: 0.8073\n",
      "Epoch 6/80\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 1.0782 - accuracy: 0.6510 - val_loss: 0.7399 - val_accuracy: 0.7917\n",
      "Epoch 7/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 1.0130 - accuracy: 0.7188 - val_loss: 0.7395 - val_accuracy: 0.8021\n",
      "Epoch 8/80\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 1.0102 - accuracy: 0.7005 - val_loss: 0.6563 - val_accuracy: 0.8490\n",
      "Epoch 9/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.9469 - accuracy: 0.7201 - val_loss: 0.6763 - val_accuracy: 0.8281\n",
      "Epoch 10/80\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 0.9377 - accuracy: 0.7500 - val_loss: 0.6461 - val_accuracy: 0.8125\n",
      "Epoch 11/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.9190 - accuracy: 0.7409 - val_loss: 0.6710 - val_accuracy: 0.8281\n",
      "Epoch 12/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.8808 - accuracy: 0.7526 - val_loss: 0.5979 - val_accuracy: 0.8177\n",
      "Epoch 13/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.9054 - accuracy: 0.7344 - val_loss: 0.6326 - val_accuracy: 0.8281\n",
      "Epoch 14/80\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 0.8591 - accuracy: 0.7513 - val_loss: 0.6398 - val_accuracy: 0.8073\n",
      "Epoch 15/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.8148 - accuracy: 0.7812 - val_loss: 0.6210 - val_accuracy: 0.8125\n",
      "Epoch 16/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.8327 - accuracy: 0.7682 - val_loss: 0.6199 - val_accuracy: 0.8073\n",
      "Epoch 17/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.7680 - accuracy: 0.8021 - val_loss: 0.6166 - val_accuracy: 0.8177\n",
      "Epoch 18/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.7602 - accuracy: 0.7826 - val_loss: 0.6372 - val_accuracy: 0.8073\n",
      "Epoch 19/80\n",
      "192/192 [==============================] - 7s 39ms/step - loss: 0.7863 - accuracy: 0.7656 - val_loss: 0.6367 - val_accuracy: 0.8125\n",
      "Epoch 20/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.7724 - accuracy: 0.7839 - val_loss: 0.6349 - val_accuracy: 0.7969\n",
      "Epoch 21/80\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 0.7355 - accuracy: 0.8034 - val_loss: 0.6680 - val_accuracy: 0.8177\n",
      "Epoch 22/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.7139 - accuracy: 0.8060 - val_loss: 0.6712 - val_accuracy: 0.8021\n",
      "Epoch 23/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.7068 - accuracy: 0.8086 - val_loss: 0.6746 - val_accuracy: 0.8073\n",
      "Epoch 24/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.7421 - accuracy: 0.7930 - val_loss: 0.6515 - val_accuracy: 0.7865\n",
      "Epoch 25/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.7433 - accuracy: 0.7943 - val_loss: 0.6129 - val_accuracy: 0.7969\n",
      "Epoch 26/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.6640 - accuracy: 0.8398 - val_loss: 0.6163 - val_accuracy: 0.7969\n",
      "Epoch 27/80\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 0.6950 - accuracy: 0.8112 - val_loss: 0.5933 - val_accuracy: 0.8229\n",
      "Epoch 28/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.6669 - accuracy: 0.8138 - val_loss: 0.5768 - val_accuracy: 0.8125\n",
      "Epoch 29/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.6644 - accuracy: 0.8164 - val_loss: 0.5256 - val_accuracy: 0.8438\n",
      "Epoch 30/80\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 0.6249 - accuracy: 0.8359 - val_loss: 0.5143 - val_accuracy: 0.8385\n",
      "Epoch 31/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.6668 - accuracy: 0.8229 - val_loss: 0.5499 - val_accuracy: 0.8021\n",
      "Epoch 32/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.6401 - accuracy: 0.8242 - val_loss: 0.5800 - val_accuracy: 0.7969\n",
      "Epoch 33/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.6584 - accuracy: 0.8151 - val_loss: 0.5999 - val_accuracy: 0.8125\n",
      "Epoch 34/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.6396 - accuracy: 0.8320 - val_loss: 0.6231 - val_accuracy: 0.7969\n",
      "Epoch 35/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.6637 - accuracy: 0.8333 - val_loss: 0.6047 - val_accuracy: 0.8125\n",
      "Epoch 36/80\n",
      "192/192 [==============================] - 6s 34ms/step - loss: 0.6107 - accuracy: 0.8438 - val_loss: 0.6005 - val_accuracy: 0.8073\n",
      "Epoch 37/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.5525 - accuracy: 0.8711 - val_loss: 0.6028 - val_accuracy: 0.8021\n",
      "Epoch 38/80\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 0.6240 - accuracy: 0.8333 - val_loss: 0.5962 - val_accuracy: 0.8073\n",
      "Epoch 39/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.6065 - accuracy: 0.8542 - val_loss: 0.5810 - val_accuracy: 0.8177\n",
      "Epoch 40/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.6575 - accuracy: 0.8034 - val_loss: 0.6169 - val_accuracy: 0.7969\n",
      "Epoch 41/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.5734 - accuracy: 0.8607 - val_loss: 0.5964 - val_accuracy: 0.8073\n",
      "Epoch 42/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.6073 - accuracy: 0.8372 - val_loss: 0.6074 - val_accuracy: 0.7812\n",
      "Epoch 43/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.5141 - accuracy: 0.8711 - val_loss: 0.5725 - val_accuracy: 0.8281\n",
      "Epoch 44/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5613 - accuracy: 0.8542 - val_loss: 0.5788 - val_accuracy: 0.8177\n",
      "Epoch 45/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.5357 - accuracy: 0.8672 - val_loss: 0.5446 - val_accuracy: 0.8229\n",
      "Epoch 46/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.5727 - accuracy: 0.8464 - val_loss: 0.5796 - val_accuracy: 0.8385\n",
      "Epoch 47/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.5472 - accuracy: 0.8516 - val_loss: 0.5910 - val_accuracy: 0.8073\n",
      "Epoch 48/80\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 0.5563 - accuracy: 0.8542 - val_loss: 0.5811 - val_accuracy: 0.8229\n",
      "Epoch 49/80\n",
      "192/192 [==============================] - 6s 34ms/step - loss: 0.5881 - accuracy: 0.8385 - val_loss: 0.5260 - val_accuracy: 0.8333\n",
      "Epoch 50/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5291 - accuracy: 0.8672 - val_loss: 0.5326 - val_accuracy: 0.8281\n",
      "Epoch 51/80\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 0.4717 - accuracy: 0.8867 - val_loss: 0.5168 - val_accuracy: 0.8490\n",
      "Epoch 52/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.5027 - accuracy: 0.8633 - val_loss: 0.5323 - val_accuracy: 0.8594\n",
      "Epoch 53/80\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 0.5304 - accuracy: 0.8763 - val_loss: 0.5649 - val_accuracy: 0.8073\n",
      "Epoch 54/80\n",
      "192/192 [==============================] - 5s 29ms/step - loss: 0.5219 - accuracy: 0.8672 - val_loss: 0.5866 - val_accuracy: 0.7760\n",
      "Epoch 55/80\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 0.4884 - accuracy: 0.8776 - val_loss: 0.5871 - val_accuracy: 0.7969\n",
      "Epoch 56/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5581 - accuracy: 0.8542 - val_loss: 0.5528 - val_accuracy: 0.8177\n",
      "Epoch 57/80\n",
      "192/192 [==============================] - 6s 34ms/step - loss: 0.5101 - accuracy: 0.8724 - val_loss: 0.5938 - val_accuracy: 0.7917\n",
      "Epoch 58/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5709 - accuracy: 0.8477 - val_loss: 0.5774 - val_accuracy: 0.8125\n",
      "Epoch 59/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.4920 - accuracy: 0.8750 - val_loss: 0.5714 - val_accuracy: 0.8073\n",
      "Epoch 60/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5042 - accuracy: 0.8607 - val_loss: 0.5194 - val_accuracy: 0.8229\n",
      "Epoch 61/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.5023 - accuracy: 0.8763 - val_loss: 0.5542 - val_accuracy: 0.8281\n",
      "Epoch 62/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.4791 - accuracy: 0.8737 - val_loss: 0.5836 - val_accuracy: 0.8021\n",
      "Epoch 63/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.5538 - accuracy: 0.8620 - val_loss: 0.5797 - val_accuracy: 0.8125\n",
      "Epoch 64/80\n",
      "192/192 [==============================] - 5s 29ms/step - loss: 0.5453 - accuracy: 0.8490 - val_loss: 0.6105 - val_accuracy: 0.7917\n",
      "Epoch 65/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.4636 - accuracy: 0.8880 - val_loss: 0.5461 - val_accuracy: 0.7917\n",
      "Epoch 66/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.5241 - accuracy: 0.8568 - val_loss: 0.5653 - val_accuracy: 0.8073\n",
      "Epoch 67/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.4809 - accuracy: 0.8802 - val_loss: 0.5652 - val_accuracy: 0.8073\n",
      "Epoch 68/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.4608 - accuracy: 0.8828 - val_loss: 0.5428 - val_accuracy: 0.8177\n",
      "Epoch 69/80\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 0.4626 - accuracy: 0.8763 - val_loss: 0.5507 - val_accuracy: 0.8385\n",
      "Epoch 70/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.4978 - accuracy: 0.8685 - val_loss: 0.5525 - val_accuracy: 0.8177\n",
      "Epoch 71/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4791 - accuracy: 0.8828 - val_loss: 0.6047 - val_accuracy: 0.8125\n",
      "Epoch 72/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.4793 - accuracy: 0.8685 - val_loss: 0.6005 - val_accuracy: 0.8177\n",
      "Epoch 73/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.5173 - accuracy: 0.8672 - val_loss: 0.5947 - val_accuracy: 0.7865\n",
      "Epoch 74/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.4422 - accuracy: 0.8971 - val_loss: 0.5720 - val_accuracy: 0.8021\n",
      "Epoch 75/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.4273 - accuracy: 0.8971 - val_loss: 0.5504 - val_accuracy: 0.8229\n",
      "Epoch 76/80\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 0.4760 - accuracy: 0.8776 - val_loss: 0.5738 - val_accuracy: 0.8125\n",
      "Epoch 77/80\n",
      "192/192 [==============================] - 5s 29ms/step - loss: 0.4117 - accuracy: 0.9023 - val_loss: 0.5720 - val_accuracy: 0.8333\n",
      "Epoch 78/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.4848 - accuracy: 0.8646 - val_loss: 0.5473 - val_accuracy: 0.8385\n",
      "Epoch 79/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.4167 - accuracy: 0.8971 - val_loss: 0.5854 - val_accuracy: 0.8125\n",
      "Epoch 80/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.4333 - accuracy: 0.8867 - val_loss: 0.5928 - val_accuracy: 0.8229\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 0.7557 - accuracy: 0.7604\n",
      "Epoch 1/80\n",
      "192/192 [==============================] - 10s 35ms/step - loss: 1.7255 - accuracy: 0.3724 - val_loss: 1.3096 - val_accuracy: 0.5677\n",
      "Epoch 2/80\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 1.3504 - accuracy: 0.5443 - val_loss: 1.0409 - val_accuracy: 0.6562\n",
      "Epoch 3/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 1.2294 - accuracy: 0.6146 - val_loss: 1.0116 - val_accuracy: 0.6719\n",
      "Epoch 4/80\n",
      "192/192 [==============================] - 7s 37ms/step - loss: 1.1538 - accuracy: 0.6354 - val_loss: 0.9772 - val_accuracy: 0.6771\n",
      "Epoch 5/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 1.0881 - accuracy: 0.6797 - val_loss: 0.9463 - val_accuracy: 0.6562\n",
      "Epoch 6/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 1.0453 - accuracy: 0.7070 - val_loss: 0.8695 - val_accuracy: 0.7396\n",
      "Epoch 7/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.9968 - accuracy: 0.7122 - val_loss: 0.8044 - val_accuracy: 0.7448\n",
      "Epoch 8/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.9882 - accuracy: 0.7279 - val_loss: 0.8331 - val_accuracy: 0.7552\n",
      "Epoch 9/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.9236 - accuracy: 0.7422 - val_loss: 0.8356 - val_accuracy: 0.7448\n",
      "Epoch 10/80\n",
      "192/192 [==============================] - 7s 38ms/step - loss: 0.8970 - accuracy: 0.7617 - val_loss: 0.7654 - val_accuracy: 0.7656\n",
      "Epoch 11/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.8915 - accuracy: 0.7734 - val_loss: 0.7541 - val_accuracy: 0.7604\n",
      "Epoch 12/80\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 0.8649 - accuracy: 0.7695 - val_loss: 0.7621 - val_accuracy: 0.7812\n",
      "Epoch 13/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.8252 - accuracy: 0.7799 - val_loss: 0.7445 - val_accuracy: 0.7500\n",
      "Epoch 14/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.8837 - accuracy: 0.7409 - val_loss: 0.7750 - val_accuracy: 0.7188\n",
      "Epoch 15/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.8146 - accuracy: 0.7812 - val_loss: 0.7540 - val_accuracy: 0.7500\n",
      "Epoch 16/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.8379 - accuracy: 0.7578 - val_loss: 0.7165 - val_accuracy: 0.7656\n",
      "Epoch 17/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.8008 - accuracy: 0.7812 - val_loss: 0.7831 - val_accuracy: 0.7448\n",
      "Epoch 18/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.7894 - accuracy: 0.7578 - val_loss: 0.7052 - val_accuracy: 0.7604\n",
      "Epoch 19/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.7551 - accuracy: 0.7969 - val_loss: 0.6997 - val_accuracy: 0.7865\n",
      "Epoch 20/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.7719 - accuracy: 0.7786 - val_loss: 0.7231 - val_accuracy: 0.7656\n",
      "Epoch 21/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.7256 - accuracy: 0.7943 - val_loss: 0.7645 - val_accuracy: 0.7344\n",
      "Epoch 22/80\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 0.6965 - accuracy: 0.8021 - val_loss: 0.7908 - val_accuracy: 0.7448\n",
      "Epoch 23/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.6802 - accuracy: 0.8060 - val_loss: 0.7286 - val_accuracy: 0.7812\n",
      "Epoch 24/80\n",
      "192/192 [==============================] - 6s 34ms/step - loss: 0.7133 - accuracy: 0.7917 - val_loss: 0.6987 - val_accuracy: 0.7865\n",
      "Epoch 25/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.7260 - accuracy: 0.8021 - val_loss: 0.6991 - val_accuracy: 0.7812\n",
      "Epoch 26/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.6841 - accuracy: 0.8216 - val_loss: 0.6871 - val_accuracy: 0.7812\n",
      "Epoch 27/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.7002 - accuracy: 0.8164 - val_loss: 0.7479 - val_accuracy: 0.7917\n",
      "Epoch 28/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.6565 - accuracy: 0.8151 - val_loss: 0.7339 - val_accuracy: 0.7656\n",
      "Epoch 29/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.7086 - accuracy: 0.8034 - val_loss: 0.7186 - val_accuracy: 0.7812\n",
      "Epoch 30/80\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 0.6663 - accuracy: 0.8203 - val_loss: 0.7728 - val_accuracy: 0.7760\n",
      "Epoch 31/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.6953 - accuracy: 0.7826 - val_loss: 0.7277 - val_accuracy: 0.7865\n",
      "Epoch 32/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.6300 - accuracy: 0.8320 - val_loss: 0.7179 - val_accuracy: 0.7708\n",
      "Epoch 33/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.6516 - accuracy: 0.8216 - val_loss: 0.7661 - val_accuracy: 0.7656\n",
      "Epoch 34/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.6298 - accuracy: 0.8268 - val_loss: 0.7115 - val_accuracy: 0.7760\n",
      "Epoch 35/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.6037 - accuracy: 0.8503 - val_loss: 0.7157 - val_accuracy: 0.7656\n",
      "Epoch 36/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.6299 - accuracy: 0.8359 - val_loss: 0.7136 - val_accuracy: 0.7656\n",
      "Epoch 37/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5803 - accuracy: 0.8464 - val_loss: 0.7143 - val_accuracy: 0.7656\n",
      "Epoch 38/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5899 - accuracy: 0.8503 - val_loss: 0.6867 - val_accuracy: 0.7760\n",
      "Epoch 39/80\n",
      "192/192 [==============================] - 6s 34ms/step - loss: 0.5742 - accuracy: 0.8464 - val_loss: 0.6998 - val_accuracy: 0.7865\n",
      "Epoch 40/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.5755 - accuracy: 0.8490 - val_loss: 0.6870 - val_accuracy: 0.7865\n",
      "Epoch 41/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.6342 - accuracy: 0.8333 - val_loss: 0.6706 - val_accuracy: 0.7812\n",
      "Epoch 42/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.5677 - accuracy: 0.8646 - val_loss: 0.7085 - val_accuracy: 0.7760\n",
      "Epoch 43/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.6078 - accuracy: 0.8307 - val_loss: 0.6951 - val_accuracy: 0.7917\n",
      "Epoch 44/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.5418 - accuracy: 0.8568 - val_loss: 0.6903 - val_accuracy: 0.7865\n",
      "Epoch 45/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.5657 - accuracy: 0.8581 - val_loss: 0.7179 - val_accuracy: 0.7396\n",
      "Epoch 46/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5739 - accuracy: 0.8529 - val_loss: 0.7378 - val_accuracy: 0.7500\n",
      "Epoch 47/80\n",
      "192/192 [==============================] - 6s 34ms/step - loss: 0.5410 - accuracy: 0.8607 - val_loss: 0.7529 - val_accuracy: 0.7708\n",
      "Epoch 48/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.6096 - accuracy: 0.8333 - val_loss: 0.7253 - val_accuracy: 0.7865\n",
      "Epoch 49/80\n",
      "192/192 [==============================] - 6s 34ms/step - loss: 0.5393 - accuracy: 0.8646 - val_loss: 0.7322 - val_accuracy: 0.7760\n",
      "Epoch 50/80\n",
      "192/192 [==============================] - 5s 29ms/step - loss: 0.5137 - accuracy: 0.8841 - val_loss: 0.7081 - val_accuracy: 0.7969\n",
      "Epoch 51/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.5317 - accuracy: 0.8646 - val_loss: 0.7099 - val_accuracy: 0.8073\n",
      "Epoch 52/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.5235 - accuracy: 0.8672 - val_loss: 0.7383 - val_accuracy: 0.7969\n",
      "Epoch 53/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.5422 - accuracy: 0.8516 - val_loss: 0.7163 - val_accuracy: 0.7865\n",
      "Epoch 54/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.5386 - accuracy: 0.8685 - val_loss: 0.7401 - val_accuracy: 0.7552\n",
      "Epoch 55/80\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 0.4859 - accuracy: 0.8932 - val_loss: 0.7462 - val_accuracy: 0.7708\n",
      "Epoch 56/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.5780 - accuracy: 0.8281 - val_loss: 0.7047 - val_accuracy: 0.7656\n",
      "Epoch 57/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.5079 - accuracy: 0.8659 - val_loss: 0.7077 - val_accuracy: 0.7812\n",
      "Epoch 58/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.5559 - accuracy: 0.8385 - val_loss: 0.7211 - val_accuracy: 0.7500\n",
      "Epoch 59/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.4716 - accuracy: 0.8906 - val_loss: 0.7187 - val_accuracy: 0.7969\n",
      "Epoch 60/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.4604 - accuracy: 0.8997 - val_loss: 0.7301 - val_accuracy: 0.8073\n",
      "Epoch 61/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.4791 - accuracy: 0.8776 - val_loss: 0.7779 - val_accuracy: 0.7760\n",
      "Epoch 62/80\n",
      "192/192 [==============================] - 5s 29ms/step - loss: 0.5020 - accuracy: 0.8776 - val_loss: 0.7721 - val_accuracy: 0.7708\n",
      "Epoch 63/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.4969 - accuracy: 0.8737 - val_loss: 0.7670 - val_accuracy: 0.7604\n",
      "Epoch 64/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.4989 - accuracy: 0.8893 - val_loss: 0.7662 - val_accuracy: 0.7448\n",
      "Epoch 65/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.4923 - accuracy: 0.8659 - val_loss: 0.7406 - val_accuracy: 0.7604\n",
      "Epoch 66/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.4873 - accuracy: 0.8789 - val_loss: 0.7176 - val_accuracy: 0.7708\n",
      "Epoch 67/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5451 - accuracy: 0.8464 - val_loss: 0.7265 - val_accuracy: 0.7812\n",
      "Epoch 68/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.4803 - accuracy: 0.8763 - val_loss: 0.7845 - val_accuracy: 0.7656\n",
      "Epoch 69/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5283 - accuracy: 0.8529 - val_loss: 0.7330 - val_accuracy: 0.7656\n",
      "Epoch 70/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.4726 - accuracy: 0.8867 - val_loss: 0.7435 - val_accuracy: 0.7552\n",
      "Epoch 71/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.4751 - accuracy: 0.8789 - val_loss: 0.7255 - val_accuracy: 0.7708\n",
      "Epoch 72/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.4720 - accuracy: 0.8880 - val_loss: 0.7901 - val_accuracy: 0.7448\n",
      "Epoch 73/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.4616 - accuracy: 0.8919 - val_loss: 0.7434 - val_accuracy: 0.7552\n",
      "Epoch 74/80\n",
      "192/192 [==============================] - 6s 34ms/step - loss: 0.4688 - accuracy: 0.8776 - val_loss: 0.8298 - val_accuracy: 0.7500\n",
      "Epoch 75/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4896 - accuracy: 0.8737 - val_loss: 0.7613 - val_accuracy: 0.7656\n",
      "Epoch 76/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.4427 - accuracy: 0.8789 - val_loss: 0.7613 - val_accuracy: 0.7656\n",
      "Epoch 77/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.3856 - accuracy: 0.9089 - val_loss: 0.7431 - val_accuracy: 0.7865\n",
      "Epoch 78/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.4312 - accuracy: 0.8971 - val_loss: 0.7709 - val_accuracy: 0.7656\n",
      "Epoch 79/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4188 - accuracy: 0.8997 - val_loss: 0.7167 - val_accuracy: 0.7917\n",
      "Epoch 80/80\n",
      "192/192 [==============================] - 6s 34ms/step - loss: 0.3814 - accuracy: 0.9036 - val_loss: 0.7559 - val_accuracy: 0.7552\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 0.7328 - accuracy: 0.7604\n",
      "Epoch 1/80\n",
      "192/192 [==============================] - 10s 37ms/step - loss: 1.8047 - accuracy: 0.3203 - val_loss: 0.9247 - val_accuracy: 0.6979\n",
      "Epoch 2/80\n",
      "192/192 [==============================] - 7s 37ms/step - loss: 1.3386 - accuracy: 0.5247 - val_loss: 0.8852 - val_accuracy: 0.7552\n",
      "Epoch 3/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 1.2208 - accuracy: 0.6159 - val_loss: 0.8426 - val_accuracy: 0.7708\n",
      "Epoch 4/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 1.1826 - accuracy: 0.6250 - val_loss: 0.8630 - val_accuracy: 0.7760\n",
      "Epoch 5/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 1.0794 - accuracy: 0.6628 - val_loss: 0.8258 - val_accuracy: 0.7760\n",
      "Epoch 6/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 1.0543 - accuracy: 0.6875 - val_loss: 0.8333 - val_accuracy: 0.7865\n",
      "Epoch 7/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 1.0192 - accuracy: 0.7057 - val_loss: 0.7661 - val_accuracy: 0.7865\n",
      "Epoch 8/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.9801 - accuracy: 0.7409 - val_loss: 0.7504 - val_accuracy: 0.7917\n",
      "Epoch 9/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.9668 - accuracy: 0.7227 - val_loss: 0.7248 - val_accuracy: 0.7969\n",
      "Epoch 10/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.9078 - accuracy: 0.7461 - val_loss: 0.7189 - val_accuracy: 0.7969\n",
      "Epoch 11/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.9132 - accuracy: 0.7643 - val_loss: 0.6958 - val_accuracy: 0.7760\n",
      "Epoch 12/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.9135 - accuracy: 0.7396 - val_loss: 0.6763 - val_accuracy: 0.8229\n",
      "Epoch 13/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.8442 - accuracy: 0.7669 - val_loss: 0.6683 - val_accuracy: 0.7917\n",
      "Epoch 14/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.8135 - accuracy: 0.7930 - val_loss: 0.6550 - val_accuracy: 0.8125\n",
      "Epoch 15/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.8039 - accuracy: 0.7734 - val_loss: 0.6222 - val_accuracy: 0.8385\n",
      "Epoch 16/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.8147 - accuracy: 0.7643 - val_loss: 0.6284 - val_accuracy: 0.8229\n",
      "Epoch 17/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.8042 - accuracy: 0.7956 - val_loss: 0.6568 - val_accuracy: 0.7812\n",
      "Epoch 18/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.8285 - accuracy: 0.7526 - val_loss: 0.7048 - val_accuracy: 0.7812\n",
      "Epoch 19/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.7745 - accuracy: 0.7799 - val_loss: 0.6624 - val_accuracy: 0.8177\n",
      "Epoch 20/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.7666 - accuracy: 0.8086 - val_loss: 0.6726 - val_accuracy: 0.8125\n",
      "Epoch 21/80\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 0.7347 - accuracy: 0.7812 - val_loss: 0.6371 - val_accuracy: 0.7917\n",
      "Epoch 22/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.7588 - accuracy: 0.7930 - val_loss: 0.6486 - val_accuracy: 0.7969\n",
      "Epoch 23/80\n",
      "192/192 [==============================] - 6s 34ms/step - loss: 0.7757 - accuracy: 0.7917 - val_loss: 0.6433 - val_accuracy: 0.8073\n",
      "Epoch 24/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.6867 - accuracy: 0.8138 - val_loss: 0.6730 - val_accuracy: 0.8125\n",
      "Epoch 25/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.7166 - accuracy: 0.7917 - val_loss: 0.6597 - val_accuracy: 0.8021\n",
      "Epoch 26/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.6640 - accuracy: 0.8203 - val_loss: 0.6494 - val_accuracy: 0.7917\n",
      "Epoch 27/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.6310 - accuracy: 0.8424 - val_loss: 0.6469 - val_accuracy: 0.8125\n",
      "Epoch 28/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.6477 - accuracy: 0.8281 - val_loss: 0.6713 - val_accuracy: 0.8021\n",
      "Epoch 29/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.6605 - accuracy: 0.8073 - val_loss: 0.6472 - val_accuracy: 0.7865\n",
      "Epoch 30/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.6666 - accuracy: 0.8203 - val_loss: 0.6143 - val_accuracy: 0.7812\n",
      "Epoch 31/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.6388 - accuracy: 0.8125 - val_loss: 0.6290 - val_accuracy: 0.7969\n",
      "Epoch 32/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.6710 - accuracy: 0.8229 - val_loss: 0.6279 - val_accuracy: 0.7865\n",
      "Epoch 33/80\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 0.6542 - accuracy: 0.8359 - val_loss: 0.6182 - val_accuracy: 0.7812\n",
      "Epoch 34/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.6102 - accuracy: 0.8451 - val_loss: 0.6484 - val_accuracy: 0.7865\n",
      "Epoch 35/80\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 0.6177 - accuracy: 0.8385 - val_loss: 0.5951 - val_accuracy: 0.8125\n",
      "Epoch 36/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.6065 - accuracy: 0.8490 - val_loss: 0.6485 - val_accuracy: 0.7812\n",
      "Epoch 37/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.6180 - accuracy: 0.8242 - val_loss: 0.6086 - val_accuracy: 0.7865\n",
      "Epoch 38/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.6061 - accuracy: 0.8268 - val_loss: 0.6164 - val_accuracy: 0.7969\n",
      "Epoch 39/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.5932 - accuracy: 0.8411 - val_loss: 0.6002 - val_accuracy: 0.7917\n",
      "Epoch 40/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.5132 - accuracy: 0.8802 - val_loss: 0.6017 - val_accuracy: 0.7708\n",
      "Epoch 41/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.6083 - accuracy: 0.8346 - val_loss: 0.6664 - val_accuracy: 0.7812\n",
      "Epoch 42/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.5678 - accuracy: 0.8568 - val_loss: 0.6710 - val_accuracy: 0.7812\n",
      "Epoch 43/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.5695 - accuracy: 0.8438 - val_loss: 0.6412 - val_accuracy: 0.7865\n",
      "Epoch 44/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.5127 - accuracy: 0.8776 - val_loss: 0.6588 - val_accuracy: 0.7760\n",
      "Epoch 45/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5634 - accuracy: 0.8542 - val_loss: 0.6266 - val_accuracy: 0.8125\n",
      "Epoch 46/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5650 - accuracy: 0.8672 - val_loss: 0.6249 - val_accuracy: 0.7812\n",
      "Epoch 47/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.6011 - accuracy: 0.8255 - val_loss: 0.6184 - val_accuracy: 0.8125\n",
      "Epoch 48/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.5698 - accuracy: 0.8464 - val_loss: 0.6086 - val_accuracy: 0.8125\n",
      "Epoch 49/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5732 - accuracy: 0.8516 - val_loss: 0.5961 - val_accuracy: 0.8125\n",
      "Epoch 50/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.5141 - accuracy: 0.8737 - val_loss: 0.6071 - val_accuracy: 0.8021\n",
      "Epoch 51/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.5206 - accuracy: 0.8724 - val_loss: 0.6024 - val_accuracy: 0.8125\n",
      "Epoch 52/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.5537 - accuracy: 0.8503 - val_loss: 0.5922 - val_accuracy: 0.8021\n",
      "Epoch 53/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5342 - accuracy: 0.8594 - val_loss: 0.5884 - val_accuracy: 0.8073\n",
      "Epoch 54/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.5064 - accuracy: 0.8724 - val_loss: 0.6070 - val_accuracy: 0.7865\n",
      "Epoch 55/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4835 - accuracy: 0.8594 - val_loss: 0.6266 - val_accuracy: 0.7917\n",
      "Epoch 56/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.4695 - accuracy: 0.8802 - val_loss: 0.6081 - val_accuracy: 0.8021\n",
      "Epoch 57/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.5061 - accuracy: 0.8698 - val_loss: 0.6185 - val_accuracy: 0.8021\n",
      "Epoch 58/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.5539 - accuracy: 0.8542 - val_loss: 0.5834 - val_accuracy: 0.8073\n",
      "Epoch 59/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.4456 - accuracy: 0.8906 - val_loss: 0.5810 - val_accuracy: 0.8073\n",
      "Epoch 60/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.5269 - accuracy: 0.8568 - val_loss: 0.6206 - val_accuracy: 0.8021\n",
      "Epoch 61/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4754 - accuracy: 0.8841 - val_loss: 0.5971 - val_accuracy: 0.8073\n",
      "Epoch 62/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.4969 - accuracy: 0.8646 - val_loss: 0.5731 - val_accuracy: 0.8073\n",
      "Epoch 63/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.4732 - accuracy: 0.8919 - val_loss: 0.6012 - val_accuracy: 0.8073\n",
      "Epoch 64/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.4969 - accuracy: 0.8789 - val_loss: 0.5795 - val_accuracy: 0.8281\n",
      "Epoch 65/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.4800 - accuracy: 0.8711 - val_loss: 0.6121 - val_accuracy: 0.8021\n",
      "Epoch 66/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4816 - accuracy: 0.8815 - val_loss: 0.6063 - val_accuracy: 0.7969\n",
      "Epoch 67/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.4521 - accuracy: 0.8867 - val_loss: 0.5872 - val_accuracy: 0.8021\n",
      "Epoch 68/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4959 - accuracy: 0.8646 - val_loss: 0.6142 - val_accuracy: 0.8073\n",
      "Epoch 69/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4582 - accuracy: 0.8945 - val_loss: 0.6134 - val_accuracy: 0.7969\n",
      "Epoch 70/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.4822 - accuracy: 0.8763 - val_loss: 0.5596 - val_accuracy: 0.8229\n",
      "Epoch 71/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.4223 - accuracy: 0.8906 - val_loss: 0.5813 - val_accuracy: 0.8177\n",
      "Epoch 72/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.5094 - accuracy: 0.8724 - val_loss: 0.6189 - val_accuracy: 0.7969\n",
      "Epoch 73/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.4061 - accuracy: 0.8997 - val_loss: 0.5984 - val_accuracy: 0.8073\n",
      "Epoch 74/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.4740 - accuracy: 0.8737 - val_loss: 0.5881 - val_accuracy: 0.7969\n",
      "Epoch 75/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4496 - accuracy: 0.8776 - val_loss: 0.5860 - val_accuracy: 0.8177\n",
      "Epoch 76/80\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 0.4208 - accuracy: 0.8971 - val_loss: 0.5994 - val_accuracy: 0.8021\n",
      "Epoch 77/80\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.4409 - accuracy: 0.8906 - val_loss: 0.5861 - val_accuracy: 0.8125\n",
      "Epoch 78/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.5123 - accuracy: 0.8607 - val_loss: 0.5952 - val_accuracy: 0.8125\n",
      "Epoch 79/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.4933 - accuracy: 0.8685 - val_loss: 0.5740 - val_accuracy: 0.8021\n",
      "Epoch 80/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.4416 - accuracy: 0.8841 - val_loss: 0.5929 - val_accuracy: 0.8125\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.7497 - accuracy: 0.7708\n",
      "Epoch 1/80\n",
      "192/192 [==============================] - 9s 34ms/step - loss: 1.7639 - accuracy: 0.3398 - val_loss: 1.0764 - val_accuracy: 0.6146\n",
      "Epoch 2/80\n",
      "192/192 [==============================] - 7s 37ms/step - loss: 1.3425 - accuracy: 0.5521 - val_loss: 0.8994 - val_accuracy: 0.6979\n",
      "Epoch 3/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 1.2352 - accuracy: 0.6068 - val_loss: 0.9187 - val_accuracy: 0.7292\n",
      "Epoch 4/80\n",
      "192/192 [==============================] - 7s 37ms/step - loss: 1.1537 - accuracy: 0.6237 - val_loss: 0.8641 - val_accuracy: 0.7656\n",
      "Epoch 5/80\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 1.0789 - accuracy: 0.6836 - val_loss: 0.8050 - val_accuracy: 0.7917\n",
      "Epoch 6/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 1.0313 - accuracy: 0.6836 - val_loss: 0.7888 - val_accuracy: 0.7812\n",
      "Epoch 7/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 1.0077 - accuracy: 0.7396 - val_loss: 0.7645 - val_accuracy: 0.7812\n",
      "Epoch 8/80\n",
      "192/192 [==============================] - 6s 34ms/step - loss: 0.9665 - accuracy: 0.7253 - val_loss: 0.7229 - val_accuracy: 0.8021\n",
      "Epoch 9/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.9187 - accuracy: 0.7630 - val_loss: 0.7045 - val_accuracy: 0.8073\n",
      "Epoch 10/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.9255 - accuracy: 0.7383 - val_loss: 0.7277 - val_accuracy: 0.8177\n",
      "Epoch 11/80\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 0.8823 - accuracy: 0.7604 - val_loss: 0.7023 - val_accuracy: 0.8177\n",
      "Epoch 12/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.8854 - accuracy: 0.7409 - val_loss: 0.6762 - val_accuracy: 0.8177\n",
      "Epoch 13/80\n",
      "192/192 [==============================] - 7s 37ms/step - loss: 0.8322 - accuracy: 0.7812 - val_loss: 0.6853 - val_accuracy: 0.7969\n",
      "Epoch 14/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.8299 - accuracy: 0.7565 - val_loss: 0.6680 - val_accuracy: 0.7865\n",
      "Epoch 15/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.8153 - accuracy: 0.7695 - val_loss: 0.6792 - val_accuracy: 0.7865\n",
      "Epoch 16/80\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 0.8743 - accuracy: 0.7422 - val_loss: 0.6128 - val_accuracy: 0.8125\n",
      "Epoch 17/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.8127 - accuracy: 0.7812 - val_loss: 0.6329 - val_accuracy: 0.8229\n",
      "Epoch 18/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.7463 - accuracy: 0.8008 - val_loss: 0.6302 - val_accuracy: 0.8177\n",
      "Epoch 19/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.7598 - accuracy: 0.8008 - val_loss: 0.5792 - val_accuracy: 0.8125\n",
      "Epoch 20/80\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 0.7384 - accuracy: 0.8008 - val_loss: 0.5956 - val_accuracy: 0.8438\n",
      "Epoch 21/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.7057 - accuracy: 0.8047 - val_loss: 0.5825 - val_accuracy: 0.8281\n",
      "Epoch 22/80\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 0.7223 - accuracy: 0.8138 - val_loss: 0.6087 - val_accuracy: 0.8490\n",
      "Epoch 23/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.6930 - accuracy: 0.8307 - val_loss: 0.5918 - val_accuracy: 0.8229\n",
      "Epoch 24/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.7124 - accuracy: 0.8047 - val_loss: 0.5943 - val_accuracy: 0.8438\n",
      "Epoch 25/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.7087 - accuracy: 0.8008 - val_loss: 0.5979 - val_accuracy: 0.8177\n",
      "Epoch 26/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.7316 - accuracy: 0.8021 - val_loss: 0.5567 - val_accuracy: 0.8281\n",
      "Epoch 27/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.7134 - accuracy: 0.8034 - val_loss: 0.6254 - val_accuracy: 0.8073\n",
      "Epoch 28/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.6737 - accuracy: 0.8060 - val_loss: 0.5887 - val_accuracy: 0.8177\n",
      "Epoch 29/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.6579 - accuracy: 0.8255 - val_loss: 0.5843 - val_accuracy: 0.8021\n",
      "Epoch 30/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.6547 - accuracy: 0.8229 - val_loss: 0.6142 - val_accuracy: 0.8281\n",
      "Epoch 31/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.6624 - accuracy: 0.8177 - val_loss: 0.6085 - val_accuracy: 0.8177\n",
      "Epoch 32/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.6591 - accuracy: 0.8268 - val_loss: 0.6067 - val_accuracy: 0.8229\n",
      "Epoch 33/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.5877 - accuracy: 0.8424 - val_loss: 0.5680 - val_accuracy: 0.8333\n",
      "Epoch 34/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.6066 - accuracy: 0.8411 - val_loss: 0.5957 - val_accuracy: 0.8125\n",
      "Epoch 35/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.6456 - accuracy: 0.8229 - val_loss: 0.6067 - val_accuracy: 0.8073\n",
      "Epoch 36/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.6308 - accuracy: 0.8372 - val_loss: 0.6240 - val_accuracy: 0.8281\n",
      "Epoch 37/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5946 - accuracy: 0.8451 - val_loss: 0.5788 - val_accuracy: 0.8385\n",
      "Epoch 38/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.6151 - accuracy: 0.8281 - val_loss: 0.5742 - val_accuracy: 0.8385\n",
      "Epoch 39/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5724 - accuracy: 0.8438 - val_loss: 0.5549 - val_accuracy: 0.8438\n",
      "Epoch 40/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.5883 - accuracy: 0.8555 - val_loss: 0.5513 - val_accuracy: 0.8438\n",
      "Epoch 41/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.5622 - accuracy: 0.8503 - val_loss: 0.5442 - val_accuracy: 0.8177\n",
      "Epoch 42/80\n",
      "192/192 [==============================] - 6s 34ms/step - loss: 0.5832 - accuracy: 0.8411 - val_loss: 0.5845 - val_accuracy: 0.8021\n",
      "Epoch 43/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.5738 - accuracy: 0.8477 - val_loss: 0.5379 - val_accuracy: 0.8229\n",
      "Epoch 44/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.5902 - accuracy: 0.8385 - val_loss: 0.5241 - val_accuracy: 0.8229\n",
      "Epoch 45/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5264 - accuracy: 0.8581 - val_loss: 0.5376 - val_accuracy: 0.8281\n",
      "Epoch 46/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.5658 - accuracy: 0.8568 - val_loss: 0.5864 - val_accuracy: 0.8333\n",
      "Epoch 47/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.5844 - accuracy: 0.8359 - val_loss: 0.6576 - val_accuracy: 0.7865\n",
      "Epoch 48/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.5769 - accuracy: 0.8333 - val_loss: 0.5830 - val_accuracy: 0.8125\n",
      "Epoch 49/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.5411 - accuracy: 0.8516 - val_loss: 0.5567 - val_accuracy: 0.8177\n",
      "Epoch 50/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.5509 - accuracy: 0.8385 - val_loss: 0.5978 - val_accuracy: 0.7969\n",
      "Epoch 51/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.5356 - accuracy: 0.8594 - val_loss: 0.6230 - val_accuracy: 0.8229\n",
      "Epoch 52/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.5433 - accuracy: 0.8477 - val_loss: 0.5745 - val_accuracy: 0.8281\n",
      "Epoch 53/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.5789 - accuracy: 0.8333 - val_loss: 0.6100 - val_accuracy: 0.8021\n",
      "Epoch 54/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.5565 - accuracy: 0.8581 - val_loss: 0.5890 - val_accuracy: 0.8125\n",
      "Epoch 55/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5720 - accuracy: 0.8307 - val_loss: 0.6097 - val_accuracy: 0.7969\n",
      "Epoch 56/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.4640 - accuracy: 0.8893 - val_loss: 0.5854 - val_accuracy: 0.8229\n",
      "Epoch 57/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5175 - accuracy: 0.8698 - val_loss: 0.6019 - val_accuracy: 0.8281\n",
      "Epoch 58/80\n",
      "192/192 [==============================] - 6s 34ms/step - loss: 0.5468 - accuracy: 0.8594 - val_loss: 0.5968 - val_accuracy: 0.8177\n",
      "Epoch 59/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.5397 - accuracy: 0.8594 - val_loss: 0.5709 - val_accuracy: 0.8281\n",
      "Epoch 60/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.4624 - accuracy: 0.8828 - val_loss: 0.5726 - val_accuracy: 0.8281\n",
      "Epoch 61/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5400 - accuracy: 0.8581 - val_loss: 0.5991 - val_accuracy: 0.8073\n",
      "Epoch 62/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5680 - accuracy: 0.8307 - val_loss: 0.6293 - val_accuracy: 0.8073\n",
      "Epoch 63/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.5427 - accuracy: 0.8659 - val_loss: 0.5894 - val_accuracy: 0.8125\n",
      "Epoch 64/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.4370 - accuracy: 0.8945 - val_loss: 0.5802 - val_accuracy: 0.8073\n",
      "Epoch 65/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.5154 - accuracy: 0.8516 - val_loss: 0.5742 - val_accuracy: 0.8281\n",
      "Epoch 66/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4757 - accuracy: 0.8737 - val_loss: 0.5870 - val_accuracy: 0.8281\n",
      "Epoch 67/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.5088 - accuracy: 0.8568 - val_loss: 0.5916 - val_accuracy: 0.8333\n",
      "Epoch 68/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4679 - accuracy: 0.8880 - val_loss: 0.5660 - val_accuracy: 0.8333\n",
      "Epoch 69/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.4802 - accuracy: 0.8802 - val_loss: 0.5626 - val_accuracy: 0.8229\n",
      "Epoch 70/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.4825 - accuracy: 0.8763 - val_loss: 0.5465 - val_accuracy: 0.8281\n",
      "Epoch 71/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.4300 - accuracy: 0.8958 - val_loss: 0.5699 - val_accuracy: 0.8281\n",
      "Epoch 72/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.4669 - accuracy: 0.8763 - val_loss: 0.5573 - val_accuracy: 0.8125\n",
      "Epoch 73/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.4918 - accuracy: 0.8659 - val_loss: 0.5785 - val_accuracy: 0.8073\n",
      "Epoch 74/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.4893 - accuracy: 0.8711 - val_loss: 0.5496 - val_accuracy: 0.8333\n",
      "Epoch 75/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.4096 - accuracy: 0.8932 - val_loss: 0.5628 - val_accuracy: 0.8177\n",
      "Epoch 76/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.4484 - accuracy: 0.8932 - val_loss: 0.5556 - val_accuracy: 0.8229\n",
      "Epoch 77/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.3903 - accuracy: 0.9167 - val_loss: 0.5655 - val_accuracy: 0.8125\n",
      "Epoch 78/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.4244 - accuracy: 0.8854 - val_loss: 0.5418 - val_accuracy: 0.8125\n",
      "Epoch 79/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.4880 - accuracy: 0.8724 - val_loss: 0.5529 - val_accuracy: 0.8177\n",
      "Epoch 80/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4802 - accuracy: 0.8841 - val_loss: 0.5718 - val_accuracy: 0.8073\n"
     ]
    }
   ],
   "source": [
    "VALIDATION_ACCURACY_SPEECH = []\n",
    "VALIDATION_LOSS_SPEECH = []\n",
    "\n",
    "save_dir = os.path.abspath(DIR) + '/ravdess_60m40f_intermediatefusion_PCA_n0.95_model/'\n",
    "fold_var = 1\n",
    "\n",
    "for train_idx, val_idx in kfold.split(concatenated_train_data, y_train_60m_40f):\n",
    "    model=multi_modal_NN()\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
    "\n",
    "    #early_stopping_callback = EarlyStopping(monitor = 'val_accuracy', patience = 15, restore_best_weights = True)\n",
    "\n",
    "    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(save_dir + get_model_name(fold_var), monitor='val_accuracy',save_best_only=True, mode='max')\n",
    "# Start training the model.\n",
    "    LRCN_model_training_history = model.fit(      x = concatenated_train_data[train_idx],\n",
    "                                                  y = y_train_40m_60f[train_idx],\n",
    "                                                  validation_data=(concatenated_train_data[val_idx], y_train_60m_40f[val_idx]),\n",
    "                                                  epochs = 80,\n",
    "                                                  batch_size = 4,\n",
    "                                                  shuffle = True,\n",
    "                                                  callbacks = [checkpoint_cb])\n",
    "    model.load_weights(save_dir + \"model_\" + str(fold_var) + \".h5\")\n",
    "\t\n",
    "    results = model.evaluate(concatenated_test_data, y_test)\n",
    "    results = dict(zip(model.metrics_names, results))\n",
    "\t\n",
    "    VALIDATION_ACCURACY_SPEECH.append(results['accuracy'])\n",
    "    VALIDATION_LOSS_SPEECH.append(results['loss'])\n",
    "\t\n",
    "    tf.keras.backend.clear_session()\n",
    "\t\n",
    "    fold_var += 1\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d1f25d-2224-478b-ab1c-e61904079cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IntermediateFusion Variant 2 **Not Selected**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "561a54f8-7541-4d87-a44f-929e18c1437c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_video_model=Model(inputs=model_video.input, outputs=model_video.get_layer('time_distributed_1').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a7587da6-8f00-4b64-bca6-2366853a3a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 5s 92ms/step\n"
     ]
    }
   ],
   "source": [
    "features_video=features_video_model.predict(X_train_50m_50f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2a7beea6-e5f0-4f00-ac80-cd97446c7034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 20, 48, 48, 1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "36b249bf-668f-4efd-a27f-6c5a1827faef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flattened = np.reshape(features_video, (960, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ce636a58-650f-4764-8e1d-128ffe63f98e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 46080)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_flattened.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5d401173-edc6-4f8b-a8ea-1c8ce9c6fcd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 134ms/step\n"
     ]
    }
   ],
   "source": [
    "features_video_test = features_video_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b1440752-6ab5-4a11-8a22-0912d5d68c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_flattened = np.reshape(features_video_test, (288, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2f2da149-e6c6-4f58-a00c-5f8183e4b617",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_audio_model=Model(inputs=model_audio.input, outputs=model_audio.get_layer('flatten_1').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1c86961a-e687-47fb-9bb2-2fd442ca674c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 17s 552ms/step\n"
     ]
    }
   ],
   "source": [
    "features_audio=features_audio_model.predict(X_train_aud_50m_50f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "96fd2255-e8e0-492a-aeeb-6c78508be46b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 262144)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "79a9e4ad-16b0-4b20-bd9f-d55fdf28d8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 5s 466ms/step\n"
     ]
    }
   ],
   "source": [
    "features_audio_test = features_audio_model.predict(X_test_aud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0a838ee6-eb49-4c4e-8d5c-e1db827f9800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 262144)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_audio_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a88e4435-92cf-4d60-930c-2224caa2ce1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "video_scaler = StandardScaler().fit(X_train_flattened)\n",
    "video_data_standardized = video_scaler.fit_transform(X_train_flattened)\n",
    "video_data_standardized_test = video_scaler.fit_transform(X_test_flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2ab1e6fd-419d-43d6-87ac-8fc7bbcf1ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_scaler = StandardScaler().fit(features_audio)\n",
    "audio_data_standardized = audio_scaler.fit_transform(features_audio)\n",
    "audio_data_standardized_test = audio_scaler.fit_transform(features_audio_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "45ce71ed-9dcc-41c5-9b99-6dfae173f763",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca_video = PCA(n_components=0.95).fit(video_data_standardized)\n",
    "video_data_pca = pca_video.fit_transform(video_data_standardized)\n",
    "video_data_pca_test = pca_video.transform(video_data_standardized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "55db80cb-0e94-4696-b8af-73f1ed7dac1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 596)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_data_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "da17417f-7d31-417f-ba40-cb8cfdbcd862",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_audio = PCA(n_components=0.95).fit(audio_data_standardized)\n",
    "audio_data_pca = pca_audio.fit_transform(audio_data_standardized)\n",
    "audio_data_pca_test = pca_audio.transform(audio_data_standardized_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d3671ae6-87a6-4a59-8b3f-5beb66b929e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 511)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_data_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4d173e19-d10c-4155-8cb3-63f02ac577e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 511)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_data_pca_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cd7c5e0f-1f15-41a9-a7e6-c853b44f37e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_train_data = np.concatenate((video_data_pca, audio_data_pca), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d7755b39-bb55-4f5c-926e-261a92ddfa0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(960, 1107)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5993e23a-6608-4d57-8ce2-c3761f4541db",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_test_data = np.concatenate((video_data_pca_test, audio_data_pca_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b95becdb-970e-420a-a25d-3297bb9db332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288, 1107)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ace0a849-b8ac-446e-ae68-0a1763820135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_modal_NN():\n",
    "  model=Sequential()\n",
    "  model.add(Input(shape=(1107)))\n",
    "  \n",
    "  model.add(Dense(2096))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dropout(0.4))\n",
    "\n",
    "  model.add(Dense(1024))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dropout(0.4))\n",
    "\n",
    "  model.add(Dense(8))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Activation('softmax'))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0857ab6a-9cf5-44b2-8b3e-d7dd4666c966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "192/192 [==============================] - 9s 32ms/step - loss: 1.8559 - accuracy: 0.3112 - val_loss: 1.2366 - val_accuracy: 0.5781\n",
      "Epoch 2/80\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 1.3523 - accuracy: 0.5052 - val_loss: 1.0969 - val_accuracy: 0.6406\n",
      "Epoch 3/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 1.2434 - accuracy: 0.5703 - val_loss: 1.0729 - val_accuracy: 0.6615\n",
      "Epoch 4/80\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 1.1398 - accuracy: 0.6549 - val_loss: 1.0545 - val_accuracy: 0.6875\n",
      "Epoch 5/80\n",
      "192/192 [==============================] - 7s 38ms/step - loss: 1.0559 - accuracy: 0.6784 - val_loss: 0.9998 - val_accuracy: 0.7188\n",
      "Epoch 6/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 1.0606 - accuracy: 0.6888 - val_loss: 0.9707 - val_accuracy: 0.7135\n",
      "Epoch 7/80\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 0.9805 - accuracy: 0.7188 - val_loss: 0.9556 - val_accuracy: 0.7188\n",
      "Epoch 8/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.9890 - accuracy: 0.7214 - val_loss: 0.9473 - val_accuracy: 0.7135\n",
      "Epoch 9/80\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 0.9599 - accuracy: 0.7305 - val_loss: 0.9898 - val_accuracy: 0.6667\n",
      "Epoch 10/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.9067 - accuracy: 0.7591 - val_loss: 0.9497 - val_accuracy: 0.6979\n",
      "Epoch 11/80\n",
      "192/192 [==============================] - 7s 37ms/step - loss: 0.8674 - accuracy: 0.7604 - val_loss: 0.9173 - val_accuracy: 0.7396\n",
      "Epoch 12/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.8592 - accuracy: 0.7656 - val_loss: 0.9552 - val_accuracy: 0.7135\n",
      "Epoch 13/80\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 0.8768 - accuracy: 0.7565 - val_loss: 0.9617 - val_accuracy: 0.7135\n",
      "Epoch 14/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.8376 - accuracy: 0.7604 - val_loss: 0.9374 - val_accuracy: 0.6927\n",
      "Epoch 15/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.7969 - accuracy: 0.8086 - val_loss: 0.9209 - val_accuracy: 0.7344\n",
      "Epoch 16/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.8421 - accuracy: 0.7617 - val_loss: 0.9397 - val_accuracy: 0.7135\n",
      "Epoch 17/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.8197 - accuracy: 0.7734 - val_loss: 0.9315 - val_accuracy: 0.6979\n",
      "Epoch 18/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.7794 - accuracy: 0.7943 - val_loss: 0.9388 - val_accuracy: 0.6979\n",
      "Epoch 19/80\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 0.7844 - accuracy: 0.7852 - val_loss: 0.9782 - val_accuracy: 0.7031\n",
      "Epoch 20/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.7679 - accuracy: 0.7773 - val_loss: 0.9416 - val_accuracy: 0.7188\n",
      "Epoch 21/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.7579 - accuracy: 0.7969 - val_loss: 0.9621 - val_accuracy: 0.7135\n",
      "Epoch 22/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.7296 - accuracy: 0.8021 - val_loss: 0.9413 - val_accuracy: 0.7031\n",
      "Epoch 23/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.7304 - accuracy: 0.8112 - val_loss: 0.9671 - val_accuracy: 0.6875\n",
      "Epoch 24/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.7116 - accuracy: 0.8099 - val_loss: 0.9809 - val_accuracy: 0.6875\n",
      "Epoch 25/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.6835 - accuracy: 0.8307 - val_loss: 0.9507 - val_accuracy: 0.6823\n",
      "Epoch 26/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.7013 - accuracy: 0.8164 - val_loss: 0.9171 - val_accuracy: 0.6875\n",
      "Epoch 27/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.7276 - accuracy: 0.7904 - val_loss: 0.9401 - val_accuracy: 0.6927\n",
      "Epoch 28/80\n",
      "192/192 [==============================] - 6s 34ms/step - loss: 0.6729 - accuracy: 0.8177 - val_loss: 0.9222 - val_accuracy: 0.6979\n",
      "Epoch 29/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.6573 - accuracy: 0.8346 - val_loss: 0.9043 - val_accuracy: 0.7031\n",
      "Epoch 30/80\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 0.6823 - accuracy: 0.8281 - val_loss: 0.9016 - val_accuracy: 0.7344\n",
      "Epoch 31/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.6287 - accuracy: 0.8203 - val_loss: 0.9234 - val_accuracy: 0.7188\n",
      "Epoch 32/80\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 0.5851 - accuracy: 0.8516 - val_loss: 0.8924 - val_accuracy: 0.7188\n",
      "Epoch 33/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.6009 - accuracy: 0.8542 - val_loss: 0.9072 - val_accuracy: 0.7188\n",
      "Epoch 34/80\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 0.6066 - accuracy: 0.8438 - val_loss: 0.8626 - val_accuracy: 0.7656\n",
      "Epoch 35/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5998 - accuracy: 0.8464 - val_loss: 0.9715 - val_accuracy: 0.6927\n",
      "Epoch 36/80\n",
      "192/192 [==============================] - 7s 37ms/step - loss: 0.6294 - accuracy: 0.8138 - val_loss: 0.9118 - val_accuracy: 0.7135\n",
      "Epoch 37/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.6238 - accuracy: 0.8359 - val_loss: 0.9029 - val_accuracy: 0.6979\n",
      "Epoch 38/80\n",
      "192/192 [==============================] - 6s 34ms/step - loss: 0.6090 - accuracy: 0.8424 - val_loss: 0.9336 - val_accuracy: 0.7031\n",
      "Epoch 39/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.5803 - accuracy: 0.8490 - val_loss: 0.9147 - val_accuracy: 0.7188\n",
      "Epoch 40/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.5973 - accuracy: 0.8307 - val_loss: 0.8987 - val_accuracy: 0.7240\n",
      "Epoch 41/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5858 - accuracy: 0.8568 - val_loss: 0.9160 - val_accuracy: 0.7240\n",
      "Epoch 42/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.5803 - accuracy: 0.8516 - val_loss: 0.9295 - val_accuracy: 0.7448\n",
      "Epoch 43/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.5884 - accuracy: 0.8451 - val_loss: 0.9042 - val_accuracy: 0.7344\n",
      "Epoch 44/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5466 - accuracy: 0.8555 - val_loss: 0.9121 - val_accuracy: 0.7292\n",
      "Epoch 45/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.5677 - accuracy: 0.8424 - val_loss: 0.8783 - val_accuracy: 0.7396\n",
      "Epoch 46/80\n",
      "192/192 [==============================] - 7s 38ms/step - loss: 0.5257 - accuracy: 0.8659 - val_loss: 0.9277 - val_accuracy: 0.7344\n",
      "Epoch 47/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5775 - accuracy: 0.8477 - val_loss: 0.9186 - val_accuracy: 0.7448\n",
      "Epoch 48/80\n",
      "192/192 [==============================] - 7s 37ms/step - loss: 0.5289 - accuracy: 0.8724 - val_loss: 0.9100 - val_accuracy: 0.7188\n",
      "Epoch 49/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5237 - accuracy: 0.8607 - val_loss: 0.9198 - val_accuracy: 0.7135\n",
      "Epoch 50/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.5059 - accuracy: 0.8737 - val_loss: 0.9179 - val_accuracy: 0.7188\n",
      "Epoch 51/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.5677 - accuracy: 0.8516 - val_loss: 0.9669 - val_accuracy: 0.7135\n",
      "Epoch 52/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.5608 - accuracy: 0.8594 - val_loss: 0.9289 - val_accuracy: 0.7188\n",
      "Epoch 53/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.5062 - accuracy: 0.8698 - val_loss: 0.9675 - val_accuracy: 0.7031\n",
      "Epoch 54/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.5071 - accuracy: 0.8724 - val_loss: 0.9532 - val_accuracy: 0.7083\n",
      "Epoch 55/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.4841 - accuracy: 0.8880 - val_loss: 0.8907 - val_accuracy: 0.7344\n",
      "Epoch 56/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5308 - accuracy: 0.8529 - val_loss: 0.8927 - val_accuracy: 0.7344\n",
      "Epoch 57/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.4656 - accuracy: 0.8776 - val_loss: 0.9310 - val_accuracy: 0.7083\n",
      "Epoch 58/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.5389 - accuracy: 0.8503 - val_loss: 0.9624 - val_accuracy: 0.6979\n",
      "Epoch 59/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.5043 - accuracy: 0.8750 - val_loss: 0.9767 - val_accuracy: 0.6927\n",
      "Epoch 60/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.4966 - accuracy: 0.8672 - val_loss: 0.9177 - val_accuracy: 0.6979\n",
      "Epoch 61/80\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 0.4370 - accuracy: 0.9010 - val_loss: 0.9542 - val_accuracy: 0.6927\n",
      "Epoch 62/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.4757 - accuracy: 0.8958 - val_loss: 0.9243 - val_accuracy: 0.7135\n",
      "Epoch 63/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.4817 - accuracy: 0.8698 - val_loss: 0.9105 - val_accuracy: 0.7344\n",
      "Epoch 64/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.4630 - accuracy: 0.8815 - val_loss: 0.9110 - val_accuracy: 0.7240\n",
      "Epoch 65/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.4518 - accuracy: 0.8919 - val_loss: 0.9210 - val_accuracy: 0.7083\n",
      "Epoch 66/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.4446 - accuracy: 0.8880 - val_loss: 0.9868 - val_accuracy: 0.6771\n",
      "Epoch 67/80\n",
      "192/192 [==============================] - 7s 38ms/step - loss: 0.4357 - accuracy: 0.8958 - val_loss: 0.9621 - val_accuracy: 0.7344\n",
      "Epoch 68/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4416 - accuracy: 0.9023 - val_loss: 1.0003 - val_accuracy: 0.7292\n",
      "Epoch 69/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.4459 - accuracy: 0.8945 - val_loss: 1.0349 - val_accuracy: 0.7240\n",
      "Epoch 70/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.4226 - accuracy: 0.8867 - val_loss: 1.0208 - val_accuracy: 0.7292\n",
      "Epoch 71/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.4248 - accuracy: 0.8906 - val_loss: 1.0350 - val_accuracy: 0.7135\n",
      "Epoch 72/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.4886 - accuracy: 0.8724 - val_loss: 1.0388 - val_accuracy: 0.6875\n",
      "Epoch 73/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.4668 - accuracy: 0.8724 - val_loss: 1.0670 - val_accuracy: 0.7083\n",
      "Epoch 74/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.4529 - accuracy: 0.8906 - val_loss: 1.0704 - val_accuracy: 0.6875\n",
      "Epoch 75/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.4416 - accuracy: 0.8841 - val_loss: 1.0203 - val_accuracy: 0.7083\n",
      "Epoch 76/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.4605 - accuracy: 0.8958 - val_loss: 1.0228 - val_accuracy: 0.6823\n",
      "Epoch 77/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.4147 - accuracy: 0.9010 - val_loss: 1.0738 - val_accuracy: 0.6875\n",
      "Epoch 78/80\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 0.4160 - accuracy: 0.8984 - val_loss: 1.0726 - val_accuracy: 0.6927\n",
      "Epoch 79/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.4374 - accuracy: 0.8971 - val_loss: 1.0923 - val_accuracy: 0.6823\n",
      "Epoch 80/80\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 0.3817 - accuracy: 0.9206 - val_loss: 1.1068 - val_accuracy: 0.6771\n",
      "9/9 [==============================] - 1s 21ms/step - loss: 0.7982 - accuracy: 0.7222\n",
      "Epoch 1/80\n",
      "192/192 [==============================] - 10s 39ms/step - loss: 1.8680 - accuracy: 0.3138 - val_loss: 1.2046 - val_accuracy: 0.5990\n",
      "Epoch 2/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 1.3800 - accuracy: 0.5195 - val_loss: 0.9890 - val_accuracy: 0.6823\n",
      "Epoch 3/80\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 1.2041 - accuracy: 0.5911 - val_loss: 1.0108 - val_accuracy: 0.7292\n",
      "Epoch 4/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 1.1664 - accuracy: 0.6393 - val_loss: 0.9259 - val_accuracy: 0.7240\n",
      "Epoch 5/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 1.1313 - accuracy: 0.6432 - val_loss: 0.8915 - val_accuracy: 0.7448\n",
      "Epoch 6/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 1.0957 - accuracy: 0.6732 - val_loss: 0.8766 - val_accuracy: 0.7292\n",
      "Epoch 7/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 1.0054 - accuracy: 0.7240 - val_loss: 0.8544 - val_accuracy: 0.7344\n",
      "Epoch 8/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 1.0411 - accuracy: 0.6810 - val_loss: 0.8316 - val_accuracy: 0.7760\n",
      "Epoch 9/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.9505 - accuracy: 0.7096 - val_loss: 0.7839 - val_accuracy: 0.7812\n",
      "Epoch 10/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.9089 - accuracy: 0.7448 - val_loss: 0.8146 - val_accuracy: 0.7760\n",
      "Epoch 11/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.8944 - accuracy: 0.7422 - val_loss: 0.7963 - val_accuracy: 0.7760\n",
      "Epoch 12/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.8962 - accuracy: 0.7409 - val_loss: 0.7860 - val_accuracy: 0.7552\n",
      "Epoch 13/80\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 0.8879 - accuracy: 0.7617 - val_loss: 0.7525 - val_accuracy: 0.7917\n",
      "Epoch 14/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.8346 - accuracy: 0.7630 - val_loss: 0.7923 - val_accuracy: 0.7812\n",
      "Epoch 15/80\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 0.8025 - accuracy: 0.7591 - val_loss: 0.7806 - val_accuracy: 0.7656\n",
      "Epoch 16/80\n",
      "192/192 [==============================] - 5s 29ms/step - loss: 0.7755 - accuracy: 0.7839 - val_loss: 0.7591 - val_accuracy: 0.7552\n",
      "Epoch 17/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.7998 - accuracy: 0.7656 - val_loss: 0.7116 - val_accuracy: 0.8021\n",
      "Epoch 18/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.7853 - accuracy: 0.7956 - val_loss: 0.7043 - val_accuracy: 0.8021\n",
      "Epoch 19/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.7158 - accuracy: 0.8138 - val_loss: 0.7236 - val_accuracy: 0.7865\n",
      "Epoch 20/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.7357 - accuracy: 0.8008 - val_loss: 0.6970 - val_accuracy: 0.8073\n",
      "Epoch 21/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.7283 - accuracy: 0.8008 - val_loss: 0.7033 - val_accuracy: 0.7760\n",
      "Epoch 22/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.7321 - accuracy: 0.8177 - val_loss: 0.7274 - val_accuracy: 0.7760\n",
      "Epoch 23/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.7093 - accuracy: 0.8073 - val_loss: 0.7626 - val_accuracy: 0.7656\n",
      "Epoch 24/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.7143 - accuracy: 0.8047 - val_loss: 0.7221 - val_accuracy: 0.7812\n",
      "Epoch 25/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.7518 - accuracy: 0.7812 - val_loss: 0.7582 - val_accuracy: 0.7552\n",
      "Epoch 26/80\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 0.6891 - accuracy: 0.8060 - val_loss: 0.6903 - val_accuracy: 0.7760\n",
      "Epoch 27/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.6793 - accuracy: 0.8216 - val_loss: 0.6785 - val_accuracy: 0.7969\n",
      "Epoch 28/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.6386 - accuracy: 0.8281 - val_loss: 0.7217 - val_accuracy: 0.7656\n",
      "Epoch 29/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.6313 - accuracy: 0.8307 - val_loss: 0.7314 - val_accuracy: 0.7552\n",
      "Epoch 30/80\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 0.6550 - accuracy: 0.8086 - val_loss: 0.7312 - val_accuracy: 0.7552\n",
      "Epoch 31/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.7016 - accuracy: 0.7995 - val_loss: 0.7206 - val_accuracy: 0.7708\n",
      "Epoch 32/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.6729 - accuracy: 0.8112 - val_loss: 0.7214 - val_accuracy: 0.7812\n",
      "Epoch 33/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.6673 - accuracy: 0.8125 - val_loss: 0.6813 - val_accuracy: 0.7917\n",
      "Epoch 34/80\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 0.6544 - accuracy: 0.8060 - val_loss: 0.6992 - val_accuracy: 0.7604\n",
      "Epoch 35/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.6569 - accuracy: 0.8164 - val_loss: 0.7126 - val_accuracy: 0.7552\n",
      "Epoch 36/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.5907 - accuracy: 0.8529 - val_loss: 0.6728 - val_accuracy: 0.7760\n",
      "Epoch 37/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.5993 - accuracy: 0.8542 - val_loss: 0.6503 - val_accuracy: 0.7969\n",
      "Epoch 38/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.6024 - accuracy: 0.8411 - val_loss: 0.7196 - val_accuracy: 0.7656\n",
      "Epoch 39/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.5879 - accuracy: 0.8451 - val_loss: 0.7092 - val_accuracy: 0.7656\n",
      "Epoch 40/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.6130 - accuracy: 0.8372 - val_loss: 0.7368 - val_accuracy: 0.7708\n",
      "Epoch 41/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.6260 - accuracy: 0.8359 - val_loss: 0.7209 - val_accuracy: 0.7292\n",
      "Epoch 42/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.6074 - accuracy: 0.8333 - val_loss: 0.6487 - val_accuracy: 0.7969\n",
      "Epoch 43/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.6220 - accuracy: 0.8203 - val_loss: 0.6593 - val_accuracy: 0.8073\n",
      "Epoch 44/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.5667 - accuracy: 0.8451 - val_loss: 0.6708 - val_accuracy: 0.7969\n",
      "Epoch 45/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.5711 - accuracy: 0.8385 - val_loss: 0.6537 - val_accuracy: 0.8021\n",
      "Epoch 46/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.5627 - accuracy: 0.8516 - val_loss: 0.6665 - val_accuracy: 0.7708\n",
      "Epoch 47/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.5715 - accuracy: 0.8529 - val_loss: 0.6792 - val_accuracy: 0.7708\n",
      "Epoch 48/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5748 - accuracy: 0.8346 - val_loss: 0.6632 - val_accuracy: 0.8021\n",
      "Epoch 49/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.5524 - accuracy: 0.8750 - val_loss: 0.6906 - val_accuracy: 0.7552\n",
      "Epoch 50/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.5219 - accuracy: 0.8750 - val_loss: 0.6971 - val_accuracy: 0.7708\n",
      "Epoch 51/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.5246 - accuracy: 0.8490 - val_loss: 0.7261 - val_accuracy: 0.7708\n",
      "Epoch 52/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5413 - accuracy: 0.8516 - val_loss: 0.6889 - val_accuracy: 0.7760\n",
      "Epoch 53/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5433 - accuracy: 0.8646 - val_loss: 0.6871 - val_accuracy: 0.7917\n",
      "Epoch 54/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.5725 - accuracy: 0.8411 - val_loss: 0.6824 - val_accuracy: 0.8177\n",
      "Epoch 55/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5072 - accuracy: 0.8724 - val_loss: 0.6521 - val_accuracy: 0.7552\n",
      "Epoch 56/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.5056 - accuracy: 0.8685 - val_loss: 0.6621 - val_accuracy: 0.7917\n",
      "Epoch 57/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.4927 - accuracy: 0.8828 - val_loss: 0.6713 - val_accuracy: 0.7760\n",
      "Epoch 58/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.5829 - accuracy: 0.8372 - val_loss: 0.6342 - val_accuracy: 0.7969\n",
      "Epoch 59/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.5215 - accuracy: 0.8685 - val_loss: 0.6783 - val_accuracy: 0.7344\n",
      "Epoch 60/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.5605 - accuracy: 0.8411 - val_loss: 0.6895 - val_accuracy: 0.7917\n",
      "Epoch 61/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5329 - accuracy: 0.8672 - val_loss: 0.6314 - val_accuracy: 0.8021\n",
      "Epoch 62/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.4575 - accuracy: 0.8841 - val_loss: 0.6454 - val_accuracy: 0.7865\n",
      "Epoch 63/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.4628 - accuracy: 0.8867 - val_loss: 0.6692 - val_accuracy: 0.7760\n",
      "Epoch 64/80\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.5188 - accuracy: 0.8568 - val_loss: 0.6786 - val_accuracy: 0.7812\n",
      "Epoch 65/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.5167 - accuracy: 0.8568 - val_loss: 0.6804 - val_accuracy: 0.7604\n",
      "Epoch 66/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5175 - accuracy: 0.8750 - val_loss: 0.6813 - val_accuracy: 0.7604\n",
      "Epoch 67/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5030 - accuracy: 0.8568 - val_loss: 0.6371 - val_accuracy: 0.7760\n",
      "Epoch 68/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5316 - accuracy: 0.8698 - val_loss: 0.6555 - val_accuracy: 0.7604\n",
      "Epoch 69/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5330 - accuracy: 0.8542 - val_loss: 0.6753 - val_accuracy: 0.7812\n",
      "Epoch 70/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.5119 - accuracy: 0.8750 - val_loss: 0.6847 - val_accuracy: 0.7812\n",
      "Epoch 71/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.4565 - accuracy: 0.8867 - val_loss: 0.6726 - val_accuracy: 0.7969\n",
      "Epoch 72/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.4221 - accuracy: 0.9036 - val_loss: 0.6649 - val_accuracy: 0.7760\n",
      "Epoch 73/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5066 - accuracy: 0.8711 - val_loss: 0.6970 - val_accuracy: 0.7604\n",
      "Epoch 74/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.4778 - accuracy: 0.8737 - val_loss: 0.7241 - val_accuracy: 0.7448\n",
      "Epoch 75/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4545 - accuracy: 0.8776 - val_loss: 0.7003 - val_accuracy: 0.7708\n",
      "Epoch 76/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.4690 - accuracy: 0.8737 - val_loss: 0.6944 - val_accuracy: 0.7552\n",
      "Epoch 77/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.4714 - accuracy: 0.8841 - val_loss: 0.6742 - val_accuracy: 0.7604\n",
      "Epoch 78/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.4058 - accuracy: 0.9049 - val_loss: 0.6903 - val_accuracy: 0.7344\n",
      "Epoch 79/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.3999 - accuracy: 0.9036 - val_loss: 0.7098 - val_accuracy: 0.7240\n",
      "Epoch 80/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.4486 - accuracy: 0.8893 - val_loss: 0.7046 - val_accuracy: 0.7344\n",
      "9/9 [==============================] - 1s 6ms/step - loss: 0.7579 - accuracy: 0.7674\n",
      "Epoch 1/80\n",
      "192/192 [==============================] - 10s 38ms/step - loss: 1.8395 - accuracy: 0.3034 - val_loss: 1.2804 - val_accuracy: 0.5938\n",
      "Epoch 2/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 1.3816 - accuracy: 0.4974 - val_loss: 1.0611 - val_accuracy: 0.6667\n",
      "Epoch 3/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 1.2385 - accuracy: 0.5859 - val_loss: 0.9864 - val_accuracy: 0.7188\n",
      "Epoch 4/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 1.1777 - accuracy: 0.6172 - val_loss: 0.9477 - val_accuracy: 0.7188\n",
      "Epoch 5/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 1.1057 - accuracy: 0.6615 - val_loss: 0.8908 - val_accuracy: 0.7604\n",
      "Epoch 6/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 1.0739 - accuracy: 0.6810 - val_loss: 0.8799 - val_accuracy: 0.7448\n",
      "Epoch 7/80\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 1.0527 - accuracy: 0.6940 - val_loss: 0.8646 - val_accuracy: 0.7656\n",
      "Epoch 8/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.9880 - accuracy: 0.6992 - val_loss: 0.8069 - val_accuracy: 0.7865\n",
      "Epoch 9/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.9537 - accuracy: 0.7292 - val_loss: 0.8044 - val_accuracy: 0.7448\n",
      "Epoch 10/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.9233 - accuracy: 0.7331 - val_loss: 0.8982 - val_accuracy: 0.7188\n",
      "Epoch 11/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.9025 - accuracy: 0.7344 - val_loss: 0.8241 - val_accuracy: 0.7656\n",
      "Epoch 12/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.9087 - accuracy: 0.7422 - val_loss: 0.8766 - val_accuracy: 0.7344\n",
      "Epoch 13/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.8861 - accuracy: 0.7604 - val_loss: 0.7968 - val_accuracy: 0.7552\n",
      "Epoch 14/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.8687 - accuracy: 0.7513 - val_loss: 0.8191 - val_accuracy: 0.7604\n",
      "Epoch 15/80\n",
      "192/192 [==============================] - 6s 28ms/step - loss: 0.8823 - accuracy: 0.7526 - val_loss: 0.7694 - val_accuracy: 0.7656\n",
      "Epoch 16/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.8136 - accuracy: 0.7656 - val_loss: 0.7900 - val_accuracy: 0.7604\n",
      "Epoch 17/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.8117 - accuracy: 0.7826 - val_loss: 0.7193 - val_accuracy: 0.7865\n",
      "Epoch 18/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.7834 - accuracy: 0.7943 - val_loss: 0.7441 - val_accuracy: 0.7917\n",
      "Epoch 19/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.7560 - accuracy: 0.7891 - val_loss: 0.7515 - val_accuracy: 0.7865\n",
      "Epoch 20/80\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 0.7921 - accuracy: 0.7682 - val_loss: 0.7350 - val_accuracy: 0.7969\n",
      "Epoch 21/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.6964 - accuracy: 0.8229 - val_loss: 0.7675 - val_accuracy: 0.7656\n",
      "Epoch 22/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.7553 - accuracy: 0.7760 - val_loss: 0.7474 - val_accuracy: 0.7500\n",
      "Epoch 23/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.7360 - accuracy: 0.7773 - val_loss: 0.7625 - val_accuracy: 0.7812\n",
      "Epoch 24/80\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 0.7072 - accuracy: 0.8125 - val_loss: 0.7102 - val_accuracy: 0.8021\n",
      "Epoch 25/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.7035 - accuracy: 0.7969 - val_loss: 0.7195 - val_accuracy: 0.7708\n",
      "Epoch 26/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.6675 - accuracy: 0.8255 - val_loss: 0.6873 - val_accuracy: 0.7865\n",
      "Epoch 27/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.6732 - accuracy: 0.8099 - val_loss: 0.7151 - val_accuracy: 0.7656\n",
      "Epoch 28/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.6772 - accuracy: 0.8177 - val_loss: 0.7241 - val_accuracy: 0.7865\n",
      "Epoch 29/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.6876 - accuracy: 0.8073 - val_loss: 0.7268 - val_accuracy: 0.7760\n",
      "Epoch 30/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.6632 - accuracy: 0.8385 - val_loss: 0.6935 - val_accuracy: 0.7865\n",
      "Epoch 31/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.6237 - accuracy: 0.8503 - val_loss: 0.7276 - val_accuracy: 0.7760\n",
      "Epoch 32/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.6168 - accuracy: 0.8411 - val_loss: 0.7140 - val_accuracy: 0.7812\n",
      "Epoch 33/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.6914 - accuracy: 0.7982 - val_loss: 0.7718 - val_accuracy: 0.7708\n",
      "Epoch 34/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.6664 - accuracy: 0.8125 - val_loss: 0.7178 - val_accuracy: 0.7812\n",
      "Epoch 35/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.6478 - accuracy: 0.8320 - val_loss: 0.7205 - val_accuracy: 0.7865\n",
      "Epoch 36/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.6156 - accuracy: 0.8229 - val_loss: 0.6963 - val_accuracy: 0.8073\n",
      "Epoch 37/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.6241 - accuracy: 0.8359 - val_loss: 0.7126 - val_accuracy: 0.7552\n",
      "Epoch 38/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.6085 - accuracy: 0.8294 - val_loss: 0.7523 - val_accuracy: 0.7812\n",
      "Epoch 39/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.6120 - accuracy: 0.8190 - val_loss: 0.7036 - val_accuracy: 0.7865\n",
      "Epoch 40/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.6396 - accuracy: 0.8112 - val_loss: 0.7169 - val_accuracy: 0.7656\n",
      "Epoch 41/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.6402 - accuracy: 0.8151 - val_loss: 0.7325 - val_accuracy: 0.7708\n",
      "Epoch 42/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.6994 - accuracy: 0.7943 - val_loss: 0.7374 - val_accuracy: 0.7656\n",
      "Epoch 43/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.5989 - accuracy: 0.8555 - val_loss: 0.7238 - val_accuracy: 0.8021\n",
      "Epoch 44/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.5439 - accuracy: 0.8490 - val_loss: 0.7121 - val_accuracy: 0.7865\n",
      "Epoch 45/80\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.5223 - accuracy: 0.8646 - val_loss: 0.7150 - val_accuracy: 0.7760\n",
      "Epoch 46/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.5670 - accuracy: 0.8294 - val_loss: 0.7214 - val_accuracy: 0.7812\n",
      "Epoch 47/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5729 - accuracy: 0.8424 - val_loss: 0.7082 - val_accuracy: 0.7969\n",
      "Epoch 48/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.5641 - accuracy: 0.8542 - val_loss: 0.7245 - val_accuracy: 0.7760\n",
      "Epoch 49/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5722 - accuracy: 0.8216 - val_loss: 0.7201 - val_accuracy: 0.7656\n",
      "Epoch 50/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.5642 - accuracy: 0.8307 - val_loss: 0.6965 - val_accuracy: 0.7917\n",
      "Epoch 51/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.6232 - accuracy: 0.8372 - val_loss: 0.6791 - val_accuracy: 0.8021\n",
      "Epoch 52/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5291 - accuracy: 0.8620 - val_loss: 0.6650 - val_accuracy: 0.8021\n",
      "Epoch 53/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.5287 - accuracy: 0.8646 - val_loss: 0.6793 - val_accuracy: 0.8073\n",
      "Epoch 54/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.5607 - accuracy: 0.8503 - val_loss: 0.6935 - val_accuracy: 0.8073\n",
      "Epoch 55/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.5164 - accuracy: 0.8698 - val_loss: 0.6676 - val_accuracy: 0.8073\n",
      "Epoch 56/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.5292 - accuracy: 0.8594 - val_loss: 0.6831 - val_accuracy: 0.8073\n",
      "Epoch 57/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.4736 - accuracy: 0.8698 - val_loss: 0.6876 - val_accuracy: 0.8125\n",
      "Epoch 58/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.4900 - accuracy: 0.8672 - val_loss: 0.7073 - val_accuracy: 0.7760\n",
      "Epoch 59/80\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.4475 - accuracy: 0.8932 - val_loss: 0.7180 - val_accuracy: 0.7760\n",
      "Epoch 60/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5054 - accuracy: 0.8711 - val_loss: 0.7223 - val_accuracy: 0.7500\n",
      "Epoch 61/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4818 - accuracy: 0.8685 - val_loss: 0.7493 - val_accuracy: 0.7760\n",
      "Epoch 62/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.4795 - accuracy: 0.8737 - val_loss: 0.7428 - val_accuracy: 0.7656\n",
      "Epoch 63/80\n",
      "192/192 [==============================] - 4s 23ms/step - loss: 0.4833 - accuracy: 0.8672 - val_loss: 0.7188 - val_accuracy: 0.7760\n",
      "Epoch 64/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.4912 - accuracy: 0.8776 - val_loss: 0.7299 - val_accuracy: 0.7656\n",
      "Epoch 65/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.4578 - accuracy: 0.8971 - val_loss: 0.7492 - val_accuracy: 0.7760\n",
      "Epoch 66/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.4776 - accuracy: 0.8659 - val_loss: 0.7387 - val_accuracy: 0.7604\n",
      "Epoch 67/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5067 - accuracy: 0.8659 - val_loss: 0.7301 - val_accuracy: 0.7760\n",
      "Epoch 68/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.5052 - accuracy: 0.8542 - val_loss: 0.7134 - val_accuracy: 0.7917\n",
      "Epoch 69/80\n",
      "192/192 [==============================] - 5s 29ms/step - loss: 0.4328 - accuracy: 0.8828 - val_loss: 0.7137 - val_accuracy: 0.7708\n",
      "Epoch 70/80\n",
      "192/192 [==============================] - 5s 29ms/step - loss: 0.4631 - accuracy: 0.8815 - val_loss: 0.7098 - val_accuracy: 0.7760\n",
      "Epoch 71/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.4374 - accuracy: 0.8893 - val_loss: 0.6802 - val_accuracy: 0.7812\n",
      "Epoch 72/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4632 - accuracy: 0.8880 - val_loss: 0.6773 - val_accuracy: 0.7812\n",
      "Epoch 73/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.4533 - accuracy: 0.8776 - val_loss: 0.6830 - val_accuracy: 0.7865\n",
      "Epoch 74/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.4237 - accuracy: 0.8945 - val_loss: 0.7078 - val_accuracy: 0.7500\n",
      "Epoch 75/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.4220 - accuracy: 0.8906 - val_loss: 0.6963 - val_accuracy: 0.7760\n",
      "Epoch 76/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4251 - accuracy: 0.8919 - val_loss: 0.6999 - val_accuracy: 0.7865\n",
      "Epoch 77/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.4482 - accuracy: 0.8802 - val_loss: 0.7240 - val_accuracy: 0.7656\n",
      "Epoch 78/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.4431 - accuracy: 0.8724 - val_loss: 0.7191 - val_accuracy: 0.7760\n",
      "Epoch 79/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4480 - accuracy: 0.8867 - val_loss: 0.7199 - val_accuracy: 0.7708\n",
      "Epoch 80/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.4110 - accuracy: 0.8997 - val_loss: 0.7139 - val_accuracy: 0.7812\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.7796 - accuracy: 0.7535\n",
      "Epoch 1/80\n",
      "192/192 [==============================] - 9s 35ms/step - loss: 1.8445 - accuracy: 0.3021 - val_loss: 1.2503 - val_accuracy: 0.5625\n",
      "Epoch 2/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 1.3931 - accuracy: 0.5065 - val_loss: 0.9837 - val_accuracy: 0.7031\n",
      "Epoch 3/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 1.2334 - accuracy: 0.5977 - val_loss: 0.9831 - val_accuracy: 0.6927\n",
      "Epoch 4/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 1.1367 - accuracy: 0.6562 - val_loss: 0.8775 - val_accuracy: 0.7604\n",
      "Epoch 5/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 1.0719 - accuracy: 0.6771 - val_loss: 0.8411 - val_accuracy: 0.7708\n",
      "Epoch 6/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 1.0655 - accuracy: 0.6888 - val_loss: 0.8133 - val_accuracy: 0.7604\n",
      "Epoch 7/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.9930 - accuracy: 0.7161 - val_loss: 0.8469 - val_accuracy: 0.7396\n",
      "Epoch 8/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 1.0152 - accuracy: 0.7057 - val_loss: 0.7909 - val_accuracy: 0.7708\n",
      "Epoch 9/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.9379 - accuracy: 0.7422 - val_loss: 0.7777 - val_accuracy: 0.7760\n",
      "Epoch 10/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.9342 - accuracy: 0.7461 - val_loss: 0.7339 - val_accuracy: 0.7552\n",
      "Epoch 11/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.9133 - accuracy: 0.7370 - val_loss: 0.7364 - val_accuracy: 0.7552\n",
      "Epoch 12/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.8793 - accuracy: 0.7565 - val_loss: 0.7182 - val_accuracy: 0.7812\n",
      "Epoch 13/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.8679 - accuracy: 0.7227 - val_loss: 0.7172 - val_accuracy: 0.7760\n",
      "Epoch 14/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.8853 - accuracy: 0.7526 - val_loss: 0.7154 - val_accuracy: 0.7656\n",
      "Epoch 15/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.8028 - accuracy: 0.7721 - val_loss: 0.6468 - val_accuracy: 0.8125\n",
      "Epoch 16/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.8345 - accuracy: 0.7734 - val_loss: 0.6593 - val_accuracy: 0.7656\n",
      "Epoch 17/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.7981 - accuracy: 0.7812 - val_loss: 0.6555 - val_accuracy: 0.7708\n",
      "Epoch 18/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.7961 - accuracy: 0.7786 - val_loss: 0.6359 - val_accuracy: 0.7812\n",
      "Epoch 19/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.8078 - accuracy: 0.7656 - val_loss: 0.6347 - val_accuracy: 0.7812\n",
      "Epoch 20/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.7701 - accuracy: 0.7786 - val_loss: 0.6422 - val_accuracy: 0.7865\n",
      "Epoch 21/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.7234 - accuracy: 0.8021 - val_loss: 0.6009 - val_accuracy: 0.7917\n",
      "Epoch 22/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.7216 - accuracy: 0.8164 - val_loss: 0.6266 - val_accuracy: 0.7969\n",
      "Epoch 23/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.8039 - accuracy: 0.7773 - val_loss: 0.6786 - val_accuracy: 0.7865\n",
      "Epoch 24/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.6951 - accuracy: 0.8125 - val_loss: 0.6139 - val_accuracy: 0.8021\n",
      "Epoch 25/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.7374 - accuracy: 0.7943 - val_loss: 0.6042 - val_accuracy: 0.8125\n",
      "Epoch 26/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.6992 - accuracy: 0.8086 - val_loss: 0.5924 - val_accuracy: 0.8125\n",
      "Epoch 27/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.6688 - accuracy: 0.8099 - val_loss: 0.5792 - val_accuracy: 0.7917\n",
      "Epoch 28/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.6578 - accuracy: 0.8190 - val_loss: 0.5822 - val_accuracy: 0.7760\n",
      "Epoch 29/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.6382 - accuracy: 0.8242 - val_loss: 0.5615 - val_accuracy: 0.8073\n",
      "Epoch 30/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.6149 - accuracy: 0.8333 - val_loss: 0.5894 - val_accuracy: 0.8125\n",
      "Epoch 31/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.6456 - accuracy: 0.8164 - val_loss: 0.5920 - val_accuracy: 0.8021\n",
      "Epoch 32/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.6561 - accuracy: 0.8242 - val_loss: 0.5491 - val_accuracy: 0.8333\n",
      "Epoch 33/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.6791 - accuracy: 0.7995 - val_loss: 0.5801 - val_accuracy: 0.8125\n",
      "Epoch 34/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.6754 - accuracy: 0.8021 - val_loss: 0.5776 - val_accuracy: 0.8177\n",
      "Epoch 35/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.6449 - accuracy: 0.8268 - val_loss: 0.6097 - val_accuracy: 0.8125\n",
      "Epoch 36/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.6569 - accuracy: 0.8021 - val_loss: 0.6437 - val_accuracy: 0.7969\n",
      "Epoch 37/80\n",
      "192/192 [==============================] - 4s 23ms/step - loss: 0.6877 - accuracy: 0.8008 - val_loss: 0.6391 - val_accuracy: 0.8125\n",
      "Epoch 38/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.6224 - accuracy: 0.8294 - val_loss: 0.6241 - val_accuracy: 0.8021\n",
      "Epoch 39/80\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.6025 - accuracy: 0.8411 - val_loss: 0.5804 - val_accuracy: 0.8177\n",
      "Epoch 40/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.5901 - accuracy: 0.8516 - val_loss: 0.5961 - val_accuracy: 0.8125\n",
      "Epoch 41/80\n",
      "192/192 [==============================] - 5s 29ms/step - loss: 0.5828 - accuracy: 0.8411 - val_loss: 0.5666 - val_accuracy: 0.8281\n",
      "Epoch 42/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.5796 - accuracy: 0.8424 - val_loss: 0.5687 - val_accuracy: 0.8385\n",
      "Epoch 43/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.5638 - accuracy: 0.8516 - val_loss: 0.5769 - val_accuracy: 0.8125\n",
      "Epoch 44/80\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.5825 - accuracy: 0.8385 - val_loss: 0.5732 - val_accuracy: 0.8229\n",
      "Epoch 45/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5402 - accuracy: 0.8646 - val_loss: 0.6124 - val_accuracy: 0.8125\n",
      "Epoch 46/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5825 - accuracy: 0.8477 - val_loss: 0.5545 - val_accuracy: 0.8333\n",
      "Epoch 47/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.5441 - accuracy: 0.8490 - val_loss: 0.6006 - val_accuracy: 0.8021\n",
      "Epoch 48/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5034 - accuracy: 0.8672 - val_loss: 0.6118 - val_accuracy: 0.7969\n",
      "Epoch 49/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.5681 - accuracy: 0.8411 - val_loss: 0.5800 - val_accuracy: 0.8021\n",
      "Epoch 50/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.5262 - accuracy: 0.8750 - val_loss: 0.5770 - val_accuracy: 0.8073\n",
      "Epoch 51/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.5187 - accuracy: 0.8724 - val_loss: 0.5729 - val_accuracy: 0.8177\n",
      "Epoch 52/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.5063 - accuracy: 0.8724 - val_loss: 0.6025 - val_accuracy: 0.7812\n",
      "Epoch 53/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.5352 - accuracy: 0.8594 - val_loss: 0.6155 - val_accuracy: 0.7760\n",
      "Epoch 54/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.5102 - accuracy: 0.8763 - val_loss: 0.6189 - val_accuracy: 0.8125\n",
      "Epoch 55/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.5101 - accuracy: 0.8685 - val_loss: 0.5823 - val_accuracy: 0.7969\n",
      "Epoch 56/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.5005 - accuracy: 0.8737 - val_loss: 0.5907 - val_accuracy: 0.7865\n",
      "Epoch 57/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.4861 - accuracy: 0.8815 - val_loss: 0.5494 - val_accuracy: 0.8125\n",
      "Epoch 58/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.5335 - accuracy: 0.8594 - val_loss: 0.5903 - val_accuracy: 0.8177\n",
      "Epoch 59/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5520 - accuracy: 0.8529 - val_loss: 0.5614 - val_accuracy: 0.8177\n",
      "Epoch 60/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4962 - accuracy: 0.8672 - val_loss: 0.5846 - val_accuracy: 0.8021\n",
      "Epoch 61/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.5203 - accuracy: 0.8672 - val_loss: 0.5939 - val_accuracy: 0.8021\n",
      "Epoch 62/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.4807 - accuracy: 0.8880 - val_loss: 0.5876 - val_accuracy: 0.8125\n",
      "Epoch 63/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.4906 - accuracy: 0.8711 - val_loss: 0.5620 - val_accuracy: 0.8125\n",
      "Epoch 64/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.4870 - accuracy: 0.8711 - val_loss: 0.5801 - val_accuracy: 0.8125\n",
      "Epoch 65/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.4649 - accuracy: 0.8789 - val_loss: 0.5832 - val_accuracy: 0.7917\n",
      "Epoch 66/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.4774 - accuracy: 0.8841 - val_loss: 0.5960 - val_accuracy: 0.7917\n",
      "Epoch 67/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.4715 - accuracy: 0.8776 - val_loss: 0.5652 - val_accuracy: 0.7604\n",
      "Epoch 68/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4526 - accuracy: 0.8750 - val_loss: 0.5970 - val_accuracy: 0.7760\n",
      "Epoch 69/80\n",
      "192/192 [==============================] - 5s 29ms/step - loss: 0.4771 - accuracy: 0.8750 - val_loss: 0.5756 - val_accuracy: 0.7865\n",
      "Epoch 70/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5497 - accuracy: 0.8516 - val_loss: 0.5767 - val_accuracy: 0.8021\n",
      "Epoch 71/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.5276 - accuracy: 0.8776 - val_loss: 0.5757 - val_accuracy: 0.7917\n",
      "Epoch 72/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.4723 - accuracy: 0.8763 - val_loss: 0.5875 - val_accuracy: 0.7917\n",
      "Epoch 73/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.4199 - accuracy: 0.9023 - val_loss: 0.5938 - val_accuracy: 0.8281\n",
      "Epoch 74/80\n",
      "192/192 [==============================] - 5s 29ms/step - loss: 0.4569 - accuracy: 0.8737 - val_loss: 0.5832 - val_accuracy: 0.8073\n",
      "Epoch 75/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.4132 - accuracy: 0.9141 - val_loss: 0.5730 - val_accuracy: 0.8229\n",
      "Epoch 76/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.4856 - accuracy: 0.8815 - val_loss: 0.5662 - val_accuracy: 0.7917\n",
      "Epoch 77/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.4257 - accuracy: 0.9010 - val_loss: 0.5897 - val_accuracy: 0.7812\n",
      "Epoch 78/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.4534 - accuracy: 0.8789 - val_loss: 0.5687 - val_accuracy: 0.8125\n",
      "Epoch 79/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.4901 - accuracy: 0.8750 - val_loss: 0.6032 - val_accuracy: 0.7708\n",
      "Epoch 80/80\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.4262 - accuracy: 0.8984 - val_loss: 0.6024 - val_accuracy: 0.7865\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.8265 - accuracy: 0.7118\n",
      "Epoch 1/80\n",
      "192/192 [==============================] - 9s 35ms/step - loss: 1.8230 - accuracy: 0.3125 - val_loss: 1.1427 - val_accuracy: 0.6094\n",
      "Epoch 2/80\n",
      "192/192 [==============================] - 7s 36ms/step - loss: 1.3808 - accuracy: 0.5182 - val_loss: 0.9707 - val_accuracy: 0.6823\n",
      "Epoch 3/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 1.2208 - accuracy: 0.6042 - val_loss: 1.0449 - val_accuracy: 0.6719\n",
      "Epoch 4/80\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 1.1803 - accuracy: 0.6198 - val_loss: 0.9484 - val_accuracy: 0.7292\n",
      "Epoch 5/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 1.1172 - accuracy: 0.6289 - val_loss: 0.9288 - val_accuracy: 0.7083\n",
      "Epoch 6/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 1.0665 - accuracy: 0.6589 - val_loss: 0.8967 - val_accuracy: 0.7396\n",
      "Epoch 7/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 1.0323 - accuracy: 0.6901 - val_loss: 0.8703 - val_accuracy: 0.7448\n",
      "Epoch 8/80\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 0.9774 - accuracy: 0.7201 - val_loss: 0.8299 - val_accuracy: 0.7708\n",
      "Epoch 9/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.9324 - accuracy: 0.7318 - val_loss: 0.7938 - val_accuracy: 0.7812\n",
      "Epoch 10/80\n",
      "192/192 [==============================] - 6s 34ms/step - loss: 0.9166 - accuracy: 0.7331 - val_loss: 0.8107 - val_accuracy: 0.8021\n",
      "Epoch 11/80\n",
      "192/192 [==============================] - 5s 29ms/step - loss: 0.9265 - accuracy: 0.7435 - val_loss: 0.7738 - val_accuracy: 0.7760\n",
      "Epoch 12/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.8885 - accuracy: 0.7474 - val_loss: 0.7657 - val_accuracy: 0.7812\n",
      "Epoch 13/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.8404 - accuracy: 0.7904 - val_loss: 0.7611 - val_accuracy: 0.7865\n",
      "Epoch 14/80\n",
      "192/192 [==============================] - 5s 29ms/step - loss: 0.8608 - accuracy: 0.7656 - val_loss: 0.7979 - val_accuracy: 0.7552\n",
      "Epoch 15/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.8423 - accuracy: 0.7708 - val_loss: 0.7474 - val_accuracy: 0.7917\n",
      "Epoch 16/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.8009 - accuracy: 0.7669 - val_loss: 0.7197 - val_accuracy: 0.7760\n",
      "Epoch 17/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.8450 - accuracy: 0.7695 - val_loss: 0.6824 - val_accuracy: 0.7865\n",
      "Epoch 18/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.7826 - accuracy: 0.8008 - val_loss: 0.6961 - val_accuracy: 0.7760\n",
      "Epoch 19/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.7466 - accuracy: 0.7865 - val_loss: 0.7368 - val_accuracy: 0.7760\n",
      "Epoch 20/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.7327 - accuracy: 0.7982 - val_loss: 0.6900 - val_accuracy: 0.7917\n",
      "Epoch 21/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.6748 - accuracy: 0.8255 - val_loss: 0.7018 - val_accuracy: 0.7865\n",
      "Epoch 22/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.7169 - accuracy: 0.8021 - val_loss: 0.7264 - val_accuracy: 0.7865\n",
      "Epoch 23/80\n",
      "192/192 [==============================] - 7s 34ms/step - loss: 0.7114 - accuracy: 0.8164 - val_loss: 0.7064 - val_accuracy: 0.7865\n",
      "Epoch 24/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.7632 - accuracy: 0.8047 - val_loss: 0.6974 - val_accuracy: 0.7812\n",
      "Epoch 25/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.7023 - accuracy: 0.8242 - val_loss: 0.7343 - val_accuracy: 0.7812\n",
      "Epoch 26/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.6794 - accuracy: 0.8060 - val_loss: 0.7482 - val_accuracy: 0.7865\n",
      "Epoch 27/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.7182 - accuracy: 0.7930 - val_loss: 0.7257 - val_accuracy: 0.8021\n",
      "Epoch 28/80\n",
      "192/192 [==============================] - 6s 32ms/step - loss: 0.6954 - accuracy: 0.8060 - val_loss: 0.6993 - val_accuracy: 0.7969\n",
      "Epoch 29/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.6440 - accuracy: 0.8229 - val_loss: 0.6847 - val_accuracy: 0.7969\n",
      "Epoch 30/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.6519 - accuracy: 0.8164 - val_loss: 0.7267 - val_accuracy: 0.7760\n",
      "Epoch 31/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.6831 - accuracy: 0.8125 - val_loss: 0.7316 - val_accuracy: 0.7656\n",
      "Epoch 32/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.6499 - accuracy: 0.8112 - val_loss: 0.6961 - val_accuracy: 0.7760\n",
      "Epoch 33/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.6135 - accuracy: 0.8255 - val_loss: 0.7114 - val_accuracy: 0.8021\n",
      "Epoch 34/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.6099 - accuracy: 0.8398 - val_loss: 0.7288 - val_accuracy: 0.7812\n",
      "Epoch 35/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.6111 - accuracy: 0.8451 - val_loss: 0.6801 - val_accuracy: 0.8021\n",
      "Epoch 36/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.6404 - accuracy: 0.8320 - val_loss: 0.7190 - val_accuracy: 0.7865\n",
      "Epoch 37/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.6005 - accuracy: 0.8281 - val_loss: 0.6941 - val_accuracy: 0.7448\n",
      "Epoch 38/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.6060 - accuracy: 0.8203 - val_loss: 0.6592 - val_accuracy: 0.7969\n",
      "Epoch 39/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.5629 - accuracy: 0.8490 - val_loss: 0.6864 - val_accuracy: 0.7812\n",
      "Epoch 40/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.6367 - accuracy: 0.8216 - val_loss: 0.6666 - val_accuracy: 0.7865\n",
      "Epoch 41/80\n",
      "192/192 [==============================] - 6s 33ms/step - loss: 0.5442 - accuracy: 0.8633 - val_loss: 0.6426 - val_accuracy: 0.7969\n",
      "Epoch 42/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.5663 - accuracy: 0.8542 - val_loss: 0.6683 - val_accuracy: 0.7760\n",
      "Epoch 43/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.5167 - accuracy: 0.8776 - val_loss: 0.6623 - val_accuracy: 0.7865\n",
      "Epoch 44/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.5312 - accuracy: 0.8802 - val_loss: 0.6982 - val_accuracy: 0.7969\n",
      "Epoch 45/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.5665 - accuracy: 0.8542 - val_loss: 0.6981 - val_accuracy: 0.7708\n",
      "Epoch 46/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.6140 - accuracy: 0.8385 - val_loss: 0.7245 - val_accuracy: 0.8021\n",
      "Epoch 47/80\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.5635 - accuracy: 0.8516 - val_loss: 0.7119 - val_accuracy: 0.7708\n",
      "Epoch 48/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.5422 - accuracy: 0.8607 - val_loss: 0.7119 - val_accuracy: 0.7812\n",
      "Epoch 49/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5292 - accuracy: 0.8698 - val_loss: 0.6940 - val_accuracy: 0.7969\n",
      "Epoch 50/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5569 - accuracy: 0.8451 - val_loss: 0.6623 - val_accuracy: 0.7969\n",
      "Epoch 51/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.5626 - accuracy: 0.8320 - val_loss: 0.6657 - val_accuracy: 0.7760\n",
      "Epoch 52/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.5390 - accuracy: 0.8607 - val_loss: 0.6337 - val_accuracy: 0.8021\n",
      "Epoch 53/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.5441 - accuracy: 0.8424 - val_loss: 0.6608 - val_accuracy: 0.7812\n",
      "Epoch 54/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.5287 - accuracy: 0.8646 - val_loss: 0.6953 - val_accuracy: 0.7760\n",
      "Epoch 55/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5274 - accuracy: 0.8594 - val_loss: 0.6814 - val_accuracy: 0.7969\n",
      "Epoch 56/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.5122 - accuracy: 0.8763 - val_loss: 0.7565 - val_accuracy: 0.7552\n",
      "Epoch 57/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.4716 - accuracy: 0.8867 - val_loss: 0.7445 - val_accuracy: 0.7500\n",
      "Epoch 58/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.4882 - accuracy: 0.8776 - val_loss: 0.7232 - val_accuracy: 0.7656\n",
      "Epoch 59/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.4677 - accuracy: 0.8815 - val_loss: 0.6903 - val_accuracy: 0.7708\n",
      "Epoch 60/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.4640 - accuracy: 0.8919 - val_loss: 0.6682 - val_accuracy: 0.7708\n",
      "Epoch 61/80\n",
      "192/192 [==============================] - 5s 29ms/step - loss: 0.5312 - accuracy: 0.8555 - val_loss: 0.7005 - val_accuracy: 0.7552\n",
      "Epoch 62/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.5360 - accuracy: 0.8685 - val_loss: 0.6945 - val_accuracy: 0.7812\n",
      "Epoch 63/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.4550 - accuracy: 0.8997 - val_loss: 0.6847 - val_accuracy: 0.7969\n",
      "Epoch 64/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.4906 - accuracy: 0.8737 - val_loss: 0.7309 - val_accuracy: 0.7865\n",
      "Epoch 65/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.4643 - accuracy: 0.8841 - val_loss: 0.6897 - val_accuracy: 0.7760\n",
      "Epoch 66/80\n",
      "192/192 [==============================] - 7s 35ms/step - loss: 0.4978 - accuracy: 0.8685 - val_loss: 0.6902 - val_accuracy: 0.7812\n",
      "Epoch 67/80\n",
      "192/192 [==============================] - 5s 24ms/step - loss: 0.4797 - accuracy: 0.8607 - val_loss: 0.6874 - val_accuracy: 0.7812\n",
      "Epoch 68/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4617 - accuracy: 0.8711 - val_loss: 0.6641 - val_accuracy: 0.7865\n",
      "Epoch 69/80\n",
      "192/192 [==============================] - 5s 29ms/step - loss: 0.4738 - accuracy: 0.8802 - val_loss: 0.6806 - val_accuracy: 0.7708\n",
      "Epoch 70/80\n",
      "192/192 [==============================] - 5s 25ms/step - loss: 0.4665 - accuracy: 0.8802 - val_loss: 0.6798 - val_accuracy: 0.7760\n",
      "Epoch 71/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.4878 - accuracy: 0.8828 - val_loss: 0.6890 - val_accuracy: 0.7760\n",
      "Epoch 72/80\n",
      "192/192 [==============================] - 5s 28ms/step - loss: 0.4665 - accuracy: 0.8815 - val_loss: 0.6880 - val_accuracy: 0.8073\n",
      "Epoch 73/80\n",
      "192/192 [==============================] - 6s 29ms/step - loss: 0.4593 - accuracy: 0.8828 - val_loss: 0.6905 - val_accuracy: 0.7969\n",
      "Epoch 74/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4298 - accuracy: 0.8880 - val_loss: 0.6900 - val_accuracy: 0.7760\n",
      "Epoch 75/80\n",
      "192/192 [==============================] - 5s 27ms/step - loss: 0.4357 - accuracy: 0.9049 - val_loss: 0.6919 - val_accuracy: 0.7917\n",
      "Epoch 76/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.4467 - accuracy: 0.8893 - val_loss: 0.7008 - val_accuracy: 0.7865\n",
      "Epoch 77/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.4419 - accuracy: 0.8802 - val_loss: 0.7232 - val_accuracy: 0.7812\n",
      "Epoch 78/80\n",
      "192/192 [==============================] - 6s 30ms/step - loss: 0.4107 - accuracy: 0.9062 - val_loss: 0.6877 - val_accuracy: 0.8125\n",
      "Epoch 79/80\n",
      "192/192 [==============================] - 5s 26ms/step - loss: 0.4307 - accuracy: 0.9089 - val_loss: 0.6846 - val_accuracy: 0.7969\n",
      "Epoch 80/80\n",
      "192/192 [==============================] - 6s 31ms/step - loss: 0.4018 - accuracy: 0.9049 - val_loss: 0.6872 - val_accuracy: 0.7812\n",
      "9/9 [==============================] - 0s 13ms/step - loss: 0.7811 - accuracy: 0.7569\n"
     ]
    }
   ],
   "source": [
    "VALIDATION_ACCURACY_SPEECH = []\n",
    "VALIDATION_LOSS_SPEECH = []\n",
    "\n",
    "save_dir = os.path.abspath(DIR) + '/ravdess_50m50f_intermediatefusion_2ndVariant_PCA_n0.95_model/'\n",
    "fold_var = 1\n",
    "\n",
    "for train_idx, val_idx in kfold.split(concatenated_train_data, y_train_50m_50f):\n",
    "    model=multi_modal_NN()\n",
    "\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
    "\n",
    "    #early_stopping_callback = EarlyStopping(monitor = 'val_accuracy', patience = 15, restore_best_weights = True)\n",
    "\n",
    "    checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(save_dir + get_model_name(fold_var), monitor='val_accuracy',save_best_only=True, mode='max')\n",
    "# Start training the model.\n",
    "    LRCN_model_training_history = model.fit(      x = concatenated_train_data[train_idx],\n",
    "                                                  y = y_train_50m_50f[train_idx],\n",
    "                                                  validation_data=(concatenated_train_data[val_idx], y_train_50m_50f[val_idx]),\n",
    "                                                  epochs = 80,\n",
    "                                                  batch_size = 4,\n",
    "                                                  shuffle = True,\n",
    "                                                  callbacks = [checkpoint_cb])\n",
    "    model.load_weights(save_dir + \"model_\" + str(fold_var) + \".h5\")\n",
    "\t\n",
    "    results = model.evaluate(concatenated_test_data, y_test)\n",
    "    results = dict(zip(model.metrics_names, results))\n",
    "\t\n",
    "    VALIDATION_ACCURACY_SPEECH.append(results['accuracy'])\n",
    "    VALIDATION_LOSS_SPEECH.append(results['loss'])\n",
    "\t\n",
    "    tf.keras.backend.clear_session()\n",
    "\t\n",
    "    fold_var += 1\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa027a0b-5b99-4603-bc03-ecfa109c3b80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
