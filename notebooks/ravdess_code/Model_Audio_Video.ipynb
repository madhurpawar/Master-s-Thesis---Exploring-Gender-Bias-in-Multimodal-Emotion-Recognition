{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "294e87e0-fe45-4028-837d-e8e855f6eb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce GTX TITAN X (UUID: GPU-220d4b5f-cb36-56a7-bc5f-fc109cfd4569)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1ab7b64-89da-4b28-84f2-5c04b53ee17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-02 14:56:50.449783: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c894f002-a6d1-4721-aeb6-3df9ea1e297a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 20:36:33.462839: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import random as rd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "import pickle\n",
    "import dlib\n",
    "\n",
    "from deepface import DeepFace\n",
    "from deepface.basemodels import VGGFace, OpenFace, Facenet, FbDeepFace, DeepID\n",
    "from deepface.extendedmodels import Age, Gender, Race, Emotion\n",
    "#from deepface.modules import verification\n",
    "from deepface.commons import functions, distance as dst\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.layers import Input,Conv2D,MaxPooling2D,Dropout,LSTM,\\\n",
    "                            TimeDistributed,Flatten,Dense,Bidirectional,ConvLSTM2D,MaxPooling3D,AveragePooling2D,Lambda,\\\n",
    "                            Activation,BatchNormalization\n",
    "\n",
    "from tensorflow import keras\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad1ab1a8-fba9-4733-927b-e522a8aa4200",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_constant = 27\n",
    "np.random.seed(seed_constant)\n",
    "rd.seed(seed_constant)\n",
    "tf.random.set_seed(seed_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ac9a764-91d5-4823-ad0a-2313254d5934",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = '/var/scratch/mpa326/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4695d6a5-3f55-48b7-9db0-0c74ebbdc9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "dbfile = open('/var/scratch/mpa326/Ravdess_code/Video Features/video_train_50m_50f', 'rb')     \n",
    "df = pickle.load(dbfile)\n",
    "\n",
    "y_train_50m_50f = df['labels']\n",
    "gender_train_50m_50f = df['genders']\n",
    "X_train_50m_50f=df['features']\n",
    "paths_train_50m_50f = df['video_files_paths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45a9e1c5-f509-4921-a550-9886519fc52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = open('/var/scratch/mpa326/Ravdess_code/Video Features/video_train_40m_60f', 'rb')     \n",
    "df = pickle.load(dbfile)\n",
    "\n",
    "y_train_40m_60f = df['labels']\n",
    "gender_train_40m_60f = df['genders']\n",
    "X_train_40m_60f=df['features']\n",
    "paths_train_40m_60f = df['video_files_paths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc74e1b4-dbb1-4f41-8731-451cad9e184d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = open('/var/scratch/mpa326/Ravdess_code/Video Features/video_train_60m_40f', 'rb')     \n",
    "df = pickle.load(dbfile)\n",
    "\n",
    "y_train_60m_40f = df['labels']\n",
    "gender_train_60m_40f = df['genders']\n",
    "X_train_60m_40f=df['features']\n",
    "paths_train_60m_40f = df['video_files_paths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9dcd380-0048-4f30-a7df-453de05163a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = open('/var/scratch/mpa326/Ravdess_code/Video Features/video_test_common','rb')\n",
    "df = pickle.load(dbfile)\n",
    "\n",
    "y_test = df['labels']\n",
    "gender_test = df['genders']\n",
    "X_test=df['features']\n",
    "paths_test = df['video_files_paths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a8d999f-8bd6-49b3-96f3-96f6de537b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = open('/var/scratch/mpa326/Ravdess_code/Audio Features/audio_train_50m_50f', 'rb')     \n",
    "df = pickle.load(dbfile)\n",
    "X_train_aud_50m_50f=df['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4c10c9e-0fb1-4502-a239-053d483391e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = open('/var/scratch/mpa326/Ravdess_code/Audio Features/audio_train_40m_60f', 'rb')     \n",
    "df = pickle.load(dbfile)\n",
    "X_train_aud_40m_60f=df['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2b9953f-3a34-485a-8ea2-b64563882866",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = open('/var/scratch/mpa326/Ravdess_code/Audio Features/audio_train_60m_40f', 'rb')     \n",
    "df = pickle.load(dbfile)\n",
    "X_train_aud_60m_40f=df['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a10b844-ce1e-4ad7-b893-d645f3227f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfile = open('/var/scratch/mpa326/Ravdess_code/Audio Features/audio_test_common', 'rb')     \n",
    "df = pickle.load(dbfile)\n",
    "X_test_aud=df['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c199714-8a32-40da-85d3-bca88dbbd033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test = np.concatenate((X_val, X_test), axis=0)\n",
    "# X_aud_test = np.concatenate((X_val_aud, X_test_aud), axis=0)\n",
    "# y_test = np.concatenate((y_val, y_test), axis=0)\n",
    "# gender_test = np.concatenate((gender_val, gender_test), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b277374f-92be-428c-9ae1-55abb9adf6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = pd.DataFrame({'paths_train': paths_train})\n",
    "# df_val = pd.DataFrame({'paths_val': paths_val})\n",
    "# df_test = pd.DataFrame({'paths_test': paths_test})\n",
    "\n",
    "# # Export each DataFrame to a separate CSV file\n",
    "# df_train.to_csv('paths_train.csv', index=False)\n",
    "# df_val.to_csv('paths_val.csv', index=False)\n",
    "# df_test.to_csv('paths_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49e5ce57-d199-4a8b-b43e-8b7b34035a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_new_path(old_path):\n",
    "#     # Extract the filename from the old path\n",
    "#     filename = os.path.basename(old_path)\n",
    "#     # Replace the first \"02\" with \"03\"\n",
    "#     new_filename = filename.replace(\"02\", \"03\", 1)\n",
    "#     # Change the extension from .mp4 to .png\n",
    "#     new_filename = os.path.splitext(new_filename)[0] + '.png'\n",
    "#     # Create the new path\n",
    "#     new_path = f\"/var/scratch/mpa326/ravdess_melspec_new/{new_filename}\"\n",
    "#     return new_path\n",
    "\n",
    "# df_train['melspec_path'] = df_train['paths_train'].apply(create_new_path)\n",
    "# df_train.to_csv('paths_train_audio.csv', index=False)\n",
    "# df_val['melspec_path'] = df_val['paths_val'].apply(create_new_path)\n",
    "# df_val.to_csv('paths_val_audio.csv', index=False)\n",
    "# df_test['melspec_path'] = df_test['paths_test'].apply(create_new_path)\n",
    "# df_test.to_csv('paths_test_audio.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b15ef76c-c60e-4ebc-8c31-2129bf4b4a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = 'video_genders.csv'\n",
    "\n",
    "# # Save NumPy array to CSV with newline character as delimiter\n",
    "# np.savetxt(file_path, genders, delimiter='\\n', fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f12d10a3-e4c7-4ab9-a950-43da974f3c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X_train_50m_50f, X_train_aud_50m_50f, y_train_50m_50f, gender_train_50m_50f = shuffle(X_train_50m_50f, X_train_aud_50m_50f, y_train_50m_50f, gender_train_50m_50f, random_state=27)\n",
    "X_train_50m_50f, X_train_aud_50m_50f, y_train_50m_50f, gender_train_50m_50f = shuffle(X_train_50m_50f, X_train_aud_50m_50f, y_train_50m_50f, gender_train_50m_50f, random_state=7)\n",
    "X_train_50m_50f, X_train_aud_50m_50f, y_train_50m_50f, gender_train_50m_50f = shuffle(X_train_50m_50f, X_train_aud_50m_50f, y_train_50m_50f, gender_train_50m_50f, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d134a1c-6307-4a2d-bfed-bbb99125634e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_40m_60f, X_train_aud_40m_60f, y_train_40m_60f, gender_train_40m_60f = shuffle(X_train_40m_60f, X_train_aud_40m_60f, y_train_40m_60f, gender_train_40m_60f, random_state=27)\n",
    "X_train_40m_60f, X_train_aud_40m_60f, y_train_40m_60f, gender_train_40m_60f = shuffle(X_train_40m_60f, X_train_aud_40m_60f, y_train_40m_60f, gender_train_40m_60f, random_state=7)\n",
    "X_train_40m_60f, X_train_aud_40m_60f, y_train_40m_60f, gender_train_40m_60f = shuffle(X_train_40m_60f, X_train_aud_40m_60f, y_train_40m_60f, gender_train_40m_60f, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47fedc06-f68c-44ab-bda9-21cc7823a3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_60m_40f, X_train_aud_60m_40f, y_train_60m_40f, gender_train_60m_40f = shuffle(X_train_60m_40f, X_train_aud_60m_40f, y_train_60m_40f, gender_train_60m_40f, random_state=27)\n",
    "X_train_60m_40f, X_train_aud_60m_40f, y_train_60m_40f, gender_train_60m_40f = shuffle(X_train_60m_40f, X_train_aud_60m_40f, y_train_60m_40f, gender_train_60m_40f, random_state=7)\n",
    "X_train_60m_40f, X_train_aud_60m_40f, y_train_60m_40f, gender_train_60m_40f = shuffle(X_train_60m_40f, X_train_aud_60m_40f, y_train_60m_40f, gender_train_60m_40f, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae43d989-edfa-4f00-b362-45f7cfc9d4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, X_test_aud, y_test, gender_test = shuffle(X_test, X_test_aud, y_test, gender_test, random_state=27)\n",
    "X_test, X_test_aud, y_test, gender_test = shuffle(X_test, X_test_aud, y_test, gender_test, random_state=7)\n",
    "X_test, X_test_aud, y_test, gender_test = shuffle(X_test, X_test_aud, y_test, gender_test, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7403c14e-8aee-468e-9ec4-b0eaed7f0cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d\n",
      "max_pooling2d\n",
      "conv2d_1\n",
      "conv2d_2\n",
      "average_pooling2d\n",
      "conv2d_3\n",
      "conv2d_4\n",
      "average_pooling2d_1\n",
      "flatten\n",
      "dense\n",
      "dropout\n",
      "dense_1\n",
      "dropout_1\n",
      "dense_2\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "emotion=Emotion.loadModel()\n",
    "for layer in emotion.layers:\n",
    "    print(layer.name)\n",
    "features_emotion=Model(inputs=emotion.input, outputs=emotion.get_layer('dense_1').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84445edb-dad2-4a54-ab77-8e0f4219a662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_input (InputLayer)   [(None, 48, 48, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 44, 44, 64)        1664      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 20, 20, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 18, 18, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " average_pooling2d (Average  (None, 7, 7, 64)          0         \n",
      " Pooling2D)                                                      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 5, 5, 128)         73856     \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 3, 3, 128)         147584    \n",
      "                                                                 \n",
      " average_pooling2d_1 (Avera  (None, 1, 1, 128)         0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              132096    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1478656 (5.64 MB)\n",
      "Trainable params: 1478656 (5.64 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "features_emotion.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cc6475b3-9f80-4afb-8fc9-c0fe17def564",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = np.ones((960,20,48,48))\n",
    "for i in range(960):\n",
    "  for j in range(20):\n",
    "    img=X_train_50m_50f[i][j]\n",
    "    img=img.astype(np.float32)\n",
    "    # df_[i][j]=cv2.resize(img,(48, 48))/255\n",
    "    df_[i][j]=img/255\n",
    "X_train_50m_50f=df_\n",
    "df_=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8876c43b-7918-47fe-9495-e80a64e770db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = np.ones((960,20,48,48))\n",
    "for i in range(960):\n",
    "  for j in range(20):\n",
    "    img=X_train_40m_60f[i][j]\n",
    "    img=img.astype(np.float32)\n",
    "    # df_[i][j]=cv2.resize(img,(48, 48))/255\n",
    "    df_[i][j]=img/255\n",
    "X_train_40m_60f=df_\n",
    "df_=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee657003-bd49-4ae3-a2a6-68feb5f2031f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = np.ones((960,20,48,48))\n",
    "for i in range(960):\n",
    "  for j in range(20):\n",
    "    img=X_train_60m_40f[i][j]\n",
    "    img=img.astype(np.float32)\n",
    "    # df_[i][j]=cv2.resize(img,(48, 48))/255\n",
    "    df_[i][j]=img/255\n",
    "X_train_60m_40f=df_\n",
    "df_=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5748e704-4670-4f98-a881-8c5dfaf0a8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = np.ones((288,20,48,48))\n",
    "for i in range(288):\n",
    "  for j in range(20):\n",
    "    img=X_test[i][j]\n",
    "    img=img.astype(np.float32)\n",
    "    # df_[i][j]=cv2.resize(img,(48, 48))/255\n",
    "    df_[i][j]=img/255\n",
    "X_test=df_\n",
    "df_=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ae380fb-e399-467d-9079-b8641ffdf42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices = np.arange(len(X_train_50m_50f))\n",
    "# np.random.shuffle(indices)\n",
    "# X_train_50m_50f = X_train_50m_50f[indices]\n",
    "# X_train_aud_50m_50f = X_train_aud_50m_50f[indices]\n",
    "# y_train_50m_50f = y_train_50m_50f[indices]\n",
    "# gender_train_50m_50f = gender_train_50m_50f[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "707865be-7c89-4893-8ea9-a8c2f501013f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices = np.arange(len(X_train_40m_60f))\n",
    "# np.random.shuffle(indices)\n",
    "# X_train_40m_60f = X_train_40m_60f[indices]\n",
    "# X_train_aud_40m_60f = X_train_aud_40m_60f[indices]\n",
    "# y_train_40m_60f = y_train_40m_60f[indices]\n",
    "# gender_train_40m_60f = gender_train_40m_60f[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e037f34-078c-495d-a321-b04448cddfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices = np.arange(len(X_train_60m_40f))\n",
    "# np.random.shuffle(indices)\n",
    "# X_train_60m_40f = X_train_60m_40f[indices]\n",
    "# X_train_aud_60m_40f = X_train_aud_60m_40f[indices]\n",
    "# y_train_60m_40f = y_train_60m_40f[indices]\n",
    "# gender_train_60m_40f = gender_train_60m_40f[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c44f76a-0324-43f2-99bc-a1c29e3c6a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices = np.arange(len(X_test))\n",
    "# np.random.shuffle(indices)\n",
    "\n",
    "# X_test = X_test[indices]\n",
    "# X_test_aud = X_test_aud[indices]\n",
    "# y_test = y_test[indices]\n",
    "# gender_test = gender_test[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c4d7c2a-2f8c-4d93-bbff-d09fac5ee795",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_emotion.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed516bd3-fd14-475b-b044-ac1a889ec291",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spatial transformer network (STN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "add2ceb2-c213-4781-9e67-efb733e09ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Localization(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(Localization, self).__init__()\n",
    "        self.pool1 = tf.keras.layers.MaxPool2D()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(20, [5, 5], activation='relu')\n",
    "        self.pool2 = tf.keras.layers.MaxPool2D()\n",
    "        self.conv2 = tf.keras.layers.Conv2D(20, [5, 5], activation='relu')\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc1 = tf.keras.layers.Dense(20, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(6, activation=None, bias_initializer=tf.keras.initializers.constant([1.0, 0.0, 0.0, 0.0, 1.0, 0.0]), kernel_initializer='zeros')\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        print(\"Building Localization Network with input shape:\", input_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [None, 2, 3]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        theta = self.fc2(x)\n",
    "        theta = tf.keras.layers.Reshape((2, 3))(theta)\n",
    "        return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8d2a8af-df42-4e61-a9f2-436ee110698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BilinearInterpolation(tf.keras.layers.Layer):\n",
    "    def __init__(self, height=40, width=40):\n",
    "        super(BilinearInterpolation, self).__init__()\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return [None, self.height, self.width, 1]\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            'height': self.height,\n",
    "            'width': self.width,\n",
    "        }\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        print(\"Building Bilinear Interpolation Layer with input shape:\", input_shape)\n",
    "\n",
    "    def advance_indexing(self, inputs, x, y):\n",
    "        '''\n",
    "        Numpy like advance indexing is not supported in tensorflow, hence, this function is a hack around the same method\n",
    "        '''        \n",
    "        shape = tf.shape(inputs)\n",
    "        batch_size, _, _ = shape[0], shape[1], shape[2]\n",
    "        \n",
    "        batch_idx = tf.range(0, batch_size)\n",
    "        batch_idx = tf.reshape(batch_idx, (batch_size, 1, 1))\n",
    "        b = tf.tile(batch_idx, (1, self.height, self.width))\n",
    "        indices = tf.stack([b, y, x], 3)\n",
    "        return tf.gather_nd(inputs, indices)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        images, theta = inputs\n",
    "        homogenous_coordinates = self.grid_generator(batch=tf.shape(images)[0])\n",
    "        return self.interpolate(images, homogenous_coordinates, theta)\n",
    "\n",
    "    def grid_generator(self, batch):\n",
    "        x = tf.linspace(-1, 1, self.width)\n",
    "        y = tf.linspace(-1, 1, self.height)\n",
    "            \n",
    "        xx, yy = tf.meshgrid(x, y)\n",
    "        xx = tf.reshape(xx, (-1,))\n",
    "        yy = tf.reshape(yy, (-1,))\n",
    "        homogenous_coordinates = tf.stack([xx, yy, tf.ones_like(xx)])\n",
    "        homogenous_coordinates = tf.expand_dims(homogenous_coordinates, axis=0)\n",
    "        homogenous_coordinates = tf.tile(homogenous_coordinates, [batch, 1, 1])\n",
    "        homogenous_coordinates = tf.cast(homogenous_coordinates, dtype=tf.float32)\n",
    "        return homogenous_coordinates\n",
    "    \n",
    "    def interpolate(self, images, homogenous_coordinates, theta):\n",
    "\n",
    "        with tf.name_scope(\"Transformation\"):\n",
    "            transformed = tf.matmul(theta, homogenous_coordinates)\n",
    "            transformed = tf.transpose(transformed, perm=[0, 2, 1])\n",
    "            transformed = tf.reshape(transformed, [-1, self.height, self.width, 2])\n",
    "                \n",
    "            x_transformed = transformed[:, :, :, 0]\n",
    "            y_transformed = transformed[:, :, :, 1]\n",
    "                \n",
    "            x = ((x_transformed + 1.) * tf.cast(self.width, dtype=tf.float32)) * 0.5\n",
    "            y = ((y_transformed + 1.) * tf.cast(self.height, dtype=tf.float32)) * 0.5\n",
    "\n",
    "        with tf.name_scope(\"VariableCasting\"):\n",
    "            x0 = tf.cast(tf.math.floor(x), dtype=tf.int32)\n",
    "            x1 = x0 + 1\n",
    "            y0 = tf.cast(tf.math.floor(y), dtype=tf.int32)\n",
    "            y1 = y0 + 1\n",
    "\n",
    "            x0 = tf.clip_by_value(x0, 0, self.width-1)\n",
    "            x1 = tf.clip_by_value(x1, 0, self.width-1)\n",
    "            y0 = tf.clip_by_value(y0, 0, self.height-1)\n",
    "            y1 = tf.clip_by_value(y1, 0, self.height-1)\n",
    "            x = tf.clip_by_value(x, 0, tf.cast(self.width, dtype=tf.float32)-1.0)\n",
    "            y = tf.clip_by_value(y, 0, tf.cast(self.height, dtype=tf.float32)-1)\n",
    "\n",
    "        with tf.name_scope(\"AdvanceIndexing\"):\n",
    "            Ia = self.advance_indexing(images, x0, y0)\n",
    "            Ib = self.advance_indexing(images, x0, y1)\n",
    "            Ic = self.advance_indexing(images, x1, y0)\n",
    "            Id = self.advance_indexing(images, x1, y1)\n",
    "\n",
    "        with tf.name_scope(\"Interpolation\"):\n",
    "            x0 = tf.cast(x0, dtype=tf.float32)\n",
    "            x1 = tf.cast(x1, dtype=tf.float32)\n",
    "            y0 = tf.cast(y0, dtype=tf.float32)\n",
    "            y1 = tf.cast(y1, dtype=tf.float32)\n",
    "                            \n",
    "            wa = (x1-x) * (y1-y)\n",
    "            wb = (x1-x) * (y-y0)\n",
    "            wc = (x-x0) * (y1-y)\n",
    "            wd = (x-x0) * (y-y0)\n",
    "\n",
    "            wa = tf.expand_dims(wa, axis=3)\n",
    "            wb = tf.expand_dims(wb, axis=3)\n",
    "            wc = tf.expand_dims(wc, axis=3)\n",
    "            wd = tf.expand_dims(wd, axis=3)\n",
    "                        \n",
    "        return tf.math.add_n([wa*Ia + wb*Ib + wc*Ic + wd*Id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f86775d6-eb86-4502-8332-c46dad0408cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_en = [\"neutral\", \"calm\", \"happy\", \"sad\", \"angry\", \"fearful\", \"disgust\", \"surprised\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21dc2896-b2b4-441f-a1c3-69b35f2ccb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create__LRCN_with_STN() :\n",
    "  image = tf.keras.layers.Input(shape=(20,48,48,1))\n",
    "  theta = TimeDistributed(Localization())(image)\n",
    "  x = TimeDistributed(BilinearInterpolation(height=48, width=48))([image, theta])\n",
    "  features=TimeDistributed(features_emotion)(x)\n",
    "  lstm=Bidirectional(LSTM(200, activation='tanh',input_shape=(20, 1024),dropout=.3))(features)\n",
    "  out=Dense(len(emotions_en), activation = 'softmax')(lstm)\n",
    "\n",
    "  return tf.keras.models.Model(inputs=image, outputs=out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32d02546-a1db-4634-bb03-cc234b2fb8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Localization Network with input shape: (None, 48, 48, 1)\n",
      "Building Bilinear Interpolation Layer with input shape: ((None, 48, 48, 1), (None, 2, 3))\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 20, 48, 48, 1)]      0         []                            \n",
      "                                                                                                  \n",
      " time_distributed (TimeDist  (None, 20, 2, 3)             43086     ['input_1[0][0]']             \n",
      " ributed)                                                                                         \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDi  (None, 20, 48, 48, 1)        0         ['input_1[0][0]',             \n",
      " stributed)                                                          'time_distributed[0][0]']    \n",
      "                                                                                                  \n",
      " time_distributed_2 (TimeDi  (None, 20, 1024)             1478656   ['time_distributed_1[0][0]']  \n",
      " stributed)                                                                                       \n",
      "                                                                                                  \n",
      " bidirectional (Bidirection  (None, 400)                  1960000   ['time_distributed_2[0][0]']  \n",
      " al)                                                                                              \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 8)                    3208      ['bidirectional[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3484950 (13.29 MB)\n",
      "Trainable params: 2006294 (7.65 MB)\n",
      "Non-trainable params: 1478656 (5.64 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "create__LRCN_with_STN().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09caf5b5-e48f-4d02-82cc-7388ae11f91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(k):\n",
    "    return 'model_'+str(k)+'.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d97c3964-8e98-4068-88a6-6cb3ce334659",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "seed = 7\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c50fd42-c276-4333-adee-cac98f7e2ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value female appears 480 times\n",
      "Value male appears 480 times\n"
     ]
    }
   ],
   "source": [
    "unique_values, counts = np.unique(gender_train_50m_50f, return_counts=True)\n",
    "\n",
    "# Print the results\n",
    "for value, count in zip(unique_values, counts):\n",
    "    print(f\"Value {value} appears {count} times\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "702502e9-6e87-4913-ae0b-05fe3c7d66ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value female appears 576 times\n",
      "Value male appears 384 times\n"
     ]
    }
   ],
   "source": [
    "unique_values, counts = np.unique(gender_train_40m_60f, return_counts=True)\n",
    "\n",
    "# Print the results\n",
    "for value, count in zip(unique_values, counts):\n",
    "    print(f\"Value {value} appears {count} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce7776f6-aad7-457a-a855-04112aafb5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value female appears 384 times\n",
      "Value male appears 576 times\n"
     ]
    }
   ],
   "source": [
    "unique_values, counts = np.unique(gender_train_60m_40f, return_counts=True)\n",
    "\n",
    "# Print the results\n",
    "for value, count in zip(unique_values, counts):\n",
    "    print(f\"Value {value} appears {count} times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c88ec373-db6f-4167-9f76-bdbd7652af22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Localization Network with input shape: (None, 48, 48, 1)\n",
      "Building Bilinear Interpolation Layer with input shape: ((None, 48, 48, 1), (None, 2, 3))\n",
      "Epoch 1/80\n",
      "96/96 [==============================] - 26s 211ms/step - loss: 1.5091 - accuracy: 0.4414 - val_loss: 1.3383 - val_accuracy: 0.4792\n",
      "Epoch 2/80\n",
      "96/96 [==============================] - 18s 192ms/step - loss: 1.2113 - accuracy: 0.5599 - val_loss: 1.2176 - val_accuracy: 0.5052\n",
      "Epoch 3/80\n",
      "96/96 [==============================] - 18s 192ms/step - loss: 1.0401 - accuracy: 0.5977 - val_loss: 1.0755 - val_accuracy: 0.6042\n",
      "Epoch 4/80\n",
      "96/96 [==============================] - 18s 192ms/step - loss: 0.9077 - accuracy: 0.6628 - val_loss: 1.1551 - val_accuracy: 0.5625\n",
      "Epoch 5/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 0.7977 - accuracy: 0.7174 - val_loss: 1.0790 - val_accuracy: 0.6198\n",
      "Epoch 6/80\n",
      "96/96 [==============================] - 18s 191ms/step - loss: 0.8750 - accuracy: 0.6771 - val_loss: 1.1670 - val_accuracy: 0.5677\n",
      "Epoch 7/80\n",
      "96/96 [==============================] - 18s 192ms/step - loss: 0.7640 - accuracy: 0.7305 - val_loss: 1.0876 - val_accuracy: 0.6198\n",
      "Epoch 8/80\n",
      "96/96 [==============================] - 19s 193ms/step - loss: 0.6141 - accuracy: 0.7695 - val_loss: 1.0843 - val_accuracy: 0.6562\n",
      "Epoch 9/80\n",
      "96/96 [==============================] - 18s 191ms/step - loss: 0.5243 - accuracy: 0.8112 - val_loss: 1.0520 - val_accuracy: 0.6510\n",
      "Epoch 10/80\n",
      "96/96 [==============================] - 19s 193ms/step - loss: 0.4702 - accuracy: 0.8281 - val_loss: 1.0144 - val_accuracy: 0.6406\n",
      "Epoch 11/80\n",
      "96/96 [==============================] - 19s 193ms/step - loss: 0.3680 - accuracy: 0.8711 - val_loss: 1.1404 - val_accuracy: 0.6250\n",
      "Epoch 12/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 0.2727 - accuracy: 0.9115 - val_loss: 1.0157 - val_accuracy: 0.6719\n",
      "Epoch 13/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 0.1982 - accuracy: 0.9440 - val_loss: 1.1703 - val_accuracy: 0.6719\n",
      "Epoch 14/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 0.1771 - accuracy: 0.9440 - val_loss: 1.0086 - val_accuracy: 0.6771\n",
      "Epoch 15/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 0.1371 - accuracy: 0.9492 - val_loss: 1.1424 - val_accuracy: 0.6615\n",
      "Epoch 16/80\n",
      "96/96 [==============================] - 19s 193ms/step - loss: 0.1260 - accuracy: 0.9701 - val_loss: 1.1330 - val_accuracy: 0.6562\n",
      "Epoch 17/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 0.1007 - accuracy: 0.9740 - val_loss: 1.0236 - val_accuracy: 0.6719\n",
      "Epoch 18/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 0.0561 - accuracy: 0.9909 - val_loss: 1.0964 - val_accuracy: 0.6875\n",
      "Epoch 19/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 0.0585 - accuracy: 0.9857 - val_loss: 1.1742 - val_accuracy: 0.6823\n",
      "Epoch 20/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 0.1119 - accuracy: 0.9635 - val_loss: 1.1256 - val_accuracy: 0.6354\n",
      "Epoch 21/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 0.0831 - accuracy: 0.9766 - val_loss: 1.3757 - val_accuracy: 0.6458\n",
      "Epoch 22/80\n",
      "96/96 [==============================] - 19s 198ms/step - loss: 0.0537 - accuracy: 0.9922 - val_loss: 1.1363 - val_accuracy: 0.6979\n",
      "Epoch 23/80\n",
      "96/96 [==============================] - 19s 198ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 1.0973 - val_accuracy: 0.7135\n",
      "Epoch 24/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.1031 - val_accuracy: 0.6823\n",
      "Epoch 25/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.1337 - val_accuracy: 0.7031\n",
      "Epoch 26/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.1408 - val_accuracy: 0.6927\n",
      "Epoch 27/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.1441 - val_accuracy: 0.7083\n",
      "Epoch 28/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.1598 - val_accuracy: 0.7083\n",
      "Epoch 29/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.1730 - val_accuracy: 0.6927\n",
      "Epoch 30/80\n",
      "96/96 [==============================] - 18s 192ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.2127 - val_accuracy: 0.6823\n",
      "Epoch 31/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.1966 - val_accuracy: 0.6979\n",
      "Epoch 32/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.2408 - val_accuracy: 0.6979\n",
      "Epoch 33/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.2389 - val_accuracy: 0.7188\n",
      "Epoch 34/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 9.6107e-04 - accuracy: 1.0000 - val_loss: 1.2421 - val_accuracy: 0.7083\n",
      "Epoch 35/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 9.0823e-04 - accuracy: 1.0000 - val_loss: 1.2610 - val_accuracy: 0.6927\n",
      "Epoch 36/80\n",
      "96/96 [==============================] - 19s 193ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.2736 - val_accuracy: 0.6875\n",
      "Epoch 37/80\n",
      "96/96 [==============================] - 19s 193ms/step - loss: 7.6473e-04 - accuracy: 1.0000 - val_loss: 1.2393 - val_accuracy: 0.6927\n",
      "Epoch 38/80\n",
      "96/96 [==============================] - 19s 197ms/step - loss: 6.7391e-04 - accuracy: 1.0000 - val_loss: 1.2342 - val_accuracy: 0.6979\n",
      "Epoch 39/80\n",
      "96/96 [==============================] - 19s 197ms/step - loss: 8.4993e-04 - accuracy: 1.0000 - val_loss: 1.2108 - val_accuracy: 0.7135\n",
      "Epoch 40/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 5.7300e-04 - accuracy: 1.0000 - val_loss: 1.2169 - val_accuracy: 0.7083\n",
      "Epoch 41/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 5.0813e-04 - accuracy: 1.0000 - val_loss: 1.2238 - val_accuracy: 0.7031\n",
      "Epoch 42/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 4.2384e-04 - accuracy: 1.0000 - val_loss: 1.2555 - val_accuracy: 0.6875\n",
      "Epoch 43/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 3.4674e-04 - accuracy: 1.0000 - val_loss: 1.2506 - val_accuracy: 0.6927\n",
      "Epoch 44/80\n",
      "96/96 [==============================] - 19s 197ms/step - loss: 3.8174e-04 - accuracy: 1.0000 - val_loss: 1.2585 - val_accuracy: 0.6875\n",
      "Epoch 45/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 3.4813e-04 - accuracy: 1.0000 - val_loss: 1.2533 - val_accuracy: 0.6823\n",
      "Epoch 46/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 2.7630e-04 - accuracy: 1.0000 - val_loss: 1.2631 - val_accuracy: 0.6771\n",
      "Epoch 47/80\n",
      "96/96 [==============================] - 19s 197ms/step - loss: 3.2032e-04 - accuracy: 1.0000 - val_loss: 1.2935 - val_accuracy: 0.6979\n",
      "Epoch 48/80\n",
      "96/96 [==============================] - 19s 200ms/step - loss: 3.6503e-04 - accuracy: 1.0000 - val_loss: 1.2970 - val_accuracy: 0.7135\n",
      "9/9 [==============================] - 2s 158ms/step - loss: 1.3845 - accuracy: 0.7014\n",
      "Building Localization Network with input shape: (None, 48, 48, 1)\n",
      "Building Bilinear Interpolation Layer with input shape: ((None, 48, 48, 1), (None, 2, 3))\n",
      "Epoch 1/80\n",
      "96/96 [==============================] - 27s 215ms/step - loss: 1.5505 - accuracy: 0.4102 - val_loss: 1.2566 - val_accuracy: 0.4792\n",
      "Epoch 2/80\n",
      "96/96 [==============================] - 19s 197ms/step - loss: 1.2219 - accuracy: 0.5456 - val_loss: 1.0464 - val_accuracy: 0.6146\n",
      "Epoch 3/80\n",
      "96/96 [==============================] - 19s 197ms/step - loss: 1.0621 - accuracy: 0.5964 - val_loss: 0.9971 - val_accuracy: 0.6198\n",
      "Epoch 4/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 0.9629 - accuracy: 0.6406 - val_loss: 0.9420 - val_accuracy: 0.6562\n",
      "Epoch 5/80\n",
      "96/96 [==============================] - 19s 193ms/step - loss: 0.8209 - accuracy: 0.6901 - val_loss: 0.9348 - val_accuracy: 0.6562\n",
      "Epoch 6/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 0.7173 - accuracy: 0.7266 - val_loss: 0.7741 - val_accuracy: 0.7188\n",
      "Epoch 7/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 0.6480 - accuracy: 0.7487 - val_loss: 0.8983 - val_accuracy: 0.6510\n",
      "Epoch 8/80\n",
      "96/96 [==============================] - 18s 192ms/step - loss: 0.5346 - accuracy: 0.8164 - val_loss: 0.8777 - val_accuracy: 0.6979\n",
      "Epoch 9/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 0.3973 - accuracy: 0.8646 - val_loss: 0.8716 - val_accuracy: 0.7396\n",
      "Epoch 10/80\n",
      "96/96 [==============================] - 19s 193ms/step - loss: 0.3526 - accuracy: 0.8815 - val_loss: 0.8904 - val_accuracy: 0.7031\n",
      "Epoch 11/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 0.2651 - accuracy: 0.9219 - val_loss: 0.7288 - val_accuracy: 0.7708\n",
      "Epoch 12/80\n",
      "96/96 [==============================] - 19s 193ms/step - loss: 0.1876 - accuracy: 0.9310 - val_loss: 0.7784 - val_accuracy: 0.7344\n",
      "Epoch 13/80\n",
      "96/96 [==============================] - 18s 192ms/step - loss: 0.1857 - accuracy: 0.9414 - val_loss: 0.7446 - val_accuracy: 0.7448\n",
      "Epoch 14/80\n",
      "96/96 [==============================] - 19s 193ms/step - loss: 0.1675 - accuracy: 0.9492 - val_loss: 0.8350 - val_accuracy: 0.7812\n",
      "Epoch 15/80\n",
      "96/96 [==============================] - 18s 191ms/step - loss: 0.1290 - accuracy: 0.9635 - val_loss: 0.9102 - val_accuracy: 0.7240\n",
      "Epoch 16/80\n",
      "96/96 [==============================] - 18s 192ms/step - loss: 0.0969 - accuracy: 0.9714 - val_loss: 0.9012 - val_accuracy: 0.7396\n",
      "Epoch 17/80\n",
      "96/96 [==============================] - 18s 192ms/step - loss: 0.1005 - accuracy: 0.9661 - val_loss: 0.9236 - val_accuracy: 0.7188\n",
      "Epoch 18/80\n",
      "96/96 [==============================] - 19s 193ms/step - loss: 0.0593 - accuracy: 0.9870 - val_loss: 0.8660 - val_accuracy: 0.7604\n",
      "Epoch 19/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 0.0317 - accuracy: 0.9935 - val_loss: 0.8546 - val_accuracy: 0.7604\n",
      "Epoch 20/80\n",
      "96/96 [==============================] - 19s 197ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.8144 - val_accuracy: 0.8021\n",
      "Epoch 21/80\n",
      "96/96 [==============================] - 18s 192ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.8763 - val_accuracy: 0.7812\n",
      "Epoch 22/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.9242 - val_accuracy: 0.7917\n",
      "Epoch 23/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.9354 - val_accuracy: 0.7708\n",
      "Epoch 24/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.9444 - val_accuracy: 0.7708\n",
      "Epoch 25/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.9494 - val_accuracy: 0.7708\n",
      "Epoch 26/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.9586 - val_accuracy: 0.7656\n",
      "Epoch 27/80\n",
      "96/96 [==============================] - 19s 197ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9550 - val_accuracy: 0.7760\n",
      "Epoch 28/80\n",
      "96/96 [==============================] - 19s 197ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.9623 - val_accuracy: 0.7917\n",
      "Epoch 29/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.9905 - val_accuracy: 0.7760\n",
      "Epoch 30/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 9.9563e-04 - accuracy: 1.0000 - val_loss: 1.0094 - val_accuracy: 0.7812\n",
      "Epoch 31/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.0047 - val_accuracy: 0.7865\n",
      "Epoch 32/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 8.0087e-04 - accuracy: 1.0000 - val_loss: 1.0255 - val_accuracy: 0.7917\n",
      "Epoch 33/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 9.7283e-04 - accuracy: 1.0000 - val_loss: 1.0454 - val_accuracy: 0.7812\n",
      "Epoch 34/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 7.5808e-04 - accuracy: 1.0000 - val_loss: 1.0330 - val_accuracy: 0.7969\n",
      "Epoch 35/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 8.8020e-04 - accuracy: 1.0000 - val_loss: 1.0443 - val_accuracy: 0.7969\n",
      "9/9 [==============================] - 3s 162ms/step - loss: 1.1515 - accuracy: 0.6806\n",
      "Building Localization Network with input shape: (None, 48, 48, 1)\n",
      "Building Bilinear Interpolation Layer with input shape: ((None, 48, 48, 1), (None, 2, 3))\n",
      "Epoch 1/80\n",
      "96/96 [==============================] - 26s 213ms/step - loss: 1.5009 - accuracy: 0.4167 - val_loss: 1.4863 - val_accuracy: 0.4740\n",
      "Epoch 2/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 1.1940 - accuracy: 0.5508 - val_loss: 1.2549 - val_accuracy: 0.5312\n",
      "Epoch 3/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 1.0457 - accuracy: 0.6172 - val_loss: 1.2001 - val_accuracy: 0.5781\n",
      "Epoch 4/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 0.9033 - accuracy: 0.6628 - val_loss: 1.1589 - val_accuracy: 0.5625\n",
      "Epoch 5/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 0.7889 - accuracy: 0.7109 - val_loss: 1.0722 - val_accuracy: 0.5938\n",
      "Epoch 6/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 0.6622 - accuracy: 0.7604 - val_loss: 1.1050 - val_accuracy: 0.5938\n",
      "Epoch 7/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 0.6319 - accuracy: 0.7630 - val_loss: 1.1458 - val_accuracy: 0.5938\n",
      "Epoch 8/80\n",
      "96/96 [==============================] - 19s 197ms/step - loss: 0.5255 - accuracy: 0.7956 - val_loss: 1.0994 - val_accuracy: 0.6250\n",
      "Epoch 9/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 0.4096 - accuracy: 0.8529 - val_loss: 1.0179 - val_accuracy: 0.6562\n",
      "Epoch 10/80\n",
      "96/96 [==============================] - 19s 193ms/step - loss: 0.2823 - accuracy: 0.8997 - val_loss: 1.1797 - val_accuracy: 0.6354\n",
      "Epoch 11/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 0.2612 - accuracy: 0.9089 - val_loss: 1.2403 - val_accuracy: 0.6354\n",
      "Epoch 12/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 0.1988 - accuracy: 0.9414 - val_loss: 1.3823 - val_accuracy: 0.6042\n",
      "Epoch 13/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 0.1529 - accuracy: 0.9531 - val_loss: 1.3620 - val_accuracy: 0.5885\n",
      "Epoch 14/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 0.1520 - accuracy: 0.9492 - val_loss: 1.1140 - val_accuracy: 0.6667\n",
      "Epoch 15/80\n",
      "96/96 [==============================] - 18s 192ms/step - loss: 0.1099 - accuracy: 0.9661 - val_loss: 1.2238 - val_accuracy: 0.6406\n",
      "Epoch 16/80\n",
      "96/96 [==============================] - 19s 193ms/step - loss: 0.0715 - accuracy: 0.9857 - val_loss: 1.2366 - val_accuracy: 0.6458\n",
      "Epoch 17/80\n",
      "96/96 [==============================] - 18s 192ms/step - loss: 0.0388 - accuracy: 0.9909 - val_loss: 1.4418 - val_accuracy: 0.6510\n",
      "Epoch 18/80\n",
      "96/96 [==============================] - 18s 192ms/step - loss: 0.0812 - accuracy: 0.9753 - val_loss: 1.4220 - val_accuracy: 0.6406\n",
      "Epoch 19/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 0.1084 - accuracy: 0.9661 - val_loss: 1.1452 - val_accuracy: 0.6719\n",
      "Epoch 20/80\n",
      "96/96 [==============================] - 19s 193ms/step - loss: 0.0754 - accuracy: 0.9818 - val_loss: 1.2902 - val_accuracy: 0.7031\n",
      "Epoch 21/80\n",
      "96/96 [==============================] - 18s 190ms/step - loss: 0.1166 - accuracy: 0.9635 - val_loss: 1.3770 - val_accuracy: 0.6771\n",
      "Epoch 22/80\n",
      "96/96 [==============================] - 18s 191ms/step - loss: 0.0640 - accuracy: 0.9857 - val_loss: 1.3664 - val_accuracy: 0.6615\n",
      "Epoch 23/80\n",
      "96/96 [==============================] - 18s 191ms/step - loss: 0.0529 - accuracy: 0.9870 - val_loss: 1.3386 - val_accuracy: 0.6771\n",
      "Epoch 24/80\n",
      "96/96 [==============================] - 18s 193ms/step - loss: 0.0521 - accuracy: 0.9870 - val_loss: 1.3502 - val_accuracy: 0.6406\n",
      "Epoch 25/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 0.0261 - accuracy: 0.9935 - val_loss: 1.4292 - val_accuracy: 0.6667\n",
      "Epoch 26/80\n",
      "96/96 [==============================] - 19s 193ms/step - loss: 0.0079 - accuracy: 0.9987 - val_loss: 1.4017 - val_accuracy: 0.6615\n",
      "Epoch 27/80\n",
      "96/96 [==============================] - 19s 193ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.3788 - val_accuracy: 0.6562\n",
      "Epoch 28/80\n",
      "96/96 [==============================] - 19s 193ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.3901 - val_accuracy: 0.6667\n",
      "Epoch 29/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.4013 - val_accuracy: 0.6562\n",
      "Epoch 30/80\n",
      "96/96 [==============================] - 18s 192ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.4287 - val_accuracy: 0.6510\n",
      "Epoch 31/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.4331 - val_accuracy: 0.6562\n",
      "Epoch 32/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.4452 - val_accuracy: 0.6562\n",
      "Epoch 33/80\n",
      "96/96 [==============================] - 19s 193ms/step - loss: 9.6361e-04 - accuracy: 1.0000 - val_loss: 1.4783 - val_accuracy: 0.6510\n",
      "Epoch 34/80\n",
      "96/96 [==============================] - 18s 193ms/step - loss: 8.9316e-04 - accuracy: 1.0000 - val_loss: 1.4729 - val_accuracy: 0.6562\n",
      "Epoch 35/80\n",
      "96/96 [==============================] - 18s 192ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.4830 - val_accuracy: 0.6562\n",
      "9/9 [==============================] - 2s 159ms/step - loss: 1.1913 - accuracy: 0.6840\n",
      "Building Localization Network with input shape: (None, 48, 48, 1)\n",
      "Building Bilinear Interpolation Layer with input shape: ((None, 48, 48, 1), (None, 2, 3))\n",
      "Epoch 1/80\n",
      "96/96 [==============================] - 25s 211ms/step - loss: 1.5114 - accuracy: 0.4036 - val_loss: 1.3404 - val_accuracy: 0.4792\n",
      "Epoch 2/80\n",
      "96/96 [==============================] - 18s 192ms/step - loss: 1.1618 - accuracy: 0.5820 - val_loss: 1.3824 - val_accuracy: 0.4271\n",
      "Epoch 3/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 1.0157 - accuracy: 0.6289 - val_loss: 1.2483 - val_accuracy: 0.5729\n",
      "Epoch 4/80\n",
      "96/96 [==============================] - 18s 192ms/step - loss: 0.8667 - accuracy: 0.6693 - val_loss: 1.1984 - val_accuracy: 0.5417\n",
      "Epoch 5/80\n",
      "96/96 [==============================] - 18s 190ms/step - loss: 0.7512 - accuracy: 0.7240 - val_loss: 1.1551 - val_accuracy: 0.5625\n",
      "Epoch 6/80\n",
      "96/96 [==============================] - 18s 189ms/step - loss: 0.6519 - accuracy: 0.7617 - val_loss: 1.1926 - val_accuracy: 0.5469\n",
      "Epoch 7/80\n",
      "96/96 [==============================] - 18s 189ms/step - loss: 0.5839 - accuracy: 0.7969 - val_loss: 1.3766 - val_accuracy: 0.5208\n",
      "Epoch 8/80\n",
      "96/96 [==============================] - 18s 192ms/step - loss: 0.4464 - accuracy: 0.8451 - val_loss: 1.2911 - val_accuracy: 0.5885\n",
      "Epoch 9/80\n",
      "96/96 [==============================] - 18s 189ms/step - loss: 0.3582 - accuracy: 0.8724 - val_loss: 1.4055 - val_accuracy: 0.5104\n",
      "Epoch 10/80\n",
      "96/96 [==============================] - 18s 190ms/step - loss: 0.4077 - accuracy: 0.8477 - val_loss: 1.3426 - val_accuracy: 0.5417\n",
      "Epoch 11/80\n",
      "96/96 [==============================] - 19s 193ms/step - loss: 0.2498 - accuracy: 0.9284 - val_loss: 1.3663 - val_accuracy: 0.5990\n",
      "Epoch 12/80\n",
      "96/96 [==============================] - 18s 192ms/step - loss: 0.1949 - accuracy: 0.9401 - val_loss: 1.3570 - val_accuracy: 0.5885\n",
      "Epoch 13/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 0.1335 - accuracy: 0.9635 - val_loss: 1.5268 - val_accuracy: 0.5781\n",
      "Epoch 14/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 0.1259 - accuracy: 0.9688 - val_loss: 1.4093 - val_accuracy: 0.6354\n",
      "Epoch 15/80\n",
      "96/96 [==============================] - 19s 193ms/step - loss: 0.0695 - accuracy: 0.9831 - val_loss: 1.5329 - val_accuracy: 0.6146\n",
      "Epoch 16/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 0.0387 - accuracy: 0.9922 - val_loss: 1.6591 - val_accuracy: 0.6146\n",
      "Epoch 17/80\n",
      "96/96 [==============================] - 19s 197ms/step - loss: 0.0791 - accuracy: 0.9792 - val_loss: 1.5245 - val_accuracy: 0.5781\n",
      "Epoch 18/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 0.1359 - accuracy: 0.9583 - val_loss: 1.5603 - val_accuracy: 0.5781\n",
      "Epoch 19/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 0.0860 - accuracy: 0.9740 - val_loss: 1.5288 - val_accuracy: 0.5885\n",
      "Epoch 20/80\n",
      "96/96 [==============================] - 18s 193ms/step - loss: 0.0447 - accuracy: 0.9935 - val_loss: 1.6392 - val_accuracy: 0.6094\n",
      "Epoch 21/80\n",
      "96/96 [==============================] - 18s 192ms/step - loss: 0.0235 - accuracy: 0.9974 - val_loss: 1.6230 - val_accuracy: 0.6094\n",
      "Epoch 22/80\n",
      "96/96 [==============================] - 18s 191ms/step - loss: 0.0406 - accuracy: 0.9909 - val_loss: 1.5743 - val_accuracy: 0.6198\n",
      "Epoch 23/80\n",
      "96/96 [==============================] - 18s 191ms/step - loss: 0.0135 - accuracy: 0.9987 - val_loss: 1.7501 - val_accuracy: 0.6198\n",
      "Epoch 24/80\n",
      "96/96 [==============================] - 18s 193ms/step - loss: 0.0725 - accuracy: 0.9779 - val_loss: 1.7742 - val_accuracy: 0.5833\n",
      "Epoch 25/80\n",
      "96/96 [==============================] - 18s 192ms/step - loss: 0.0876 - accuracy: 0.9779 - val_loss: 1.5414 - val_accuracy: 0.6250\n",
      "Epoch 26/80\n",
      "96/96 [==============================] - 19s 193ms/step - loss: 0.0821 - accuracy: 0.9727 - val_loss: 1.7995 - val_accuracy: 0.5990\n",
      "Epoch 27/80\n",
      "96/96 [==============================] - 19s 193ms/step - loss: 0.0540 - accuracy: 0.9896 - val_loss: 1.7978 - val_accuracy: 0.6302\n",
      "Epoch 28/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 0.0438 - accuracy: 0.9883 - val_loss: 1.8088 - val_accuracy: 0.5938\n",
      "Epoch 29/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 0.0328 - accuracy: 0.9935 - val_loss: 1.8755 - val_accuracy: 0.5938\n",
      "9/9 [==============================] - 2s 157ms/step - loss: 1.1192 - accuracy: 0.6562\n",
      "Building Localization Network with input shape: (None, 48, 48, 1)\n",
      "Building Bilinear Interpolation Layer with input shape: ((None, 48, 48, 1), (None, 2, 3))\n",
      "Epoch 1/80\n",
      "96/96 [==============================] - 27s 216ms/step - loss: 1.5522 - accuracy: 0.3932 - val_loss: 1.2692 - val_accuracy: 0.5469\n",
      "Epoch 2/80\n",
      "96/96 [==============================] - 19s 197ms/step - loss: 1.2143 - accuracy: 0.5482 - val_loss: 1.0899 - val_accuracy: 0.5625\n",
      "Epoch 3/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 1.0127 - accuracy: 0.6211 - val_loss: 1.1104 - val_accuracy: 0.5938\n",
      "Epoch 4/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 0.8794 - accuracy: 0.6719 - val_loss: 1.0668 - val_accuracy: 0.5938\n",
      "Epoch 5/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 0.7792 - accuracy: 0.7057 - val_loss: 0.9792 - val_accuracy: 0.6094\n",
      "Epoch 6/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 0.7047 - accuracy: 0.7487 - val_loss: 1.0085 - val_accuracy: 0.6406\n",
      "Epoch 7/80\n",
      "96/96 [==============================] - 19s 193ms/step - loss: 0.5953 - accuracy: 0.7786 - val_loss: 1.0176 - val_accuracy: 0.5990\n",
      "Epoch 8/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 0.4756 - accuracy: 0.8151 - val_loss: 1.0529 - val_accuracy: 0.6562\n",
      "Epoch 9/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 0.4089 - accuracy: 0.8607 - val_loss: 0.9749 - val_accuracy: 0.6510\n",
      "Epoch 10/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 0.3421 - accuracy: 0.8880 - val_loss: 0.9530 - val_accuracy: 0.6875\n",
      "Epoch 11/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 0.2828 - accuracy: 0.8971 - val_loss: 0.9613 - val_accuracy: 0.6823\n",
      "Epoch 12/80\n",
      "96/96 [==============================] - 19s 193ms/step - loss: 0.2009 - accuracy: 0.9375 - val_loss: 0.9969 - val_accuracy: 0.6823\n",
      "Epoch 13/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 0.1968 - accuracy: 0.9362 - val_loss: 0.9976 - val_accuracy: 0.6771\n",
      "Epoch 14/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 0.0880 - accuracy: 0.9831 - val_loss: 1.0668 - val_accuracy: 0.6771\n",
      "Epoch 15/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 0.1054 - accuracy: 0.9661 - val_loss: 1.1834 - val_accuracy: 0.6875\n",
      "Epoch 16/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 0.1017 - accuracy: 0.9779 - val_loss: 1.0303 - val_accuracy: 0.6927\n",
      "Epoch 17/80\n",
      "96/96 [==============================] - 18s 192ms/step - loss: 0.0585 - accuracy: 0.9870 - val_loss: 1.1007 - val_accuracy: 0.6875\n",
      "Epoch 18/80\n",
      "96/96 [==============================] - 18s 191ms/step - loss: 0.0944 - accuracy: 0.9753 - val_loss: 1.2165 - val_accuracy: 0.6771\n",
      "Epoch 19/80\n",
      "96/96 [==============================] - 18s 192ms/step - loss: 0.1279 - accuracy: 0.9583 - val_loss: 1.3337 - val_accuracy: 0.6562\n",
      "Epoch 20/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 0.1014 - accuracy: 0.9753 - val_loss: 1.2061 - val_accuracy: 0.6771\n",
      "Epoch 21/80\n",
      "96/96 [==============================] - 19s 197ms/step - loss: 0.0798 - accuracy: 0.9779 - val_loss: 1.1610 - val_accuracy: 0.6979\n",
      "Epoch 22/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 0.0813 - accuracy: 0.9779 - val_loss: 1.1092 - val_accuracy: 0.7240\n",
      "Epoch 23/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 0.0592 - accuracy: 0.9844 - val_loss: 1.2081 - val_accuracy: 0.6979\n",
      "Epoch 24/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 0.0484 - accuracy: 0.9857 - val_loss: 1.1322 - val_accuracy: 0.7083\n",
      "Epoch 25/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 0.0218 - accuracy: 0.9974 - val_loss: 1.1960 - val_accuracy: 0.7031\n",
      "Epoch 26/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 0.0316 - accuracy: 0.9935 - val_loss: 1.3319 - val_accuracy: 0.6458\n",
      "Epoch 27/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 0.0775 - accuracy: 0.9753 - val_loss: 1.1163 - val_accuracy: 0.6979\n",
      "Epoch 28/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 0.0508 - accuracy: 0.9818 - val_loss: 1.0000 - val_accuracy: 0.7500\n",
      "Epoch 29/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.0967 - val_accuracy: 0.7344\n",
      "Epoch 30/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 0.0111 - accuracy: 0.9987 - val_loss: 1.1385 - val_accuracy: 0.7083\n",
      "Epoch 31/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1638 - val_accuracy: 0.7344\n",
      "Epoch 32/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.1558 - val_accuracy: 0.7240\n",
      "Epoch 33/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.1702 - val_accuracy: 0.7240\n",
      "Epoch 34/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.1536 - val_accuracy: 0.7448\n",
      "Epoch 35/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.1630 - val_accuracy: 0.7292\n",
      "Epoch 36/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.1878 - val_accuracy: 0.7240\n",
      "Epoch 37/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.1586 - val_accuracy: 0.7448\n",
      "Epoch 38/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.1816 - val_accuracy: 0.7396\n",
      "Epoch 39/80\n",
      "96/96 [==============================] - 19s 193ms/step - loss: 7.6175e-04 - accuracy: 1.0000 - val_loss: 1.1913 - val_accuracy: 0.7292\n",
      "Epoch 40/80\n",
      "96/96 [==============================] - 19s 193ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.2235 - val_accuracy: 0.7083\n",
      "Epoch 41/80\n",
      "96/96 [==============================] - 19s 193ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.2075 - val_accuracy: 0.7396\n",
      "Epoch 42/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 6.1246e-04 - accuracy: 1.0000 - val_loss: 1.2393 - val_accuracy: 0.7448\n",
      "Epoch 43/80\n",
      "96/96 [==============================] - 19s 197ms/step - loss: 5.0988e-04 - accuracy: 1.0000 - val_loss: 1.2321 - val_accuracy: 0.7552\n",
      "Epoch 44/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 4.7168e-04 - accuracy: 1.0000 - val_loss: 1.2441 - val_accuracy: 0.7448\n",
      "Epoch 45/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 5.7523e-04 - accuracy: 1.0000 - val_loss: 1.2691 - val_accuracy: 0.7500\n",
      "Epoch 46/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 4.5013e-04 - accuracy: 1.0000 - val_loss: 1.2762 - val_accuracy: 0.7552\n",
      "Epoch 47/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 3.7123e-04 - accuracy: 1.0000 - val_loss: 1.2686 - val_accuracy: 0.7448\n",
      "Epoch 48/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 2.8940e-04 - accuracy: 1.0000 - val_loss: 1.2841 - val_accuracy: 0.7552\n",
      "Epoch 49/80\n",
      "96/96 [==============================] - 19s 193ms/step - loss: 4.1537e-04 - accuracy: 1.0000 - val_loss: 1.3094 - val_accuracy: 0.7500\n",
      "Epoch 50/80\n",
      "96/96 [==============================] - 19s 194ms/step - loss: 2.6185e-04 - accuracy: 1.0000 - val_loss: 1.3061 - val_accuracy: 0.7552\n",
      "Epoch 51/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 2.5433e-04 - accuracy: 1.0000 - val_loss: 1.2934 - val_accuracy: 0.7500\n",
      "Epoch 52/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 2.2883e-04 - accuracy: 1.0000 - val_loss: 1.3009 - val_accuracy: 0.7500\n",
      "Epoch 53/80\n",
      "96/96 [==============================] - 19s 195ms/step - loss: 2.2503e-04 - accuracy: 1.0000 - val_loss: 1.3001 - val_accuracy: 0.7552\n",
      "Epoch 54/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 1.9541e-04 - accuracy: 1.0000 - val_loss: 1.3165 - val_accuracy: 0.7552\n",
      "Epoch 55/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 2.3619e-04 - accuracy: 1.0000 - val_loss: 1.3477 - val_accuracy: 0.7396\n",
      "Epoch 56/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 1.8131e-04 - accuracy: 1.0000 - val_loss: 1.3302 - val_accuracy: 0.7344\n",
      "Epoch 57/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 1.7918e-04 - accuracy: 1.0000 - val_loss: 1.3107 - val_accuracy: 0.7500\n",
      "Epoch 58/80\n",
      "96/96 [==============================] - 19s 196ms/step - loss: 2.1870e-04 - accuracy: 1.0000 - val_loss: 1.3812 - val_accuracy: 0.7344\n",
      "9/9 [==============================] - 2s 161ms/step - loss: 1.5406 - accuracy: 0.7222\n"
     ]
    }
   ],
   "source": [
    "VALIDATION_ACCURACY = []\n",
    "VALIDATION_LOSS = []\n",
    "\n",
    "save_dir = os.path.abspath(DIR)+'/ravdess_60m40f_video_model/'\n",
    "fold_var = 1\n",
    "\n",
    "for train_idx, val_idx in kfold.split(X_train_60m_40f, y_train_60m_40f):\n",
    "  # with tpu_strategy.scope():\n",
    "  model=create__LRCN_with_STN() \n",
    "  model.compile(loss='sparse_categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
    "  early_stopping_callback = EarlyStopping(monitor = 'val_accuracy', patience = 15, restore_best_weights = True)\n",
    "  checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(save_dir+get_model_name(fold_var), \n",
    "        monitor='val_accuracy', \n",
    "        save_best_only=True, mode='max')\n",
    "\n",
    "  LRCN_model_training_history = model.fit(        x = X_train_60m_40f[train_idx],\n",
    "                                                  y = y_train_60m_40f[train_idx],\n",
    "                                                  validation_data=(X_train_60m_40f[val_idx],y_train_60m_40f[val_idx]),\n",
    "                                                  epochs = 80,\n",
    "                                                  batch_size = 8,\n",
    "                                                  shuffle = True,\n",
    "                                                  callbacks = [checkpoint_cb,early_stopping_callback])\n",
    "\n",
    "  model.load_weights(save_dir+\"model_\"+str(fold_var)+\".h5\")\n",
    "\t\n",
    "  results = model.evaluate(X_test, y_test)\n",
    "  results = dict(zip(model.metrics_names,results))\n",
    "\t\n",
    "  VALIDATION_ACCURACY.append(results['accuracy'])\n",
    "  VALIDATION_LOSS.append(results['loss'])\n",
    "\t\n",
    "  tf.keras.backend.clear_session()\n",
    "\t\n",
    "  fold_var += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ba2c1487-a86f-49a1-b738-980d6e390dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Localization Network with input shape: (None, 48, 48, 1)\n",
      "Building Bilinear Interpolation Layer with input shape: ((None, 48, 48, 1), (None, 2, 3))\n",
      "9/9 [==============================] - 4s 146ms/step - loss: 7.7533 - accuracy: 0.1319\n",
      "Test set evaluation: {'loss': 7.753340721130371, 'accuracy': 0.1319444477558136}\n",
      "5/5 [==============================] - 2s 139ms/step\n",
      "5/5 [==============================] - 1s 136ms/step\n",
      "Gender bias analysis: {'female': {'accuracy': 0.1111111111111111, 'precision': 0.10728945761840498, 'recall': 0.11085526315789473, 'f1': 0.10767020569804298, 'tpr': array([0.1       , 0.        , 0.26315789, 0.15789474, 0.05263158,\n",
      "       0.05      , 0.10526316, 0.15789474]), 'fpr_value': array([0.08955224, 0.144     , 0.104     , 0.2       , 0.104     ,\n",
      "       0.09677419, 0.136     , 0.144     ]), 'fnr_value': array([0.9       , 1.        , 0.73684211, 0.84210526, 0.94736842,\n",
      "       0.95      , 0.89473684, 0.84210526]), 'precision_value': array([0.07692308, 0.        , 0.27777778, 0.10714286, 0.07142857,\n",
      "       0.07692308, 0.10526316, 0.14285714]), 'positive_rate': 3.611111111111111}, 'male': {'accuracy': 0.1527777777777778, 'precision': 0.14816038075309174, 'recall': 0.1493421052631579, 'f1': 0.14803279848657047, 'tpr': array([0.1       , 0.2       , 0.21052632, 0.21052632, 0.05263158,\n",
      "       0.21052632, 0.10526316, 0.10526316]), 'fpr_value': array([0.07462687, 0.15322581, 0.128     , 0.136     , 0.104     ,\n",
      "       0.096     , 0.12      , 0.16      ]), 'fnr_value': array([0.9       , 0.8       , 0.78947368, 0.78947368, 0.94736842,\n",
      "       0.78947368, 0.89473684, 0.89473684]), 'precision_value': array([0.09090909, 0.17391304, 0.2       , 0.19047619, 0.07142857,\n",
      "       0.25      , 0.11764706, 0.09090909]), 'positive_rate': 3.5972222222222223}}\n",
      "Disparate Impact Ratio: 0.9961538461538462\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'csv_file_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 106\u001b[0m\n\u001b[1;32m    104\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;66;03m#csv_file_path = 'video_metrics_results_7th_Jul.csv'\u001b[39;00m\n\u001b[0;32m--> 106\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[43mcsv_file_path\u001b[49m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;66;03m#gender_accuracy[gender] = final_model.evaluate(X_test[gender_indices], y_test[gender_indices])[1]\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'csv_file_path' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "save_dir = os.path.abspath(DIR)+'/ravdess_50m50f_video_model/'\n",
    "final_model = create__LRCN_with_STN()\n",
    "final_model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=[\"accuracy\"])\n",
    "final_model.load_weights(save_dir + \"model_1.h5\")  # Adjust to load the best model if necessary\n",
    "\n",
    "test_results = final_model.evaluate(X_test, y_test)\n",
    "test_results = dict(zip(final_model.metrics_names, test_results))\n",
    "\n",
    "print(\"Test set evaluation:\", test_results)\n",
    "\n",
    "# Gender bias analysis\n",
    "metrics_by_gender = {}\n",
    "for gender in np.unique(gender_test):\n",
    "    gender_indices = np.where(gender_test == gender)\n",
    "    X_gender_test = X_test[gender_indices]\n",
    "    y_gender_test = y_test[gender_indices]\n",
    "    y_pred = np.argmax(final_model.predict(X_gender_test), axis=1)\n",
    "\n",
    "    accuracy = np.mean(y_pred == y_gender_test)\n",
    "    precision = precision_score(y_gender_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_gender_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_gender_test, y_pred, average='macro')\n",
    "\n",
    "    cm = confusion_matrix(y_gender_test, y_pred)\n",
    "    tn = np.sum(cm) - (np.sum(cm, axis=0) + np.sum(cm, axis=1) - np.diag(cm))\n",
    "    fp = np.sum(cm, axis=0) - np.diag(cm)\n",
    "    fn = np.sum(cm, axis=1) - np.diag(cm)\n",
    "    tp = np.diag(cm)\n",
    "    tpr = tp / (tp + fn)  # True Positive Rate\n",
    "    fpr = fp / (fp + tn)  # False Positive Rate\n",
    "    fnr = fn / (fn + tp)  # False Negative Rate\n",
    "    precision_value = tp / (tp + fp)\n",
    "\n",
    "    metrics_by_gender[gender] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'tpr': tpr,\n",
    "        'fpr_value': fpr,\n",
    "        'fnr_value': fnr,\n",
    "        'precision_value': precision_value,\n",
    "        'positive_rate': np.mean(y_pred)\n",
    "    }\n",
    "\n",
    "#Additional fairness metrics\n",
    "positive_rates = [metrics_by_gender[gender]['positive_rate'] for gender in metrics_by_gender]\n",
    "disparate_impact_ratio = min(positive_rates) / max(positive_rates)\n",
    "\n",
    "print(\"Gender bias analysis:\", metrics_by_gender)\n",
    "print(\"Disparate Impact Ratio:\", disparate_impact_ratio)\n",
    "\n",
    "for gender in metrics_by_gender:\n",
    "    metrics_by_gender[gender]['demographic_parity'] = metrics_by_gender[gender]['positive_rate']\n",
    "    metrics_by_gender[gender]['equalized_odds'] = (metrics_by_gender[gender]['fpr_value'], metrics_by_gender[gender]['fnr_value'])\n",
    "    metrics_by_gender[gender]['equal_opportunity'] = metrics_by_gender[gender]['tpr']\n",
    "    metrics_by_gender[gender]['predictive_parity'] = metrics_by_gender[gender]['precision_value']\n",
    "\n",
    "    \n",
    "# avg_fpr_values = [np.mean(fpr) for fpr in fpr_value]\n",
    "# avg_fnr_values = [np.mean(fnr) for fnr in fnr_value]\n",
    "\n",
    "# false_positive_equality = max(avg_fpr_values) - min(avg_fpr_values)\n",
    "# false_negative_equality = max(avg_fnr_values) - min(avg_fnr_values)\n",
    "\n",
    "# print(\"False Positive Equality:\", false_positive_equality)\n",
    "# print(\"False Negative Equality:\", false_negative_equality) \n",
    "\n",
    "\n",
    "# for gender in metrics_by_gender:\n",
    "#     print(f\"Gender: {gender}\")\n",
    "#     print(f\"  Demographic Parity: {metrics_by_gender[gender]['demographic_parity']}\")\n",
    "#     print(f\"  Equalized Odds (FPR, FNR): {metrics_by_gender[gender]['equalized_odds']}\")\n",
    "#     print(f\"  Equal Opportunity (TPR): {metrics_by_gender[gender]['equal_opportunity']}\")\n",
    "#     print(f\"  Predictive Parity: {metrics_by_gender[gender]['predictive_parity']}\")\n",
    "\n",
    "\n",
    "data = {\n",
    "    'Metric': [\n",
    "        'Accuracy', 'Precision', 'Recall', 'F1 Score', 'True Positive Rate', 'False Positive Rate',\n",
    "        'False Negative Rate', 'Predictive Parity', 'Positive Rate', 'Demographic Parity',\n",
    "        'Equalized Odds (FPR, FNR)', 'Equal Opportunity (TPR)'\n",
    "    ],\n",
    "    'Male': [\n",
    "        metrics_by_gender['male']['accuracy'], metrics_by_gender['male']['precision'],\n",
    "        metrics_by_gender['male']['recall'], metrics_by_gender['male']['f1'],\n",
    "        metrics_by_gender['male']['tpr'], metrics_by_gender['male']['fpr_value'],\n",
    "        metrics_by_gender['male']['fnr_value'], metrics_by_gender['male']['precision_value'],\n",
    "        metrics_by_gender['male']['positive_rate'], metrics_by_gender['male']['demographic_parity'],\n",
    "        metrics_by_gender['male']['equalized_odds'], metrics_by_gender['male']['equal_opportunity']\n",
    "    ],\n",
    "    'Female': [\n",
    "        metrics_by_gender['female']['accuracy'], metrics_by_gender['female']['precision'],\n",
    "        metrics_by_gender['female']['recall'], metrics_by_gender['female']['f1'],\n",
    "        metrics_by_gender['female']['tpr'], metrics_by_gender['female']['fpr_value'],\n",
    "        metrics_by_gender['female']['fnr_value'], metrics_by_gender['female']['precision_value'],\n",
    "        metrics_by_gender['female']['positive_rate'], metrics_by_gender['female']['demographic_parity'],\n",
    "        metrics_by_gender['female']['equalized_odds'], metrics_by_gender['female']['equal_opportunity']\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create DataFrame and display\n",
    "df = pd.DataFrame(data)\n",
    "#csv_file_path = 'video_metrics_results_7th_Jul.csv'\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "\n",
    "#gender_accuracy[gender] = final_model.evaluate(X_test[gender_indices], y_test[gender_indices])[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9aa4ff89-87d1-450a-bf27-46e7c2115508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values: ['female' 'male']\n",
      "Counts: [107 109]\n"
     ]
    }
   ],
   "source": [
    "unique_values, counts = np.unique(gender_test, return_counts=True)\n",
    "\n",
    "# Displaying the results\n",
    "print(\"Unique values:\", unique_values)\n",
    "print(\"Counts:\", counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5afcc1fd-c98a-4505-8b0d-7780b5eb1395",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d7a3ee0-1e39-4a82-bcca-0485f6e8de8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_alexnet():\n",
    "  AlexNet = Sequential()\n",
    "\n",
    "  #1st Convolutional Layer\n",
    "  AlexNet.add(Conv2D(filters=96, input_shape=(128,128,3), kernel_size=(11,11), strides=(4,4), padding='same'))\n",
    "  AlexNet.add(BatchNormalization())\n",
    "  AlexNet.add(Activation('relu'))\n",
    "  AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='same'))\n",
    "\n",
    "  #2nd Convolutional Layer\n",
    "  AlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\n",
    "  AlexNet.add(BatchNormalization())\n",
    "  AlexNet.add(Activation('relu'))\n",
    "  AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='same'))\n",
    "\n",
    "  #3rd Convolutional Layer\n",
    "  AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "  AlexNet.add(BatchNormalization())\n",
    "  AlexNet.add(Activation('relu'))\n",
    "\n",
    "  #4th Convolutional Layer\n",
    "  AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "  AlexNet.add(BatchNormalization())\n",
    "  AlexNet.add(Activation('relu'))\n",
    "\n",
    "  #5th Convolutional Layer\n",
    "  AlexNet.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "  AlexNet.add(BatchNormalization())\n",
    "  AlexNet.add(Activation('relu'))\n",
    "  AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(1,1), padding='same'))\n",
    "\n",
    "  #Passing it to a Fully Connected layer\n",
    "  AlexNet.add(Flatten())\n",
    "  AlexNet.add(Dense(4096, input_shape=(32,32,3,)))\n",
    "  AlexNet.add(BatchNormalization())\n",
    "  AlexNet.add(Activation('relu'))\n",
    "  AlexNet.add(Dropout(0.4))\n",
    "\n",
    "  # #2nd Fully Connected Layer\n",
    "  # AlexNet.add(Dense(4096))\n",
    "  # AlexNet.add(BatchNormalization())\n",
    "  # AlexNet.add(Activation('relu'))\n",
    "  # #Add Dropout\n",
    "  # AlexNet.add(Dropout(0.4))\n",
    "\n",
    "  #3rd Fully Connected Layer\n",
    "  AlexNet.add(Dense(1000))\n",
    "  AlexNet.add(BatchNormalization())\n",
    "  AlexNet.add(Activation('relu'))\n",
    "  #Add Dropout\n",
    "  AlexNet.add(Dropout(0.4))\n",
    "\n",
    "  #Output Layer\n",
    "  AlexNet.add(Dense(8))\n",
    "  AlexNet.add(BatchNormalization())\n",
    "  AlexNet.add(Activation('softmax'))\n",
    "\n",
    "  return AlexNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4c5c1cf-b6f8-40c8-9ed8-b30fea6252a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 96)        34944     \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 32, 32, 96)        384       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32, 32, 96)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 32, 32, 96)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 256)       614656    \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 32, 32, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 32, 32, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 384)       885120    \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 32, 32, 384)       1536      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 32, 32, 384)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 384)       1327488   \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 32, 32, 384)       1536      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 32, 32, 384)       0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 32, 32, 256)       884992    \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 32, 32, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 32, 32, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 262144)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              1073745920\n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 4096)              16384     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 4096)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1000)              4097000   \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 1000)              4000      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 1000)              0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1000)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 8008      \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 8)                 32        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 8)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1081624048 (4.03 GB)\n",
      "Trainable params: 1081611088 (4.03 GB)\n",
      "Non-trainable params: 12960 (50.62 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_alexnet().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b174b52-d667-46fd-8eba-4af73a37b77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.EfficientNetV2B1(\n",
    "    weights='imagenet',\n",
    "    input_shape=(224, 224, 3),\n",
    "    include_top=False)\n",
    "# Freeze base model\n",
    "base_model.trainable = False\n",
    "def model_feature_extraction():\n",
    "  inputs = keras.Input(shape=(224, 224, 3))\n",
    "  x = tf.cast(inputs, tf.float32)\n",
    "  # x = tf.keras.applications.efficientnet.preprocess_input(x)\n",
    "  x = base_model(inputs, training=False)\n",
    "  x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "  inter = keras.layers.Dense(1024,activation='relu')(x)\n",
    "  outputs = keras.layers.Dense(8,activation = 'softmax')(inter)\n",
    "  model = keras.Model(inputs, outputs)\n",
    "  model.summary()\n",
    "\n",
    "  return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df616cdd-19ff-48a4-a8ad-6cac5bb4293b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbfile = open('data_audio_1D', 'rb')\n",
    "# df_aud = pickle.load(dbfile)\n",
    "# labels = df_aud['labels']\n",
    "\n",
    "\n",
    "# dbfile = open('data_mel_new', 'rb')\n",
    "# df_audio_1=pickle.load(dbfile)\n",
    "# df_audio = df_audio_1['features']\n",
    "# labels = df_audio_1['labels']\n",
    "# genders_audio = df_audio_1['genders']\n",
    "# paths = df_audio_1['video_files_paths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4214bac-1e85-4228-aabd-bcd2d83bc52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbfile = open('audio_train', 'rb')\n",
    "# df = pickle.load(dbfile)\n",
    "# X_train_aud = df['features']\n",
    "# y_train_aud = df['labels']\n",
    "# gender_train_aud = df['genders']\n",
    "# paths_train_aud = df['audio_file_paths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e563a519-d989-48a3-8120-b7ba33608f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbfile = open('audio_val', 'rb')\n",
    "# df = pickle.load(dbfile)\n",
    "# X_val_aud = df['features']\n",
    "# y_val_aud = df['labels']\n",
    "# gender_val_aud = df['genders']\n",
    "# paths_val_aud = df['audio_file_paths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "90f0b44f-1f0c-4ed4-a643-8a89fbaae3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbfile = open('audio_test', 'rb')\n",
    "# df = pickle.load(dbfile)\n",
    "# X_test_aud = df['features']\n",
    "# y_test_aud = df['labels']\n",
    "# gender_test_aud = df['genders']\n",
    "# paths_test_aud = df['audio_file_paths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "abccb46a-7f93-4a67-a748-c553077f320b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 4, ..., 3, 6, 4])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# emotion_to_index = {emotion: idx for idx, emotion in enumerate(emotions_en)}\n",
    "# y_train_aud = np.array([emotion_to_index[emotion] for emotion in y_train_aud], dtype=int)\n",
    "# y_val_aud = np.array([emotion_to_index[emotion] for emotion in y_val_aud], dtype=int)\n",
    "# y_test_aud = np.array([emotion_to_index[emotion] for emotion in y_test_aud], dtype=int)\n",
    "# y_train_aud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b9c0403e-d9f2-4763-9440-f0224779140b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(1440, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "# print(type(df_audio))\n",
    "\n",
    "# #df_audio = np.array(df_audio)\n",
    "\n",
    "# # Check the type to confirm the conversion\n",
    "# print(type(df_audio))  # Output should be <class 'numpy.ndarray'>\n",
    "# print(df_audio.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "510c40d8-3c44-48ad-8e1f-8c7431509561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def resize_images(images, new_size=(128, 128)):\n",
    "#     resized_images = tf.image.resize(images, new_size)\n",
    "#     return resized_images\n",
    "\n",
    "# # Resize the dataset\n",
    "# df_audio_tensor = tf.convert_to_tensor(df_audio)\n",
    "# df_audio_resized = resize_images(df_audio_tensor, new_size=(128, 128))\n",
    "# df_audio_resized = df_audio_resized.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6f7788a-f6af-4abd-9c53-db3cf5c248dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440, 128, 128, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_audio_resized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f554676-604f-41de-8b15-90c31b3766a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440,)\n"
     ]
    }
   ],
   "source": [
    "# labels = np.array(labels)\n",
    "# print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e7c3f97-e642-4cd4-bb11-13404e055f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440,)\n"
     ]
    }
   ],
   "source": [
    "# #genders = np.array(genders_audio)\n",
    "# print(genders.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5d41c37a-e866-40ab-8cfd-6911a4c5452d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (1008, 128, 128, 3)\n",
      "Validation set shape: (216, 128, 128, 3)\n",
      "Test set shape: (216, 128, 128, 3)\n",
      "Label Train set shape: (1008,)\n",
      "Label Validation set shape: (216,)\n",
      "Label Test set shape: (216,)\n",
      "GenderTrain set shape: ['female' 'male' 'female' ... 'female' 'male' 'male']\n",
      "Gender Validation set shape: (216,)\n",
      "Gender Test set shape: (216,)\n"
     ]
    }
   ],
   "source": [
    "# combined_labels = [(e, g) for e, g in zip(labels, genders)]\n",
    "# X_train, X_temp, y_train, y_temp, gender_train, gender_temp = train_test_split(\n",
    "#     df_audio, labels, genders, test_size=0.3, stratify=combined_labels, random_state=42\n",
    "# )\n",
    "\n",
    "# combined_temp_labels = [(e, g) for e, g in zip(y_temp, gender_temp)]\n",
    "\n",
    "# # Split the temporary set into validation and test sets\n",
    "# X_val, X_test, y_val, y_test, gender_val, gender_test = train_test_split(\n",
    "#     X_temp, y_temp, gender_temp, test_size=0.5, stratify=combined_temp_labels, random_state=42\n",
    "# )\n",
    "\n",
    "# print(\"Train set shape:\", X_train.shape)\n",
    "# print(\"Validation set shape:\", X_val.shape)\n",
    "# print(\"Test set shape:\", X_test.shape)\n",
    "\n",
    "# print(\"Label Train set shape:\", y_train.shape)\n",
    "# print(\"Label Validation set shape:\", y_val.shape)\n",
    "# print(\"Label Test set shape:\", y_test.shape)\n",
    "\n",
    "# print(\"GenderTrain set shape:\", gender_train)\n",
    "# print(\"Gender Validation set shape:\", gender_val.shape)\n",
    "# print(\"Gender Test set shape:\", gender_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3de93c6-ed9b-4b93-8a9f-bd4a0ca4ab21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 21:05:06.297423: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 4294967296 exceeds 10% of free system memory.\n",
      "2024-07-29 21:05:06.846655: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 4294967296 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "96/96 [==============================] - 822s 8s/step - loss: 2.1121 - accuracy: 0.1979 - val_loss: 43.6466 - val_accuracy: 0.1406\n",
      "Epoch 2/80\n",
      "96/96 [==============================] - 1114s 11s/step - loss: 1.8630 - accuracy: 0.2734 - val_loss: 2.1062 - val_accuracy: 0.2552\n",
      "Epoch 3/80\n",
      "96/96 [==============================] - 1037s 11s/step - loss: 1.7733 - accuracy: 0.3529 - val_loss: 2.9946 - val_accuracy: 0.2917\n",
      "Epoch 4/80\n",
      "96/96 [==============================] - 988s 10s/step - loss: 1.7091 - accuracy: 0.3542 - val_loss: 5.9470 - val_accuracy: 0.1823\n",
      "Epoch 5/80\n",
      "96/96 [==============================] - 991s 10s/step - loss: 1.5800 - accuracy: 0.4245 - val_loss: 3.6494 - val_accuracy: 0.1771\n",
      "Epoch 6/80\n",
      "96/96 [==============================] - 967s 10s/step - loss: 1.5318 - accuracy: 0.4531 - val_loss: 2.9489 - val_accuracy: 0.2500\n",
      "Epoch 7/80\n",
      "96/96 [==============================] - 1047s 11s/step - loss: 1.4463 - accuracy: 0.4792 - val_loss: 1.6246 - val_accuracy: 0.3802\n",
      "Epoch 8/80\n",
      "96/96 [==============================] - 993s 10s/step - loss: 1.3593 - accuracy: 0.5286 - val_loss: 1.7457 - val_accuracy: 0.2812\n",
      "Epoch 9/80\n",
      "96/96 [==============================] - 990s 10s/step - loss: 1.2891 - accuracy: 0.5521 - val_loss: 2.3563 - val_accuracy: 0.3542\n",
      "Epoch 10/80\n",
      "96/96 [==============================] - 1000s 10s/step - loss: 1.2306 - accuracy: 0.5625 - val_loss: 2.1063 - val_accuracy: 0.3385\n",
      "Epoch 11/80\n",
      "96/96 [==============================] - 1047s 11s/step - loss: 1.1606 - accuracy: 0.5977 - val_loss: 1.3858 - val_accuracy: 0.5052\n",
      "Epoch 12/80\n",
      "96/96 [==============================] - 1010s 11s/step - loss: 1.0600 - accuracy: 0.6523 - val_loss: 2.4116 - val_accuracy: 0.3125\n",
      "Epoch 13/80\n",
      "96/96 [==============================] - 1008s 11s/step - loss: 0.9920 - accuracy: 0.6927 - val_loss: 1.5924 - val_accuracy: 0.4427\n",
      "Epoch 14/80\n",
      "96/96 [==============================] - 989s 10s/step - loss: 0.9221 - accuracy: 0.7188 - val_loss: 1.5633 - val_accuracy: 0.4740\n",
      "Epoch 15/80\n",
      "96/96 [==============================] - 980s 10s/step - loss: 0.8818 - accuracy: 0.7240 - val_loss: 1.5394 - val_accuracy: 0.4635\n",
      "Epoch 16/80\n",
      "96/96 [==============================] - 982s 10s/step - loss: 0.8374 - accuracy: 0.7461 - val_loss: 1.3886 - val_accuracy: 0.4844\n",
      "Epoch 17/80\n",
      "96/96 [==============================] - 1043s 11s/step - loss: 0.8322 - accuracy: 0.7227 - val_loss: 1.6352 - val_accuracy: 0.4740\n",
      "Epoch 18/80\n",
      "96/96 [==============================] - 1055s 11s/step - loss: 0.7527 - accuracy: 0.7865 - val_loss: 1.3739 - val_accuracy: 0.5260\n",
      "Epoch 19/80\n",
      "96/96 [==============================] - 1072s 11s/step - loss: 0.7579 - accuracy: 0.7552 - val_loss: 1.2622 - val_accuracy: 0.5365\n",
      "Epoch 20/80\n",
      "96/96 [==============================] - 1080s 11s/step - loss: 0.7248 - accuracy: 0.7734 - val_loss: 1.4615 - val_accuracy: 0.5625\n",
      "Epoch 21/80\n",
      "96/96 [==============================] - 1024s 11s/step - loss: 0.6828 - accuracy: 0.7904 - val_loss: 1.6375 - val_accuracy: 0.5000\n",
      "Epoch 22/80\n",
      "96/96 [==============================] - 1010s 11s/step - loss: 0.6992 - accuracy: 0.7904 - val_loss: 1.3182 - val_accuracy: 0.5521\n",
      "Epoch 23/80\n",
      "96/96 [==============================] - 1087s 11s/step - loss: 0.6753 - accuracy: 0.8060 - val_loss: 1.2635 - val_accuracy: 0.5677\n",
      "Epoch 24/80\n",
      "96/96 [==============================] - 855s 9s/step - loss: 0.6836 - accuracy: 0.7930 - val_loss: 1.4636 - val_accuracy: 0.5156\n",
      "Epoch 25/80\n",
      "96/96 [==============================] - 787s 8s/step - loss: 0.6306 - accuracy: 0.8112 - val_loss: 1.3212 - val_accuracy: 0.5781\n",
      "Epoch 26/80\n",
      "96/96 [==============================] - 738s 8s/step - loss: 0.6143 - accuracy: 0.8086 - val_loss: 1.2986 - val_accuracy: 0.5521\n",
      "Epoch 27/80\n",
      "96/96 [==============================] - 727s 8s/step - loss: 0.6243 - accuracy: 0.8112 - val_loss: 1.7685 - val_accuracy: 0.4583\n",
      "Epoch 28/80\n",
      "96/96 [==============================] - 743s 8s/step - loss: 0.6400 - accuracy: 0.8034 - val_loss: 2.0029 - val_accuracy: 0.3594\n",
      "Epoch 29/80\n",
      "96/96 [==============================] - 783s 8s/step - loss: 0.5594 - accuracy: 0.8451 - val_loss: 1.2613 - val_accuracy: 0.6094\n",
      "Epoch 30/80\n",
      "96/96 [==============================] - 740s 8s/step - loss: 0.5454 - accuracy: 0.8398 - val_loss: 1.2215 - val_accuracy: 0.6094\n",
      "Epoch 31/80\n",
      "96/96 [==============================] - 755s 8s/step - loss: 0.5306 - accuracy: 0.8451 - val_loss: 3.5108 - val_accuracy: 0.2344\n",
      "Epoch 32/80\n",
      "96/96 [==============================] - 739s 8s/step - loss: 0.5195 - accuracy: 0.8464 - val_loss: 1.2688 - val_accuracy: 0.5990\n",
      "Epoch 33/80\n",
      "96/96 [==============================] - 732s 8s/step - loss: 0.5437 - accuracy: 0.8359 - val_loss: 1.8573 - val_accuracy: 0.4115\n",
      "Epoch 34/80\n",
      "96/96 [==============================] - 731s 8s/step - loss: 0.4841 - accuracy: 0.8516 - val_loss: 1.4811 - val_accuracy: 0.5052\n",
      "Epoch 35/80\n",
      "96/96 [==============================] - 743s 8s/step - loss: 0.5351 - accuracy: 0.8438 - val_loss: 1.7023 - val_accuracy: 0.4688\n",
      "Epoch 36/80\n",
      "96/96 [==============================] - 733s 8s/step - loss: 0.4808 - accuracy: 0.8724 - val_loss: 1.3745 - val_accuracy: 0.5417\n",
      "Epoch 37/80\n",
      "96/96 [==============================] - 735s 8s/step - loss: 0.4983 - accuracy: 0.8607 - val_loss: 2.3527 - val_accuracy: 0.3490\n",
      "Epoch 38/80\n",
      "96/96 [==============================] - 738s 8s/step - loss: 0.4912 - accuracy: 0.8620 - val_loss: 1.2349 - val_accuracy: 0.5573\n",
      "Epoch 39/80\n",
      "96/96 [==============================] - 737s 8s/step - loss: 0.5093 - accuracy: 0.8581 - val_loss: 1.2807 - val_accuracy: 0.5625\n",
      "Epoch 40/80\n",
      "96/96 [==============================] - 732s 8s/step - loss: 0.4503 - accuracy: 0.8737 - val_loss: 1.2229 - val_accuracy: 0.5938\n",
      "Epoch 41/80\n",
      "96/96 [==============================] - 732s 8s/step - loss: 0.4483 - accuracy: 0.8737 - val_loss: 1.2039 - val_accuracy: 0.5938\n",
      "Epoch 42/80\n",
      "96/96 [==============================] - 736s 8s/step - loss: 0.4344 - accuracy: 0.8906 - val_loss: 1.4562 - val_accuracy: 0.5208\n",
      "Epoch 43/80\n",
      "96/96 [==============================] - 743s 8s/step - loss: 0.4405 - accuracy: 0.8919 - val_loss: 1.2342 - val_accuracy: 0.5885\n",
      "Epoch 44/80\n",
      "96/96 [==============================] - 750s 8s/step - loss: 0.4475 - accuracy: 0.8763 - val_loss: 1.2359 - val_accuracy: 0.5938\n",
      "9/9 [==============================] - 17s 1s/step - loss: 1.3060 - accuracy: 0.5486\n",
      "Epoch 1/80\n",
      "96/96 [==============================] - 842s 8s/step - loss: 2.1166 - accuracy: 0.2122 - val_loss: 5.1950 - val_accuracy: 0.2083\n",
      "Epoch 2/80\n",
      "96/96 [==============================] - 798s 8s/step - loss: 1.9566 - accuracy: 0.2891 - val_loss: 5.3270 - val_accuracy: 0.1510\n",
      "Epoch 3/80\n",
      "96/96 [==============================] - 791s 8s/step - loss: 1.7754 - accuracy: 0.3333 - val_loss: 2.5574 - val_accuracy: 0.2344\n",
      "Epoch 4/80\n",
      "80/96 [========================>.....] - ETA: 2:03 - loss: 1.6700 - accuracy: 0.3734"
     ]
    }
   ],
   "source": [
    "VALIDATION_ACCURACY_SPEECH = []\n",
    "VALIDATION_LOSS_SPEECH= []\n",
    "\n",
    "save_dir = os.path.abspath(DIR)+'/ravdess_60m40f_audio_model/'\n",
    "fold_var = 1\n",
    "\n",
    "for train_idx, val_idx in kfold.split(X_train_aud_60m_40f, y_train_60m_40f):\n",
    "  # with tpu_strategy.scope():\n",
    "  model=model_alexnet() \n",
    "  model.compile(loss='sparse_categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
    "  early_stopping_callback = EarlyStopping(monitor = 'val_accuracy', patience = 15, restore_best_weights = True)\n",
    "  checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(save_dir+get_model_name(fold_var), \n",
    "        monitor='val_accuracy', \n",
    "        save_best_only=True, mode='max')\n",
    "\n",
    "  LRCN_model_training_history = model.fit(        x = X_train_aud_60m_40f[train_idx],\n",
    "                                                  y = y_train_60m_40f[train_idx],\n",
    "                                                  validation_data=(X_train_aud_60m_40f[val_idx], y_train_60m_40f[val_idx]),\n",
    "                                                  epochs = 80,\n",
    "                                                  batch_size = 8,\n",
    "                                                  shuffle = True,\n",
    "                                                  callbacks = [checkpoint_cb,early_stopping_callback])\n",
    "\n",
    "  model.load_weights(save_dir+\"model_\"+str(fold_var)+\".h5\")\n",
    "\t\n",
    "  results = model.evaluate(X_test_aud, y_test)\n",
    "  results = dict(zip(model.metrics_names,results))\n",
    "\t\n",
    "  VALIDATION_ACCURACY_SPEECH.append(results['accuracy'])\n",
    "  VALIDATION_LOSS_SPEECH.append(results['loss'])\n",
    "\t\n",
    "  tf.keras.backend.clear_session()\n",
    "\t\n",
    "  fold_var += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e6dc190e-c616-4c6c-a13f-7ef8ffee4211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 9s 1s/step - loss: 1.1040 - accuracy: 0.6343\n",
      "Test set evaluation: {'loss': 1.1039944887161255, 'accuracy': 0.6342592835426331}\n",
      "4/4 [==============================] - 5s 2s/step\n",
      "4/4 [==============================] - 2s 570ms/step\n",
      "Gender bias analysis: {'female': {'accuracy': 0.6448598130841121, 'precision': 0.6562150961643238, 'recall': 0.6327380952380952, 'f1': 0.6217810342810343, 'tpr': array([0.42857143, 0.78571429, 0.78571429, 0.28571429, 0.78571429,\n",
      "       0.4       , 0.73333333, 0.85714286]), 'fpr': array([0.02      , 0.05376344, 0.12903226, 0.02150538, 0.03225806,\n",
      "       0.0326087 , 0.04347826, 0.07526882]), 'fnr': array([0.57142857, 0.21428571, 0.21428571, 0.71428571, 0.21428571,\n",
      "       0.6       , 0.26666667, 0.14285714]), 'precision_value': array([0.6       , 0.6875    , 0.47826087, 0.66666667, 0.78571429,\n",
      "       0.66666667, 0.73333333, 0.63157895]), 'positive_rate': 3.7757009345794392}, 'male': {'accuracy': 0.6238532110091743, 'precision': 0.5869543200674099, 'recall': 0.5803571428571429, 'f1': 0.5603783273968284, 'tpr': array([0.        , 0.93333333, 0.71428571, 0.28571429, 0.73333333,\n",
      "       0.6       , 0.64285714, 0.73333333]), 'fpr': array([0.00980392, 0.15957447, 0.06315789, 0.03157895, 0.05319149,\n",
      "       0.        , 0.03157895, 0.08510638]), 'fnr': array([1.        , 0.06666667, 0.28571429, 0.71428571, 0.26666667,\n",
      "       0.4       , 0.35714286, 0.26666667]), 'precision_value': array([0.        , 0.48275862, 0.625     , 0.57142857, 0.6875    ,\n",
      "       1.        , 0.75      , 0.57894737]), 'positive_rate': 3.63302752293578}}\n",
      "Disparate Impact Ratio: 0.9622127350349714\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "save_dir = os.path.abspath(DIR)+'/saved_model_feature_extraction_audio/'\n",
    "final_model = model_alexnet()\n",
    "final_model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=[\"accuracy\"])\n",
    "final_model.load_weights(save_dir + \"model_1.h5\")  # Adjust to load the best model if necessary\n",
    "\n",
    "test_results = final_model.evaluate(X_test_aud, y_test_aud)\n",
    "test_results = dict(zip(final_model.metrics_names, test_results))\n",
    "\n",
    "print(\"Test set evaluation:\", test_results)\n",
    "\n",
    "# Gender bias analysis\n",
    "metrics_by_gender = {}\n",
    "for gender in np.unique(gender_test):\n",
    "    gender_indices = np.where(gender_test == gender)\n",
    "    X_gender_test = X_test[gender_indices]\n",
    "    y_gender_test = y_test[gender_indices]\n",
    "    y_pred = np.argmax(final_model.predict(X_gender_test), axis=1)\n",
    "\n",
    "    accuracy = np.mean(y_pred == y_gender_test)\n",
    "    precision = precision_score(y_gender_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_gender_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_gender_test, y_pred, average='macro')\n",
    "\n",
    "    cm = confusion_matrix(y_gender_test, y_pred)\n",
    "    tn = np.sum(cm) - (np.sum(cm, axis=0) + np.sum(cm, axis=1) - np.diag(cm))\n",
    "    fp = np.sum(cm, axis=0) - np.diag(cm)\n",
    "    fn = np.sum(cm, axis=1) - np.diag(cm)\n",
    "    tp = np.diag(cm)\n",
    "    tpr = tp / (tp + fn)  # True Positive Rate\n",
    "    fpr = fp / (fp + tn)  # False Positive Rate\n",
    "    fnr = fn / (fn + tp)  # False Negative Rate\n",
    "    precision_value = tp / (tp + fp)\n",
    "\n",
    "    metrics_by_gender[gender] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'tpr': tpr,\n",
    "        'fpr': fpr,\n",
    "        'fnr': fnr,\n",
    "        'precision_value': precision_value,\n",
    "        'positive_rate': np.mean(y_pred)\n",
    "    }\n",
    "\n",
    "#Additional fairness metrics\n",
    "positive_rates = [metrics_by_gender[gender]['positive_rate'] for gender in metrics_by_gender]\n",
    "disparate_impact_ratio = min(positive_rates) / max(positive_rates)\n",
    "\n",
    "print(\"Gender bias analysis:\", metrics_by_gender)\n",
    "print(\"Disparate Impact Ratio:\", disparate_impact_ratio)\n",
    "\n",
    "for gender in metrics_by_gender:\n",
    "    metrics_by_gender[gender]['demographic_parity'] = metrics_by_gender[gender]['positive_rate']\n",
    "    metrics_by_gender[gender]['equalized_odds'] = (metrics_by_gender[gender]['fpr'], metrics_by_gender[gender]['fnr'])\n",
    "    metrics_by_gender[gender]['equal_opportunity'] = metrics_by_gender[gender]['tpr']\n",
    "    metrics_by_gender[gender]['predictive_parity'] = metrics_by_gender[gender]['precision_value']\n",
    "\n",
    "# avg_fpr_values = [np.mean(fpr) for fpr in fpr_values]\n",
    "# avg_fnr_values = [np.mean(fnr) for fnr in fnr_values]\n",
    "\n",
    "# false_positive_equality = max(avg_fpr_values) - min(avg_fpr_values)\n",
    "# false_negative_equality = max(avg_fnr_values) - min(avg_fnr_values)\n",
    "\n",
    "# print(\"False Positive Equality:\", false_positive_equality)\n",
    "# print(\"False Negative Equality:\", false_negative_equality) \n",
    "\n",
    "\n",
    "# for gender in metrics_by_gender:\n",
    "#     print(f\"Gender: {gender}\")\n",
    "#     print(f\"  Demographic Parity: {metrics_by_gender[gender]['demographic_parity']}\")\n",
    "#     print(f\"  Equalized Odds (FPR, FNR): {metrics_by_gender[gender]['equalized_odds']}\")\n",
    "#     print(f\"  Equal Opportunity (TPR): {metrics_by_gender[gender]['equal_opportunity']}\")\n",
    "#     print(f\"  Predictive Parity: {metrics_by_gender[gender]['predictive_parity']}\")\n",
    "\n",
    "\n",
    "data = {\n",
    "    'Metric': [\n",
    "        'Accuracy', 'Precision', 'Recall', 'F1 Score', 'True Positive Rate', 'False Positive Rate',\n",
    "        'False Negative Rate', 'Predictive Parity', 'Positive Rate', 'Demographic Parity',\n",
    "        'Equalized Odds (FPR, FNR)', 'Equal Opportunity (TPR)'\n",
    "    ],\n",
    "    'Male': [\n",
    "        metrics_by_gender['male']['accuracy'], metrics_by_gender['male']['precision'],\n",
    "        metrics_by_gender['male']['recall'], metrics_by_gender['male']['f1'],\n",
    "        metrics_by_gender['male']['tpr'], metrics_by_gender['male']['fpr'],\n",
    "        metrics_by_gender['male']['fnr'], metrics_by_gender['male']['precision_value'],\n",
    "        metrics_by_gender['male']['positive_rate'], metrics_by_gender['male']['demographic_parity'],\n",
    "        metrics_by_gender['male']['equalized_odds'], metrics_by_gender['male']['equal_opportunity']\n",
    "    ],\n",
    "    'Female': [\n",
    "        metrics_by_gender['female']['accuracy'], metrics_by_gender['female']['precision'],\n",
    "        metrics_by_gender['female']['recall'], metrics_by_gender['female']['f1'],\n",
    "        metrics_by_gender['female']['tpr'], metrics_by_gender['female']['fpr'],\n",
    "        metrics_by_gender['female']['fnr'], metrics_by_gender['female']['precision_value'],\n",
    "        metrics_by_gender['female']['positive_rate'], metrics_by_gender['female']['demographic_parity'],\n",
    "        metrics_by_gender['female']['equalized_odds'], metrics_by_gender['female']['equal_opportunity']\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create DataFrame and display\n",
    "df = pd.DataFrame(data)\n",
    "csv_file_path = 'audio_metrics_results_7th_Jul.csv'\n",
    "df.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e83836c2-41aa-4688-9bb9-ba1ce16a4a5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values: ['female' 'male']\n",
      "Counts: [107 109]\n"
     ]
    }
   ],
   "source": [
    "unique_values, counts = np.unique(gender_test, return_counts=True)\n",
    "\n",
    "# Displaying the results\n",
    "print(\"Unique values:\", unique_values)\n",
    "print(\"Counts:\", counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b35b41-7e79-4626-87ca-930e0b6ccd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multi-model - Late fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5292a368-80cd-4ca5-a83c-d97e582fbf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_fold = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "29cbe708-fc44-4972-b929-a88b992dd686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "save_dir = os.path.abspath(DIR)+'/saved_model_feature_extraction_audio/'\n",
    "model_audio = model_alexnet()\n",
    "model_audio.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=[\"accuracy\"])\n",
    "model_audio.load_weights(save_dir +\"model_\"+str(indice_fold)+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d1360d2a-3844-44d6-b856-0a8b927b9e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Localization Network with input shape: (None, 48, 48, 1)\n",
      "Building Bilinear Interpolation Layer with input shape: ((None, 48, 48, 1), (None, 2, 3))\n"
     ]
    }
   ],
   "source": [
    "save_dir = os.path.abspath(DIR)+'/saved_models_lrcn_stn/'\n",
    "\n",
    "model_video = create__LRCN_with_STN()\n",
    "model_video.compile(loss='sparese_categorical_crossentropy', optimizer='Adam', metrics=[\"accuracy\"])\n",
    "model_video.load_weights(save_dir+\"model_\"+str(indice_fold)+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2344d1a6-541f-4e49-aeef-029501d8508b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)       [(None, 20, 48, 48, 1)]      0         []                            \n",
      "                                                                                                  \n",
      " time_distributed_33 (TimeD  (None, 20, 2, 3)             43086     ['input_13[0][0]']            \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " time_distributed_34 (TimeD  (None, 20, 48, 48, 1)        0         ['input_13[0][0]',            \n",
      " istributed)                                                         'time_distributed_33[0][0]'] \n",
      "                                                                                                  \n",
      " time_distributed_35 (TimeD  (None, 20, 1024)             1478656   ['time_distributed_34[0][0]'] \n",
      " istributed)                                                                                      \n",
      "                                                                                                  \n",
      " bidirectional_11 (Bidirect  (None, 400)                  1960000   ['time_distributed_35[0][0]'] \n",
      " ional)                                                                                           \n",
      "                                                                                                  \n",
      " dense_47 (Dense)            (None, 8)                    3208      ['bidirectional_11[0][0]']    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3484950 (13.29 MB)\n",
      "Trainable params: 2006294 (7.65 MB)\n",
      "Non-trainable params: 1478656 (5.64 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_video.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7f5792c6-21b7-486a-9361-fc2b0f0de9eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Metric  \\\n",
      "0                    Accuracy   \n",
      "1                   Precision   \n",
      "2                      Recall   \n",
      "3                    F1 Score   \n",
      "4          True Positive Rate   \n",
      "5         False Positive Rate   \n",
      "6         False Negative Rate   \n",
      "7           Predictive Parity   \n",
      "8               Positive Rate   \n",
      "9          Demographic Parity   \n",
      "10  Equalized Odds (FPR, FNR)   \n",
      "11    Equal Opportunity (TPR)   \n",
      "\n",
      "                                                 Male  \\\n",
      "0                                             0.53211   \n",
      "1                                            0.571701   \n",
      "2                                            0.514286   \n",
      "3                                            0.519221   \n",
      "4   [0.2857142857142857, 0.6666666666666666, 0.4, ...   \n",
      "5   [0.0392156862745098, 0.0851063829787234, 0.095...   \n",
      "6   [0.7142857142857143, 0.3333333333333333, 0.6, ...   \n",
      "7   [0.3333333333333333, 0.5555555555555556, 0.4, ...   \n",
      "8                                            3.486239   \n",
      "9                                            3.486239   \n",
      "10  ([0.0392156862745098, 0.0851063829787234, 0.09...   \n",
      "11  [0.2857142857142857, 0.6666666666666666, 0.4, ...   \n",
      "\n",
      "                                               Female  \n",
      "0                                            0.635514  \n",
      "1                                            0.656052  \n",
      "2                                            0.632738  \n",
      "3                                            0.631259  \n",
      "4   [0.5714285714285714, 0.8571428571428571, 0.785...  \n",
      "5   [0.03, 0.03225806451612903, 0.0967741935483871...  \n",
      "6   [0.42857142857142855, 0.14285714285714285, 0.2...  \n",
      "7   [0.5714285714285714, 0.8, 0.55, 0.571428571428...  \n",
      "8                                            3.392523  \n",
      "9                                            3.392523  \n",
      "10  ([0.03, 0.03225806451612903, 0.096774193548387...  \n",
      "11  [0.5714285714285714, 0.8571428571428571, 0.785...  \n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9d7c1d4b-d165-43d6-b436-31502d7e0cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "seed=7\n",
    "kfold=StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "indices=[]\n",
    "for train_index, test_index in kfold.split(df, labels):\n",
    "    indices.append([train_index, test_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "529d1bf0-364e-491b-881e-943d24b447da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 7 7 7]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3bcef7b4-5c00-4681-8b83-23070cce18ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_video_model=Model(inputs=model_video.input, outputs=model_video.get_layer('bidirectional_11').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7a8cb9d9-14ae-46b6-8872-bca567f35ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 10s 142ms/step\n"
     ]
    }
   ],
   "source": [
    "features_video=features_video_model.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1491efbe-3bdb-46de-b245-e9c419e47080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  2.6046636e-37 ...  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00 -3.3500925e-08  2.1837667e-33 ...  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00]\n",
      " ...\n",
      " [ 0.0000000e+00 -0.0000000e+00  7.6159418e-01 ...  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  7.1184909e-01 ...  0.0000000e+00\n",
      "  -0.0000000e+00 -0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  7.6538086e-01 ...  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(features_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "df1047a0-e1b5-42ff-9a9e-69e9bb8a0d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440, 400)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "190fad69-869e-42ef-8591-51f827218d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_audio_model=Model(inputs=model_audio.input, outputs=model_audio.get_layer('dropout_7').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "04a85e9c-e4aa-43cf-bca6-aa5ba8a85c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 60s 1s/step\n"
     ]
    }
   ],
   "source": [
    "features_audio=features_audio_model.predict(df_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2291cfa8-a51b-4d30-8326-2d5dfdf91908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440, 1000)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c737417e-9aa2-4ed7-939f-70a4739a82f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.concatenate((features_video,features_audio),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8cb56256-3836-4453-bfb6-679eaaaadfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440, 1400)\n",
      "[[ 0.0000000e+00  0.0000000e+00  0.0000000e+00 ...  0.0000000e+00\n",
      "   0.0000000e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  2.6046636e-37 ...  0.0000000e+00\n",
      "   1.4337306e+00  0.0000000e+00]\n",
      " [ 0.0000000e+00 -3.3500925e-08  2.1837667e-33 ...  0.0000000e+00\n",
      "   3.8423204e-01  0.0000000e+00]\n",
      " ...\n",
      " [ 0.0000000e+00 -0.0000000e+00  7.6159418e-01 ...  2.1384232e+00\n",
      "   0.0000000e+00  3.3266492e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  7.1184909e-01 ...  2.3069346e+00\n",
      "   0.0000000e+00  2.3839350e+00]\n",
      " [ 0.0000000e+00  0.0000000e+00  7.6538086e-01 ...  8.3070189e-01\n",
      "   2.4034429e-01  1.1089498e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8932d6c7-4a11-440e-9977-62829ddbead0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optuna\n",
      "  Downloading optuna-3.6.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.13.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in ./miniconda3/envs/tf/lib/python3.9/site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./miniconda3/envs/tf/lib/python3.9/site-packages (from optuna) (24.0)\n",
      "Collecting sqlalchemy>=1.3.0 (from optuna)\n",
      "  Downloading SQLAlchemy-2.0.30-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: tqdm in ./miniconda3/envs/tf/lib/python3.9/site-packages (from optuna) (4.66.4)\n",
      "Requirement already satisfied: PyYAML in ./miniconda3/envs/tf/lib/python3.9/site-packages (from optuna) (6.0.1)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in ./miniconda3/envs/tf/lib/python3.9/site-packages (from alembic>=1.5.0->optuna) (4.11.0)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy>=1.3.0->optuna)\n",
      "  Downloading greenlet-3.0.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in ./miniconda3/envs/tf/lib/python3.9/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n",
      "Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.30-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
      "Downloading greenlet-3.0.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (660 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m660.8/660.8 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: Mako, greenlet, colorlog, sqlalchemy, alembic, optuna\n",
      "Successfully installed Mako-1.3.5 alembic-1.13.1 colorlog-6.8.2 greenlet-3.0.3 optuna-3.6.1 sqlalchemy-2.0.30\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "03de993c-3029-46e4-a180-e7f0d1001f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "indice_train,indice_test=indices[indice_fold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "402c4d15-52b0-4923-b00d-29ec2953f34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (1008, 1400)\n",
      "Validation set shape: (216, 1400)\n",
      "Test set shape: (216, 1400)\n",
      "Label Train set shape: (1008,)\n",
      "Label Validation set shape: (216,)\n",
      "Label Test set shape: (216,)\n",
      "GenderTrain set shape: ['female' 'male' 'female' ... 'female' 'male' 'male']\n",
      "Gender Validation set shape: (216,)\n",
      "Gender Test set shape: (216,)\n"
     ]
    }
   ],
   "source": [
    "combined_labels = [(e, g) for e, g in zip(labels, genders)]\n",
    "X_train, X_temp, y_train, y_temp, gender_train, gender_temp = train_test_split(\n",
    "    data, labels, genders, test_size=0.3, stratify=combined_labels, random_state=42\n",
    ")\n",
    "\n",
    "combined_temp_labels = [(e, g) for e, g in zip(y_temp, gender_temp)]\n",
    "\n",
    "# Split the temporary set into validation and test sets\n",
    "X_val, X_test, y_val, y_test, gender_val, gender_test = train_test_split(\n",
    "    X_temp, y_temp, gender_temp, test_size=0.5, stratify=combined_temp_labels, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train set shape:\", X_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape)\n",
    "print(\"Test set shape:\", X_test.shape)\n",
    "\n",
    "print(\"Label Train set shape:\", y_train.shape)\n",
    "print(\"Label Validation set shape:\", y_val.shape)\n",
    "print(\"Label Test set shape:\", y_test.shape)\n",
    "\n",
    "print(\"GenderTrain set shape:\", gender_train)\n",
    "print(\"Gender Validation set shape:\", gender_val.shape)\n",
    "print(\"Gender Test set shape:\", gender_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d1b1f2e4-5885-4f64-a8c3-8998cfb70658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train = data[indice_train],labels[indice_train]\n",
    "# X_test, y_test = data[indice_test],labels[indice_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f5bd598b-25cb-4561-b22d-adcdc85ccc27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216, 1400)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2fbe9e3e-64b4-48b6-af30-8338fbdb8352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import linear_model\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b762004a-04f0-4687-a7ea-b3ce9b340d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "X_val = sc.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8321f475-ad31-43cf-8e01-2c0ce39b904b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "lda = PCA(n_components=800)\n",
    "X_train = lda.fit_transform(X_train)\n",
    "X_test = lda.transform(X_test)\n",
    "X_val = lda.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0db1d288-f11b-4f9d-9640-7ac24eb4ce17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1008, 1400)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e2972915-bcf5-4d46-8680-df82c93f1dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    logreg_c = trial.suggest_float(\"logreg_c\", 1e-10, 1e10, log=True)\n",
    "    X_combined = np.vstack((X_train, X_val))\n",
    "    y_combined = np.hstack((y_train, y_val))\n",
    "    \n",
    "    # Initialize the logistic regression model with the suggested C value\n",
    "    clf = linear_model.LogisticRegression(C=logreg_c)\n",
    "    \n",
    "    # Fit the model on the combined training and validation data\n",
    "    clf.fit(X_combined, y_combined)\n",
    "    preds = clf.predict(X_test)\n",
    "    score = accuracy_score(y_test, preds)\n",
    "    gc.collect()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "671b64a3-8f99-4946-a53c-33a2ddf50b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-15 20:51:45,562] A new study created in memory with name: tps-feb-2022\n",
      "[I 2024-06-15 20:52:02,496] Trial 0 finished with value: 0.8564814814814815 and parameters: {'logreg_c': 3.582137263067999}. Best is trial 0 with value: 0.8564814814814815.\n",
      "[I 2024-06-15 20:52:17,784] Trial 1 finished with value: 0.8657407407407407 and parameters: {'logreg_c': 2671763.636383394}. Best is trial 1 with value: 0.8657407407407407.\n",
      "[I 2024-06-15 20:52:48,265] Trial 2 finished with value: 0.8611111111111112 and parameters: {'logreg_c': 0.003013327616642366}. Best is trial 1 with value: 0.8657407407407407.\n",
      "[I 2024-06-15 20:53:12,076] Trial 3 finished with value: 0.8611111111111112 and parameters: {'logreg_c': 0.30502941590720467}. Best is trial 1 with value: 0.8657407407407407.\n",
      "[I 2024-06-15 20:54:20,480] Trial 4 finished with value: 0.8564814814814815 and parameters: {'logreg_c': 3.223338847539848e-07}. Best is trial 1 with value: 0.8657407407407407.\n",
      "[I 2024-06-15 20:54:36,884] Trial 5 finished with value: 0.8842592592592593 and parameters: {'logreg_c': 4259.124759916206}. Best is trial 5 with value: 0.8842592592592593.\n",
      "[I 2024-06-15 20:55:02,989] Trial 6 finished with value: 0.8611111111111112 and parameters: {'logreg_c': 5.261035954568146e-08}. Best is trial 5 with value: 0.8842592592592593.\n",
      "[I 2024-06-15 20:55:22,589] Trial 7 finished with value: 0.8564814814814815 and parameters: {'logreg_c': 4.609167906668523e-10}. Best is trial 5 with value: 0.8842592592592593.\n",
      "[I 2024-06-15 20:55:38,291] Trial 8 finished with value: 0.8564814814814815 and parameters: {'logreg_c': 46427412.36126765}. Best is trial 5 with value: 0.8842592592592593.\n",
      "[I 2024-06-15 20:55:52,518] Trial 9 finished with value: 0.8564814814814815 and parameters: {'logreg_c': 5.884348301529303}. Best is trial 5 with value: 0.8842592592592593.\n",
      "[I 2024-06-15 20:56:06,629] Trial 10 finished with value: 0.8611111111111112 and parameters: {'logreg_c': 15841.756079841145}. Best is trial 5 with value: 0.8842592592592593.\n",
      "[I 2024-06-15 20:56:21,937] Trial 11 finished with value: 0.8564814814814815 and parameters: {'logreg_c': 1690379235.5619273}. Best is trial 5 with value: 0.8842592592592593.\n",
      "[I 2024-06-15 20:56:38,130] Trial 12 finished with value: 0.8564814814814815 and parameters: {'logreg_c': 131220.18865066237}. Best is trial 5 with value: 0.8842592592592593.\n",
      "[I 2024-06-15 20:56:54,182] Trial 13 finished with value: 0.8564814814814815 and parameters: {'logreg_c': 43239.36246315595}. Best is trial 5 with value: 0.8842592592592593.\n",
      "[I 2024-06-15 20:57:09,099] Trial 14 finished with value: 0.8611111111111112 and parameters: {'logreg_c': 4633393.715382505}. Best is trial 5 with value: 0.8842592592592593.\n",
      "[I 2024-06-15 20:57:34,490] Trial 15 finished with value: 0.8657407407407407 and parameters: {'logreg_c': 254.07778030788725}. Best is trial 5 with value: 0.8842592592592593.\n",
      "[I 2024-06-15 20:57:49,856] Trial 16 finished with value: 0.8564814814814815 and parameters: {'logreg_c': 6204606511.0534}. Best is trial 5 with value: 0.8842592592592593.\n",
      "[I 2024-06-15 20:58:15,714] Trial 17 finished with value: 0.8564814814814815 and parameters: {'logreg_c': 0.0005201195616119776}. Best is trial 5 with value: 0.8842592592592593.\n",
      "[I 2024-06-15 20:58:31,263] Trial 18 finished with value: 0.8564814814814815 and parameters: {'logreg_c': 1017.6308987583706}. Best is trial 5 with value: 0.8842592592592593.\n",
      "[I 2024-06-15 20:58:46,141] Trial 19 finished with value: 0.8611111111111112 and parameters: {'logreg_c': 4948327.524907186}. Best is trial 5 with value: 0.8842592592592593.\n",
      "[I 2024-06-15 20:59:01,333] Trial 20 finished with value: 0.9120370370370371 and parameters: {'logreg_c': 277.9763062288022}. Best is trial 20 with value: 0.9120370370370371.\n",
      "[I 2024-06-15 20:59:24,425] Trial 21 finished with value: 0.8888888888888888 and parameters: {'logreg_c': 131.7476474054726}. Best is trial 20 with value: 0.9120370370370371.\n",
      "[I 2024-06-15 21:00:13,507] Trial 22 finished with value: 0.8009259259259259 and parameters: {'logreg_c': 0.0468114354646663}. Best is trial 20 with value: 0.9120370370370371.\n",
      "[I 2024-06-15 21:00:28,992] Trial 23 finished with value: 0.8611111111111112 and parameters: {'logreg_c': 127.53067095302887}. Best is trial 20 with value: 0.9120370370370371.\n",
      "[I 2024-06-15 21:01:12,975] Trial 24 finished with value: 0.8657407407407407 and parameters: {'logreg_c': 41.255323619779396}. Best is trial 20 with value: 0.9120370370370371.\n",
      "[I 2024-06-15 21:01:29,549] Trial 25 finished with value: 0.8611111111111112 and parameters: {'logreg_c': 2903.8987802454503}. Best is trial 20 with value: 0.9120370370370371.\n",
      "[I 2024-06-15 21:01:43,385] Trial 26 finished with value: 0.8657407407407407 and parameters: {'logreg_c': 2.8534290249554725e-05}. Best is trial 20 with value: 0.9120370370370371.\n",
      "[I 2024-06-15 21:02:23,647] Trial 27 finished with value: 0.8611111111111112 and parameters: {'logreg_c': 0.055940156207179306}. Best is trial 20 with value: 0.9120370370370371.\n",
      "[I 2024-06-15 21:02:39,077] Trial 28 finished with value: 0.8564814814814815 and parameters: {'logreg_c': 282320.77456622623}. Best is trial 20 with value: 0.9120370370370371.\n",
      "[I 2024-06-15 21:02:53,904] Trial 29 finished with value: 0.8564814814814815 and parameters: {'logreg_c': 6.344492836835024}. Best is trial 20 with value: 0.9120370370370371.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "study = optuna.create_study(study_name=\"tps-feb-2022\", direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "29ca8bcb-6f97-467c-8e2b-b83ef25b6f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best accuracy:  0.9120370370370371\n",
      "  Value: 0.9120370370370371\n",
      "  Params: \n",
      "    logreg_c: 277.9763062288022\n"
     ]
    }
   ],
   "source": [
    "trial = study.best_trial\n",
    "print(\"  Best accuracy: \", study.best_value)\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "dfabe1b9-0fdd-4efa-b1d1-9afb3ec4f94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=277.9763062288022)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=277.9763062288022)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=277.9763062288022)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "best_params = study.best_params\n",
    "logreg_c = best_params[\"logreg_c\"]\n",
    "X_combined = np.vstack((X_train, X_val))\n",
    "y_combined = np.hstack((y_train, y_val))\n",
    "best_clf = LogisticRegression(C=logreg_c)\n",
    "best_clf.fit(X_combined, y_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0d71396b-f4dc-4b02-aa23-675dfd83ba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_preds = best_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4a4b5a06-9118-4445-a092-aa703844a013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set evaluation: {'accuracy': 0.9120370370370371, 'precision': 0.9084532076719576, 'recall': 0.9083743842364532, 'f1_score': 0.9079476449782163}\n"
     ]
    }
   ],
   "source": [
    "overall_metrics = {\n",
    "    'accuracy': accuracy_score(y_test, best_preds),\n",
    "    'precision': precision_score(y_test, best_preds, average='macro'),\n",
    "    'recall': recall_score(y_test, best_preds, average='macro'),\n",
    "    'f1_score': f1_score(y_test, best_preds, average='macro')\n",
    "}\n",
    "\n",
    "print(\"Test set evaluation:\", overall_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a05d168e-2d71-4738-9e02-2becf8f660ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender bias analysis: {'female': {'accuracy': 0.8878504672897196, 'precision': 0.8894551526904468, 'recall': 0.8779761904761905, 'f1': 0.8795235128469973, 'tpr': array([0.71428571, 1.        , 1.        , 0.86666667, 0.8       ,\n",
      "       0.71428571, 1.        , 0.92857143]), 'fpr': array([0.01      , 0.        , 0.03225806, 0.04347826, 0.01086957,\n",
      "       0.01075269, 0.01075269, 0.01075269]), 'fnr': array([0.28571429, 0.        , 0.        , 0.13333333, 0.2       ,\n",
      "       0.28571429, 0.        , 0.07142857]), 'precision_value': array([0.83333333, 1.        , 0.82352941, 0.76470588, 0.92307692,\n",
      "       0.90909091, 0.93333333, 0.92857143]), 'positive_rate': 3.682242990654206}, 'male': {'accuracy': 0.9357798165137615, 'precision': 0.9348679812834224, 'recall': 0.9380952380952381, 'f1': 0.9325628458258464, 'tpr': array([1.        , 1.        , 1.        , 0.71428571, 1.        ,\n",
      "       1.        , 0.85714286, 0.93333333]), 'fpr': array([0.00980392, 0.0106383 , 0.        , 0.01052632, 0.0212766 ,\n",
      "       0.02105263, 0.        , 0.        ]), 'fnr': array([0.        , 0.        , 0.        , 0.28571429, 0.        ,\n",
      "       0.        , 0.14285714, 0.06666667]), 'precision_value': array([0.875     , 0.9375    , 1.        , 0.90909091, 0.88235294,\n",
      "       0.875     , 1.        , 1.        ]), 'positive_rate': 3.6422018348623855}}\n",
      "Disparate Impact Ratio: 0.9891258790108508\n",
      "False Positive Equality: 0.006945774070643101\n",
      "False Negative Equality: 0.06011904761904762\n"
     ]
    }
   ],
   "source": [
    "metrics_by_gender = {}\n",
    "for gender in np.unique(gender_test):\n",
    "    gender_indices = np.where(gender_test == gender)\n",
    "    X_gender_test = X_test[gender_indices]\n",
    "    y_gender_test = y_test[gender_indices]\n",
    "    y_pred = best_clf.predict(X_gender_test)\n",
    "\n",
    "    accuracy = np.mean(y_pred == y_gender_test)\n",
    "    precision = precision_score(y_gender_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_gender_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_gender_test, y_pred, average='macro')\n",
    "\n",
    "    cm = confusion_matrix(y_gender_test, y_pred)\n",
    "    tn = np.sum(cm) - (np.sum(cm, axis=0) + np.sum(cm, axis=1) - np.diag(cm))\n",
    "    fp = np.sum(cm, axis=0) - np.diag(cm)\n",
    "    fn = np.sum(cm, axis=1) - np.diag(cm)\n",
    "    tp = np.diag(cm)\n",
    "    tpr = tp / (tp + fn)  # True Positive Rate\n",
    "    fpr = fp / (fp + tn)  # False Positive Rate\n",
    "    fnr = fn / (fn + tp)  # False Negative Rate\n",
    "    precision_value = tp / (tp + fp)\n",
    "\n",
    "    metrics_by_gender[gender] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'tpr': tpr,\n",
    "        'fpr': fpr,\n",
    "        'fnr': fnr,\n",
    "        'precision_value': precision_value,\n",
    "        'positive_rate': np.mean(y_pred)\n",
    "    }\n",
    "\n",
    "# Additional fairness metrics\n",
    "positive_rates = [metrics_by_gender[gender]['positive_rate'] for gender in metrics_by_gender]\n",
    "disparate_impact_ratio = min(positive_rates) / max(positive_rates)\n",
    "\n",
    "print(\"Gender bias analysis:\", metrics_by_gender)\n",
    "print(\"Disparate Impact Ratio:\", disparate_impact_ratio)\n",
    "\n",
    "for gender in metrics_by_gender:\n",
    "    metrics_by_gender[gender]['demographic_parity'] = metrics_by_gender[gender]['positive_rate']\n",
    "    metrics_by_gender[gender]['equalized_odds'] = (metrics_by_gender[gender]['fpr'], metrics_by_gender[gender]['fnr'])\n",
    "    metrics_by_gender[gender]['equal_opportunity'] = metrics_by_gender[gender]['tpr']\n",
    "    metrics_by_gender[gender]['predictive_parity'] = metrics_by_gender[gender]['precision_value']\n",
    "\n",
    "fpr_values = [metrics_by_gender[gender]['fpr'] for gender in metrics_by_gender]\n",
    "fnr_values = [metrics_by_gender[gender]['fnr'] for gender in metrics_by_gender]\n",
    "\n",
    "avg_fpr_values = [np.mean(fpr) for fpr in fpr_values]\n",
    "avg_fnr_values = [np.mean(fnr) for fnr in fnr_values]\n",
    "\n",
    "false_positive_equality = max(avg_fpr_values) - min(avg_fpr_values)\n",
    "false_negative_equality = max(avg_fnr_values) - min(avg_fnr_values)\n",
    "\n",
    "print(\"False Positive Equality:\", false_positive_equality)\n",
    "print(\"False Negative Equality:\", false_negative_equality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "310aa80d-dbd1-4319-8c02-6172df9f2295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Metric  \\\n",
      "0                    Accuracy   \n",
      "1                   Precision   \n",
      "2                      Recall   \n",
      "3                    F1 Score   \n",
      "4          True Positive Rate   \n",
      "5         False Positive Rate   \n",
      "6         False Negative Rate   \n",
      "7           Predictive Parity   \n",
      "8               Positive Rate   \n",
      "9          Demographic Parity   \n",
      "10  Equalized Odds (FPR, FNR)   \n",
      "11    Equal Opportunity (TPR)   \n",
      "\n",
      "                                                 Male  \\\n",
      "0                                             0.93578   \n",
      "1                                            0.934868   \n",
      "2                                            0.938095   \n",
      "3                                            0.932563   \n",
      "4   [1.0, 1.0, 1.0, 0.7142857142857143, 1.0, 1.0, ...   \n",
      "5   [0.00980392156862745, 0.010638297872340425, 0....   \n",
      "6   [0.0, 0.0, 0.0, 0.2857142857142857, 0.0, 0.0, ...   \n",
      "7   [0.875, 0.9375, 1.0, 0.9090909090909091, 0.882...   \n",
      "8                                            3.642202   \n",
      "9                                            3.642202   \n",
      "10  ([0.00980392156862745, 0.010638297872340425, 0...   \n",
      "11  [1.0, 1.0, 1.0, 0.7142857142857143, 1.0, 1.0, ...   \n",
      "\n",
      "                                               Female  \n",
      "0                                             0.88785  \n",
      "1                                            0.889455  \n",
      "2                                            0.877976  \n",
      "3                                            0.879524  \n",
      "4   [0.7142857142857143, 1.0, 1.0, 0.8666666666666...  \n",
      "5   [0.01, 0.0, 0.03225806451612903, 0.04347826086...  \n",
      "6   [0.2857142857142857, 0.0, 0.0, 0.1333333333333...  \n",
      "7   [0.8333333333333334, 1.0, 0.8235294117647058, ...  \n",
      "8                                            3.682243  \n",
      "9                                            3.682243  \n",
      "10  ([0.01, 0.0, 0.03225806451612903, 0.0434782608...  \n",
      "11  [0.7142857142857143, 1.0, 1.0, 0.8666666666666...  \n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'Metric': [\n",
    "        'Accuracy', 'Precision', 'Recall', 'F1 Score', 'True Positive Rate', 'False Positive Rate',\n",
    "        'False Negative Rate', 'Predictive Parity', 'Positive Rate', 'Demographic Parity',\n",
    "        'Equalized Odds (FPR, FNR)', 'Equal Opportunity (TPR)'\n",
    "    ],\n",
    "    'Male': [\n",
    "        metrics_by_gender['male']['accuracy'], metrics_by_gender['male']['precision'],\n",
    "        metrics_by_gender['male']['recall'], metrics_by_gender['male']['f1'],\n",
    "        metrics_by_gender['male']['tpr'], metrics_by_gender['male']['fpr'],\n",
    "        metrics_by_gender['male']['fnr'], metrics_by_gender['male']['precision_value'],\n",
    "        metrics_by_gender['male']['positive_rate'], metrics_by_gender['male']['demographic_parity'],\n",
    "        metrics_by_gender['male']['equalized_odds'], metrics_by_gender['male']['equal_opportunity']\n",
    "    ],\n",
    "    'Female': [\n",
    "        metrics_by_gender['female']['accuracy'], metrics_by_gender['female']['precision'],\n",
    "        metrics_by_gender['female']['recall'], metrics_by_gender['female']['f1'],\n",
    "        metrics_by_gender['female']['tpr'], metrics_by_gender['female']['fpr'],\n",
    "        metrics_by_gender['female']['fnr'], metrics_by_gender['female']['precision_value'],\n",
    "        metrics_by_gender['female']['positive_rate'], metrics_by_gender['female']['demographic_parity'],\n",
    "        metrics_by_gender['female']['equalized_odds'], metrics_by_gender['female']['equal_opportunity']\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create DataFrame and display\n",
    "df = pd.DataFrame(data)\n",
    "csv_file_path = 'late_fusion_metrics_results.csv'\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1725d119-e4a8-4530-b874-9736e27d6c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_modal_NN():\n",
    "  model=Sequential()\n",
    "  model.add(Input(shape=(800)))\n",
    "  \n",
    "  model.add(Dense(2096))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dropout(0.4))\n",
    "\n",
    "  model.add(Dense(1024))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Activation('relu'))\n",
    "  model.add(Dropout(0.4))\n",
    "\n",
    "  model.add(Dense(8))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Activation('softmax'))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "30e2bb7d-12b9-41c6-b397-1e10e87ef4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "288/288 [==============================] - 6s 17ms/step - loss: 1.2131 - accuracy: 0.6458 - val_loss: 0.2582 - val_accuracy: 0.9479\n",
      "Epoch 2/80\n",
      "288/288 [==============================] - 5s 17ms/step - loss: 1.0488 - accuracy: 0.7439 - val_loss: 0.2190 - val_accuracy: 0.9549\n",
      "Epoch 3/80\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 1.0184 - accuracy: 0.7335 - val_loss: 0.2076 - val_accuracy: 0.9583\n",
      "Epoch 4/80\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.9271 - accuracy: 0.7778 - val_loss: 0.1819 - val_accuracy: 0.9653\n",
      "Epoch 5/80\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.8443 - accuracy: 0.8151 - val_loss: 0.1856 - val_accuracy: 0.9549\n",
      "Epoch 6/80\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.8615 - accuracy: 0.7951 - val_loss: 0.1823 - val_accuracy: 0.9583\n",
      "Epoch 7/80\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.8154 - accuracy: 0.8125 - val_loss: 0.1678 - val_accuracy: 0.9653\n",
      "Epoch 8/80\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.7782 - accuracy: 0.8316 - val_loss: 0.1598 - val_accuracy: 0.9549\n",
      "Epoch 9/80\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.7183 - accuracy: 0.8464 - val_loss: 0.1690 - val_accuracy: 0.9618\n",
      "Epoch 10/80\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.7193 - accuracy: 0.8299 - val_loss: 0.1690 - val_accuracy: 0.9514\n",
      "Epoch 11/80\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.6757 - accuracy: 0.8481 - val_loss: 0.1809 - val_accuracy: 0.9479\n",
      "Epoch 12/80\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.6826 - accuracy: 0.8385 - val_loss: 0.1582 - val_accuracy: 0.9688\n",
      "Epoch 13/80\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.6605 - accuracy: 0.8498 - val_loss: 0.1712 - val_accuracy: 0.9479\n",
      "Epoch 14/80\n",
      "288/288 [==============================] - 4s 16ms/step - loss: 0.6574 - accuracy: 0.8438 - val_loss: 0.1645 - val_accuracy: 0.9479\n",
      "Epoch 15/80\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.6170 - accuracy: 0.8524 - val_loss: 0.1556 - val_accuracy: 0.9618\n",
      "Epoch 16/80\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.5860 - accuracy: 0.8620 - val_loss: 0.1670 - val_accuracy: 0.9618\n",
      "Epoch 17/80\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.5667 - accuracy: 0.8872 - val_loss: 0.1465 - val_accuracy: 0.9583\n",
      "Epoch 18/80\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.5690 - accuracy: 0.8828 - val_loss: 0.1561 - val_accuracy: 0.9688\n",
      "Epoch 19/80\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.5797 - accuracy: 0.8681 - val_loss: 0.1627 - val_accuracy: 0.9618\n",
      "Epoch 20/80\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.5692 - accuracy: 0.8845 - val_loss: 0.1613 - val_accuracy: 0.9583\n",
      "Epoch 21/80\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.5484 - accuracy: 0.8802 - val_loss: 0.1523 - val_accuracy: 0.9688\n",
      "Epoch 22/80\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.5089 - accuracy: 0.8880 - val_loss: 0.1519 - val_accuracy: 0.9618\n",
      "Epoch 23/80\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.4859 - accuracy: 0.8958 - val_loss: 0.1565 - val_accuracy: 0.9444\n",
      "Epoch 24/80\n",
      "288/288 [==============================] - 5s 16ms/step - loss: 0.4627 - accuracy: 0.8976 - val_loss: 0.1523 - val_accuracy: 0.9757\n",
      "Epoch 25/80\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.4888 - accuracy: 0.8915 - val_loss: 0.1408 - val_accuracy: 0.9653\n",
      "Epoch 26/80\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.4788 - accuracy: 0.9062 - val_loss: 0.1464 - val_accuracy: 0.9757\n",
      "Epoch 27/80\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.4668 - accuracy: 0.8950 - val_loss: 0.1357 - val_accuracy: 0.9688\n",
      "Epoch 28/80\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.4538 - accuracy: 0.9141 - val_loss: 0.1553 - val_accuracy: 0.9688\n",
      "Epoch 29/80\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.4731 - accuracy: 0.9019 - val_loss: 0.1564 - val_accuracy: 0.9583\n",
      "Epoch 30/80\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.4626 - accuracy: 0.8993 - val_loss: 0.1487 - val_accuracy: 0.9618\n",
      "Epoch 31/80\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.4356 - accuracy: 0.9132 - val_loss: 0.1449 - val_accuracy: 0.9583\n",
      "Epoch 32/80\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.4035 - accuracy: 0.9340 - val_loss: 0.1373 - val_accuracy: 0.9653\n",
      "Epoch 33/80\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.4008 - accuracy: 0.9167 - val_loss: 0.1423 - val_accuracy: 0.9688\n",
      "Epoch 34/80\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.4051 - accuracy: 0.9245 - val_loss: 0.1402 - val_accuracy: 0.9583\n",
      "Epoch 35/80\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.3808 - accuracy: 0.9236 - val_loss: 0.1383 - val_accuracy: 0.9688\n",
      "Epoch 36/80\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.4149 - accuracy: 0.9271 - val_loss: 0.1384 - val_accuracy: 0.9653\n",
      "Epoch 37/80\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.3820 - accuracy: 0.9236 - val_loss: 0.1622 - val_accuracy: 0.9688\n",
      "Epoch 38/80\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.4119 - accuracy: 0.9115 - val_loss: 0.1568 - val_accuracy: 0.9653\n",
      "Epoch 39/80\n",
      "288/288 [==============================] - 4s 15ms/step - loss: 0.3907 - accuracy: 0.9227 - val_loss: 0.1406 - val_accuracy: 0.9583\n"
     ]
    }
   ],
   "source": [
    "model=multi_modal_NN()\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor = 'val_accuracy', patience = 15, restore_best_weights = True)\n",
    "\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"model_final.h5\", monitor='val_accuracy',save_best_only=True, mode='max')\n",
    "# Start training the model.\n",
    "LRCN_model_training_history = model.fit(          x = X_train,\n",
    "                                                  y = y_train,\n",
    "                                                  validation_data=(X_test, y_test),\n",
    "                                                  epochs = 80,\n",
    "                                                  batch_size = 4,\n",
    "                                                  shuffle = True,\n",
    "                                                  callbacks = [checkpoint_cb,early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bed8162c-e40e-40d6-b11e-5f79c38c9afd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'logreg_c'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m clf \u001b[38;5;241m=\u001b[39m \u001b[43mSVC\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'logreg_c'"
     ]
    }
   ],
   "source": [
    "#clf = SVC(**trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed53c36-30fd-4325-8b45-6f2ada9e11dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Early Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b31eaf51-52d3-4b3e-8da5-93c6d1f155a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dbfile = open('video_data_new2', 'rb')     \n",
    "# df = pickle.load(dbfile)\n",
    "\n",
    "# emotion_labels = df['labels']\n",
    "# genders = df['genders']\n",
    "# df=df['features']\n",
    "\n",
    "\n",
    "# dbfile = open('data_mel_new', 'rb')\n",
    "# df_audio_1=pickle.load(dbfile)\n",
    "# df_audio = df_audio_1['features']\n",
    "# labels = df_audio_1['labels']\n",
    "# genders_audio = df_audio_1['genders']\n",
    "# paths = df_audio_1['video_files_paths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1a67872a-21f0-4d51-9d7c-1060e01e8025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels = np.array(labels)\n",
    "# labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55df8f33-552c-4a89-b364-ab246041ccb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1008, 49152)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1 - Flatten\n",
    "X_train_flattened = np.reshape(X_train, (1008, 20, -1))\n",
    "X_train_flattened.shape\n",
    "X_train_aud_flattened = np.reshape(X_train_aud, (1008, -1))\n",
    "X_train_aud_flattened.shape\n",
    "# video_data_flat = np.reshape(df, (1440, -1))  # Reshape to (816, 20*48*48) or similar\n",
    "# audio_data_flat = np.reshape(df_audio, (1440, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c694222-ec96-4155-9ba7-cd862fe16b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_aud_reshape = np.reshape(X_train_aud_flattened, (1008, 1, 49152))\n",
    "\n",
    "X_train_aud_repeated = np.repeat(X_train_aud_reshape, 20, axis=1)\n",
    "X_train_aud_repeated = X_train_aud_repeated/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee79cb85-736d-4bbb-9da9-2fcebae44576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1008, 20, 49152)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_aud_repeated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35f0cf48-1dbe-4b55-8d50-f48ac804260a",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_train_data = np.concatenate((X_train_flattened, X_train_aud_repeated), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecf8fcc8-7a23-44b7-8bb2-cda3459a1b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_flattened = np.reshape(X_val, (216, 20, -1))\n",
    "X_val_flattened.shape\n",
    "X_val_aud_flattened = np.reshape(X_val_aud, (216, -1))\n",
    "X_val_aud_flattened.shape\n",
    "\n",
    "X_val_aud_reshape = np.reshape(X_val_aud_flattened, (216, 1, 49152))\n",
    "\n",
    "X_val_aud_repeated = np.repeat(X_val_aud_reshape, 20, axis=1)\n",
    "X_val_aud_repeated = X_val_aud_repeated/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67c255f1-8068-4cf9-a12c-8e2e262526b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_val_data = np.concatenate((X_val_flattened, X_val_aud_repeated), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ac418b5-2a3b-4a2b-9c1f-101a7279675b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_flattened = np.reshape(X_test, (216, 20, -1))\n",
    "X_test_flattened.shape\n",
    "X_test_aud_flattened = np.reshape(X_test_aud, (216, -1))\n",
    "X_test_aud_flattened.shape\n",
    "\n",
    "X_test_aud_reshape = np.reshape(X_test_aud_flattened, (216, 1, 49152))\n",
    "\n",
    "X_test_aud_repeated = np.repeat(X_test_aud_reshape, 20, axis=1)\n",
    "X_test_aud_repeated = X_val_aud_repeated/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0de683d5-7a50-4ad4-a8b5-d3e6f0d043a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_test_data = np.concatenate((X_test_flattened, X_test_aud_repeated), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66690350-36e7-4841-a4a9-e5c057c556b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_modal_NN(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=input_shape))\n",
    "    \n",
    "    # Flatten the input\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(2096))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Dense(1024))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Dense(8))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69edb2d1-1124-434a-b4d1-6365fa07cd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, X, y, batch_size=32, shuffle=True):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.X) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        X_batch = self.X[indices]\n",
    "        y_batch = self.y[indices]\n",
    "        return X_batch, y_batch\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(len(self.X))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "# Create data generators\n",
    "train_generator = DataGenerator(concatenated_train_data, y_train, batch_size=32)\n",
    "val_generator = DataGenerator(concatenated_val_data, y_val, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7950a7be-c49a-41ad-bd5c-3e7c66ab7e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-14 03:01:51.438454: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 8628142080 exceeds 10% of free system memory.\n",
      "2024-07-14 03:01:52.293987: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 8628142080 exceeds 10% of free system memory.\n",
      "2024-07-14 03:01:52.779791: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 8628142080 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-14 03:01:54.871313: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 8628142080 exceeds 10% of free system memory.\n",
      "2024-07-14 03:01:55.169380: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 8628142080 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 868s 21s/step - loss: 2.4236 - accuracy: 0.1240 - val_loss: 12.0393 - val_accuracy: 0.0990\n",
      "Epoch 2/80\n",
      "31/31 [==============================] - 1512s 36s/step - loss: 2.3074 - accuracy: 0.1603 - val_loss: 4.5128 - val_accuracy: 0.1198\n",
      "Epoch 3/80\n",
      "31/31 [==============================] - 1711s 42s/step - loss: 2.2011 - accuracy: 0.1552 - val_loss: 2.4045 - val_accuracy: 0.1094\n",
      "Epoch 4/80\n",
      "31/31 [==============================] - 466s 15s/step - loss: 2.0756 - accuracy: 0.1583 - val_loss: 2.2634 - val_accuracy: 0.1302\n",
      "Epoch 5/80\n",
      "31/31 [==============================] - 1592s 36s/step - loss: 2.0632 - accuracy: 0.1804 - val_loss: 2.1483 - val_accuracy: 0.1302\n",
      "Epoch 6/80\n",
      "31/31 [==============================] - 472s 14s/step - loss: 2.0550 - accuracy: 0.1764 - val_loss: 2.1428 - val_accuracy: 0.0990\n",
      "Epoch 7/80\n",
      "31/31 [==============================] - 402s 13s/step - loss: 2.0402 - accuracy: 0.2016 - val_loss: 2.1316 - val_accuracy: 0.1198\n",
      "Epoch 8/80\n",
      "31/31 [==============================] - 395s 13s/step - loss: 2.0423 - accuracy: 0.2067 - val_loss: 2.1036 - val_accuracy: 0.1302\n",
      "Epoch 9/80\n",
      "31/31 [==============================] - 402s 13s/step - loss: 2.0322 - accuracy: 0.2026 - val_loss: 2.1127 - val_accuracy: 0.1250\n",
      "Epoch 10/80\n",
      "31/31 [==============================] - 396s 13s/step - loss: 2.0264 - accuracy: 0.2036 - val_loss: 2.1123 - val_accuracy: 0.1250\n",
      "Epoch 11/80\n",
      "31/31 [==============================] - 481s 16s/step - loss: 1.9990 - accuracy: 0.2339 - val_loss: 2.0912 - val_accuracy: 0.1667\n",
      "Epoch 12/80\n",
      "31/31 [==============================] - 1566s 29s/step - loss: 2.0033 - accuracy: 0.2248 - val_loss: 2.1127 - val_accuracy: 0.1302\n",
      "Epoch 13/80\n",
      "31/31 [==============================] - 449s 14s/step - loss: 1.9611 - accuracy: 0.2651 - val_loss: 2.0993 - val_accuracy: 0.1458\n",
      "Epoch 14/80\n",
      "31/31 [==============================] - 451s 15s/step - loss: 1.9806 - accuracy: 0.2500 - val_loss: 2.1636 - val_accuracy: 0.0938\n",
      "Epoch 15/80\n",
      "31/31 [==============================] - 426s 14s/step - loss: 1.9088 - accuracy: 0.2843 - val_loss: 2.1235 - val_accuracy: 0.1198\n",
      "Epoch 16/80\n",
      "31/31 [==============================] - 441s 14s/step - loss: 1.9255 - accuracy: 0.2893 - val_loss: 2.2604 - val_accuracy: 0.0990\n",
      "Epoch 17/80\n",
      "31/31 [==============================] - 410s 13s/step - loss: 1.8673 - accuracy: 0.3085 - val_loss: 2.2008 - val_accuracy: 0.1198\n",
      "Epoch 18/80\n",
      "31/31 [==============================] - 440s 14s/step - loss: 1.8404 - accuracy: 0.3276 - val_loss: 2.1419 - val_accuracy: 0.1198\n",
      "Epoch 19/80\n",
      "31/31 [==============================] - 419s 14s/step - loss: 1.7634 - accuracy: 0.3639 - val_loss: 2.1789 - val_accuracy: 0.1198\n",
      "Epoch 20/80\n",
      "31/31 [==============================] - 398s 13s/step - loss: 1.7482 - accuracy: 0.3871 - val_loss: 2.2311 - val_accuracy: 0.1250\n",
      "Epoch 21/80\n",
      "31/31 [==============================] - 394s 13s/step - loss: 1.7158 - accuracy: 0.3992 - val_loss: 2.3151 - val_accuracy: 0.1406\n",
      "Epoch 22/80\n",
      "31/31 [==============================] - 418s 14s/step - loss: 1.6553 - accuracy: 0.4254 - val_loss: 2.2561 - val_accuracy: 0.1302\n",
      "Epoch 23/80\n",
      "31/31 [==============================] - 410s 13s/step - loss: 1.6009 - accuracy: 0.4587 - val_loss: 2.2912 - val_accuracy: 0.1458\n",
      "Epoch 24/80\n",
      "31/31 [==============================] - 547s 18s/step - loss: 1.5940 - accuracy: 0.4365 - val_loss: 2.1396 - val_accuracy: 0.1719\n",
      "Epoch 25/80\n",
      "31/31 [==============================] - 1241s 28s/step - loss: 1.4667 - accuracy: 0.5323 - val_loss: 2.2313 - val_accuracy: 0.1875\n",
      "Epoch 26/80\n",
      "31/31 [==============================] - 1219s 29s/step - loss: 1.4874 - accuracy: 0.5222 - val_loss: 2.2217 - val_accuracy: 0.1875\n",
      "Epoch 27/80\n",
      "31/31 [==============================] - 525s 17s/step - loss: 1.3952 - accuracy: 0.5655 - val_loss: 2.1590 - val_accuracy: 0.1979\n",
      "Epoch 28/80\n",
      "31/31 [==============================] - 1659s 37s/step - loss: 1.3344 - accuracy: 0.5786 - val_loss: 2.2409 - val_accuracy: 0.1562\n",
      "Epoch 29/80\n",
      "31/31 [==============================] - 476s 15s/step - loss: 1.2596 - accuracy: 0.6139 - val_loss: 2.2153 - val_accuracy: 0.1615\n",
      "Epoch 30/80\n",
      "31/31 [==============================] - 536s 17s/step - loss: 1.2326 - accuracy: 0.6300 - val_loss: 2.2430 - val_accuracy: 0.2031\n",
      "Epoch 31/80\n",
      "31/31 [==============================] - 1845s 34s/step - loss: 1.1433 - accuracy: 0.6764 - val_loss: 2.2171 - val_accuracy: 0.1979\n",
      "Epoch 32/80\n",
      "31/31 [==============================] - 509s 16s/step - loss: 1.0897 - accuracy: 0.6996 - val_loss: 2.3884 - val_accuracy: 0.1771\n",
      "Epoch 33/80\n",
      "31/31 [==============================] - 527s 17s/step - loss: 1.1010 - accuracy: 0.6845 - val_loss: 2.2415 - val_accuracy: 0.2083\n",
      "Epoch 34/80\n",
      "31/31 [==============================] - 1988s 34s/step - loss: 1.0302 - accuracy: 0.7127 - val_loss: 2.3478 - val_accuracy: 0.1719\n",
      "Epoch 35/80\n",
      "31/31 [==============================] - 591s 17s/step - loss: 1.0130 - accuracy: 0.7329 - val_loss: 2.1203 - val_accuracy: 0.1823\n",
      "Epoch 36/80\n",
      "31/31 [==============================] - 471s 15s/step - loss: 0.9286 - accuracy: 0.7581 - val_loss: 2.0724 - val_accuracy: 0.1667\n",
      "Epoch 37/80\n",
      "31/31 [==============================] - 502s 16s/step - loss: 0.9296 - accuracy: 0.7510 - val_loss: 2.1858 - val_accuracy: 0.2083\n",
      "Epoch 38/80\n",
      "31/31 [==============================] - 489s 16s/step - loss: 0.8841 - accuracy: 0.7752 - val_loss: 2.0532 - val_accuracy: 0.1823\n",
      "Epoch 39/80\n",
      "31/31 [==============================] - 490s 16s/step - loss: 0.8484 - accuracy: 0.7772 - val_loss: 2.1380 - val_accuracy: 0.1719\n",
      "Epoch 40/80\n",
      "31/31 [==============================] - 446s 14s/step - loss: 0.7826 - accuracy: 0.8034 - val_loss: 2.2961 - val_accuracy: 0.1771\n",
      "Epoch 41/80\n",
      "31/31 [==============================] - 474s 15s/step - loss: 0.7855 - accuracy: 0.7974 - val_loss: 2.1719 - val_accuracy: 0.1562\n",
      "Epoch 42/80\n",
      "31/31 [==============================] - 521s 17s/step - loss: 0.8042 - accuracy: 0.7843 - val_loss: 2.5807 - val_accuracy: 0.2135\n",
      "Epoch 43/80\n",
      "31/31 [==============================] - 1372s 29s/step - loss: 0.7641 - accuracy: 0.8085 - val_loss: 2.2166 - val_accuracy: 0.2083\n",
      "Epoch 44/80\n",
      "31/31 [==============================] - 723s 21s/step - loss: 0.7048 - accuracy: 0.8427 - val_loss: 2.1478 - val_accuracy: 0.2292\n",
      "Epoch 45/80\n",
      "31/31 [==============================] - 1463s 31s/step - loss: 0.7278 - accuracy: 0.8286 - val_loss: 2.3659 - val_accuracy: 0.2083\n",
      "Epoch 46/80\n",
      "31/31 [==============================] - 518s 16s/step - loss: 0.6903 - accuracy: 0.8185 - val_loss: 2.2668 - val_accuracy: 0.2083\n",
      "Epoch 47/80\n",
      "31/31 [==============================] - 482s 15s/step - loss: 0.6365 - accuracy: 0.8498 - val_loss: 2.2119 - val_accuracy: 0.1875\n",
      "Epoch 48/80\n",
      "31/31 [==============================] - 508s 16s/step - loss: 0.5980 - accuracy: 0.8649 - val_loss: 2.1204 - val_accuracy: 0.2135\n",
      "Epoch 49/80\n",
      "31/31 [==============================] - 500s 16s/step - loss: 0.6120 - accuracy: 0.8569 - val_loss: 2.1840 - val_accuracy: 0.2292\n",
      "Epoch 50/80\n",
      "31/31 [==============================] - 493s 16s/step - loss: 0.5890 - accuracy: 0.8720 - val_loss: 2.1897 - val_accuracy: 0.2292\n",
      "Epoch 51/80\n",
      "31/31 [==============================] - 502s 16s/step - loss: 0.5715 - accuracy: 0.8740 - val_loss: 2.1904 - val_accuracy: 0.2292\n",
      "Epoch 52/80\n",
      "31/31 [==============================] - 511s 16s/step - loss: 0.5603 - accuracy: 0.8679 - val_loss: 2.3230 - val_accuracy: 0.1302\n",
      "Epoch 53/80\n",
      "31/31 [==============================] - 500s 16s/step - loss: 0.5644 - accuracy: 0.8740 - val_loss: 2.4582 - val_accuracy: 0.1719\n",
      "Epoch 54/80\n",
      "31/31 [==============================] - 498s 16s/step - loss: 0.5549 - accuracy: 0.8700 - val_loss: 2.4927 - val_accuracy: 0.1667\n",
      "Epoch 55/80\n",
      "31/31 [==============================] - 485s 16s/step - loss: 0.5570 - accuracy: 0.8639 - val_loss: 2.2663 - val_accuracy: 0.1771\n",
      "Epoch 56/80\n",
      "31/31 [==============================] - 501s 16s/step - loss: 0.5323 - accuracy: 0.8679 - val_loss: 2.1729 - val_accuracy: 0.1875\n",
      "Epoch 57/80\n",
      "31/31 [==============================] - 496s 16s/step - loss: 0.4992 - accuracy: 0.8881 - val_loss: 2.5041 - val_accuracy: 0.1510\n",
      "Epoch 58/80\n",
      "31/31 [==============================] - 486s 16s/step - loss: 0.5165 - accuracy: 0.8831 - val_loss: 2.3792 - val_accuracy: 0.1927\n",
      "Epoch 59/80\n",
      "31/31 [==============================] - 921s 30s/step - loss: 0.4905 - accuracy: 0.8861 - val_loss: 2.3664 - val_accuracy: 0.1719\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = '/var/scratch/mpa326/saved_models_early_fusion/model_1.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 19\u001b[0m\n\u001b[1;32m      9\u001b[0m checkpoint_cb \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mearly_fusion.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m early_fusion_history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     13\u001b[0m     train_generator,\n\u001b[1;32m     14\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mval_generator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[checkpoint_cb, early_stopping_callback]\n\u001b[1;32m     18\u001b[0m )\n\u001b[0;32m---> 19\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfold_var\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# early_fusion_history = model.fit(\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#     x = concatenated_train_data,\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#     y = y_train,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#     callbacks=[checkpoint_cb, early_stopping_callback]\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n",
      "File \u001b[0;32m/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/h5py/_hl/files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[1;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[1;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[1;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[1;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[1;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[38;5;241m=\u001b[39mswmr)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[0;32m/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/h5py/_hl/files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[1;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[0;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = '/var/scratch/mpa326/saved_models_early_fusion/model_1.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "input_shape = (20, 51456)  # Shape of your input data\n",
    "save_dir = os.path.abspath(DIR)+'/saved_models_early_fusion/'\n",
    "fold_var=1\n",
    "model = multi_modal_NN(input_shape)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "\n",
    "early_stopping_callback = EarlyStopping(monitor='val_accuracy', patience=15, restore_best_weights=True)\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"early_fusion.h5\", monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "\n",
    "\n",
    "early_fusion_history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=80,\n",
    "    shuffle=True,\n",
    "    callbacks=[checkpoint_cb, early_stopping_callback]\n",
    ")\n",
    "model.load_weights(save_dir+\"model_\"+str(fold_var)+\".h5\")\n",
    "\n",
    "# early_fusion_history = model.fit(\n",
    "#     x = concatenated_train_data,\n",
    "#     y = y_train,\n",
    "#     validation_data=(concatenated_val_data, y_val),\n",
    "#     epochs=80,\n",
    "#     batch_size=2,\n",
    "#     shuffle=True,\n",
    "#     callbacks=[checkpoint_cb, early_stopping_callback]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf91f928-e643-4509-a5fc-08bc4f9832c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(save_dir + 'early_fusion_model_final_fold_' + str(fold_var) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8173909d-7b6e-425c-9030-b83b8df09a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = DataGenerator(concatenated_test_data, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1505e8a-c039-4397-9d23-e9ba884547f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 59s 8s/step - loss: 2.6923 - accuracy: 0.2130\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(concatenated_test_data, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4add31f-e98f-493d-9f22-e39ddffc1100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 18s 4s/step\n",
      "4/4 [==============================] - 5s 1s/step\n",
      "Gender bias analysis: {'female': {'accuracy': 0.21495327102803738, 'precision': 0.057060838033843674, 'recall': 0.19702380952380955, 'f1': 0.08664772727272727, 'tpr': array([0.        , 0.        , 0.64285714, 0.        , 0.        ,\n",
      "       0.        , 0.93333333, 0.        ]), 'fpr': array([0.        , 0.        , 0.2688172 , 0.        , 0.        ,\n",
      "       0.        , 0.64130435, 0.        ]), 'fnr': array([1.        , 1.        , 0.35714286, 1.        , 1.        ,\n",
      "       1.        , 0.06666667, 1.        ]), 'precision_value': array([       nan,        nan, 0.26470588,        nan,        nan,\n",
      "              nan, 0.19178082,        nan]), 'positive_rate': 4.728971962616822}, 'male': {'accuracy': 0.21100917431192662, 'precision': 0.06435356811862836, 'recall': 0.20535714285714285, 'f1': 0.09233247422680413, 'tpr': array([0.        , 0.        , 0.64285714, 0.        , 0.        ,\n",
      "       0.        , 1.        , 0.        ]), 'fpr': array([0.        , 0.        , 0.17894737, 0.        , 0.        ,\n",
      "       0.        , 0.72631579, 0.        ]), 'fnr': array([1.        , 1.        , 0.35714286, 1.        , 1.        ,\n",
      "       1.        , 0.        , 1.        ]), 'precision_value': array([       nan,        nan, 0.34615385,        nan,        nan,\n",
      "              nan, 0.1686747 ,        nan]), 'positive_rate': 5.045871559633028}}\n",
      "Disparate Impact Ratio: 0.9371962616822429\n",
      "False Positive Equality: 0.0006072992790531612\n",
      "False Negative Equality: 0.008333333333333304\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "metrics_by_gender = {}\n",
    "for gender in np.unique(gender_test):\n",
    "    gender_indices = np.where(gender_test == gender)\n",
    "    X_gender_test = concatenated_test_data[gender_indices]\n",
    "    y_gender_test = y_test[gender_indices]\n",
    "    y_pred = model.predict(X_gender_test)\n",
    "    y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    accuracy = np.mean(y_pred == y_gender_test)\n",
    "    precision = precision_score(y_gender_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_gender_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_gender_test, y_pred, average='macro')\n",
    "\n",
    "    cm = confusion_matrix(y_gender_test, y_pred)\n",
    "    tn = np.sum(cm) - (np.sum(cm, axis=0) + np.sum(cm, axis=1) - np.diag(cm))\n",
    "    fp = np.sum(cm, axis=0) - np.diag(cm)\n",
    "    fn = np.sum(cm, axis=1) - np.diag(cm)\n",
    "    tp = np.diag(cm)\n",
    "    tpr = tp / (tp + fn)  # True Positive Rate\n",
    "    fpr = fp / (fp + tn)  # False Positive Rate\n",
    "    fnr = fn / (fn + tp)  # False Negative Rate\n",
    "    precision_value = tp / (tp + fp)\n",
    "\n",
    "    metrics_by_gender[gender] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'tpr': tpr,\n",
    "        'fpr': fpr,\n",
    "        'fnr': fnr,\n",
    "        'precision_value': precision_value,\n",
    "        'positive_rate': np.mean(y_pred)\n",
    "    }\n",
    "\n",
    "# Additional fairness metrics\n",
    "positive_rates = [metrics_by_gender[gender]['positive_rate'] for gender in metrics_by_gender]\n",
    "disparate_impact_ratio = min(positive_rates) / max(positive_rates)\n",
    "\n",
    "print(\"Gender bias analysis:\", metrics_by_gender)\n",
    "print(\"Disparate Impact Ratio:\", disparate_impact_ratio)\n",
    "\n",
    "for gender in metrics_by_gender:\n",
    "    metrics_by_gender[gender]['demographic_parity'] = metrics_by_gender[gender]['positive_rate']\n",
    "    metrics_by_gender[gender]['equalized_odds'] = (metrics_by_gender[gender]['fpr'], metrics_by_gender[gender]['fnr'])\n",
    "    metrics_by_gender[gender]['equal_opportunity'] = metrics_by_gender[gender]['tpr']\n",
    "    metrics_by_gender[gender]['predictive_parity'] = metrics_by_gender[gender]['precision_value']\n",
    "\n",
    "fpr_values = [metrics_by_gender[gender]['fpr'] for gender in metrics_by_gender]\n",
    "fnr_values = [metrics_by_gender[gender]['fnr'] for gender in metrics_by_gender]\n",
    "\n",
    "avg_fpr_values = [np.mean(fpr) for fpr in fpr_values]\n",
    "avg_fnr_values = [np.mean(fnr) for fnr in fnr_values]\n",
    "\n",
    "false_positive_equality = max(avg_fpr_values) - min(avg_fpr_values)\n",
    "false_negative_equality = max(avg_fnr_values) - min(avg_fnr_values)\n",
    "\n",
    "print(\"False Positive Equality:\", false_positive_equality)\n",
    "print(\"False Negative Equality:\", false_negative_equality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9250bc55-dd19-4001-859b-fe11df94bab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Metric  \\\n",
      "0                    Accuracy   \n",
      "1                   Precision   \n",
      "2                      Recall   \n",
      "3                    F1 Score   \n",
      "4          True Positive Rate   \n",
      "5         False Positive Rate   \n",
      "6         False Negative Rate   \n",
      "7           Predictive Parity   \n",
      "8               Positive Rate   \n",
      "9          Demographic Parity   \n",
      "10  Equalized Odds (FPR, FNR)   \n",
      "11    Equal Opportunity (TPR)   \n",
      "\n",
      "                                                 Male  \\\n",
      "0                                            0.211009   \n",
      "1                                            0.064354   \n",
      "2                                            0.205357   \n",
      "3                                            0.092332   \n",
      "4   [0.0, 0.0, 0.6428571428571429, 0.0, 0.0, 0.0, ...   \n",
      "5   [0.0, 0.0, 0.17894736842105263, 0.0, 0.0, 0.0,...   \n",
      "6   [1.0, 1.0, 0.35714285714285715, 1.0, 1.0, 1.0,...   \n",
      "7   [nan, nan, 0.34615384615384615, nan, nan, nan,...   \n",
      "8                                            5.045872   \n",
      "9                                            5.045872   \n",
      "10  ([0.0, 0.0, 0.17894736842105263, 0.0, 0.0, 0.0...   \n",
      "11  [0.0, 0.0, 0.6428571428571429, 0.0, 0.0, 0.0, ...   \n",
      "\n",
      "                                               Female  \n",
      "0                                            0.214953  \n",
      "1                                            0.057061  \n",
      "2                                            0.197024  \n",
      "3                                            0.086648  \n",
      "4   [0.0, 0.0, 0.6428571428571429, 0.0, 0.0, 0.0, ...  \n",
      "5   [0.0, 0.0, 0.26881720430107525, 0.0, 0.0, 0.0,...  \n",
      "6   [1.0, 1.0, 0.35714285714285715, 1.0, 1.0, 1.0,...  \n",
      "7   [nan, nan, 0.2647058823529412, nan, nan, nan, ...  \n",
      "8                                            4.728972  \n",
      "9                                            4.728972  \n",
      "10  ([0.0, 0.0, 0.26881720430107525, 0.0, 0.0, 0.0...  \n",
      "11  [0.0, 0.0, 0.6428571428571429, 0.0, 0.0, 0.0, ...  \n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'Metric': [\n",
    "        'Accuracy', 'Precision', 'Recall', 'F1 Score', 'True Positive Rate', 'False Positive Rate',\n",
    "        'False Negative Rate', 'Predictive Parity', 'Positive Rate', 'Demographic Parity',\n",
    "        'Equalized Odds (FPR, FNR)', 'Equal Opportunity (TPR)'\n",
    "    ],\n",
    "    'Male': [\n",
    "        metrics_by_gender['male']['accuracy'], metrics_by_gender['male']['precision'],\n",
    "        metrics_by_gender['male']['recall'], metrics_by_gender['male']['f1'],\n",
    "        metrics_by_gender['male']['tpr'], metrics_by_gender['male']['fpr'],\n",
    "        metrics_by_gender['male']['fnr'], metrics_by_gender['male']['precision_value'],\n",
    "        metrics_by_gender['male']['positive_rate'], metrics_by_gender['male']['demographic_parity'],\n",
    "        metrics_by_gender['male']['equalized_odds'], metrics_by_gender['male']['equal_opportunity']\n",
    "    ],\n",
    "    'Female': [\n",
    "        metrics_by_gender['female']['accuracy'], metrics_by_gender['female']['precision'],\n",
    "        metrics_by_gender['female']['recall'], metrics_by_gender['female']['f1'],\n",
    "        metrics_by_gender['female']['tpr'], metrics_by_gender['female']['fpr'],\n",
    "        metrics_by_gender['female']['fnr'], metrics_by_gender['female']['precision_value'],\n",
    "        metrics_by_gender['female']['positive_rate'], metrics_by_gender['female']['demographic_parity'],\n",
    "        metrics_by_gender['female']['equalized_odds'], metrics_by_gender['female']['equal_opportunity']\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create DataFrame and display\n",
    "df = pd.DataFrame(data)\n",
    "csv_file_path = 'early_fusion_metrics_results14thJul.csv'\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6acc0207-7853-45a2-a239-ddb4f2bb4707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create__LRCN_with_STN():\n",
    "#     concatenated_features = tf.keras.layers.Input(shape=(95232,))\n",
    "#     x = tf.keras.layers.Reshape((20, 4761))(concatenated_features)\n",
    "    \n",
    "#     lstm = Bidirectional(LSTM(200, activation='tanh', input_shape=(20, 4761), dropout=0.3))(x)\n",
    "    \n",
    "#     out = Dense(len(emotions_en), activation='softmax')(lstm)\n",
    "\n",
    "#     model = tf.keras.models.Model(inputs=concatenated_features, outputs=out)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "84741eaf-97ef-4b7d-b49e-39066b44529a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (1008, 95232)\n",
      "Validation set shape: (216, 95232)\n",
      "Test set shape: (216, 95232)\n",
      "Label Train set shape: (1008,)\n",
      "Label Validation set shape: (216,)\n",
      "Label Test set shape: (216,)\n",
      "GenderTrain set shape: ['female' 'male' 'female' ... 'female' 'male' 'male']\n",
      "Gender Validation set shape: (216,)\n",
      "Gender Test set shape: (216,)\n"
     ]
    }
   ],
   "source": [
    "# combined_labels = [(e, g) for e, g in zip(labels, genders)]\n",
    "# X_train, X_temp, y_train, y_temp, gender_train, gender_temp = train_test_split(\n",
    "#     concatenated_data, labels, genders, test_size=0.3, stratify=combined_labels, random_state=42\n",
    "# )\n",
    "\n",
    "# combined_temp_labels = [(e, g) for e, g in zip(y_temp, gender_temp)]\n",
    "\n",
    "# # Split the temporary set into validation and test sets\n",
    "# X_val, X_test, y_val, y_test, gender_val, gender_test = train_test_split(\n",
    "#     X_temp, y_temp, gender_temp, test_size=0.5, stratify=combined_temp_labels, random_state=42\n",
    "# )\n",
    "\n",
    "# print(\"Train set shape:\", X_train.shape)\n",
    "# print(\"Validation set shape:\", X_val.shape)\n",
    "# print(\"Test set shape:\", X_test.shape)\n",
    "\n",
    "# print(\"Label Train set shape:\", y_train.shape)\n",
    "# print(\"Label Validation set shape:\", y_val.shape)\n",
    "# print(\"Label Test set shape:\", y_test.shape)\n",
    "\n",
    "# print(\"GenderTrain set shape:\", gender_train)\n",
    "# print(\"Gender Validation set shape:\", gender_val.shape)\n",
    "# print(\"Gender Test set shape:\", gender_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1fb2f7c3-f2f2-4fac-bb28-32a7fc1df662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import linear_model\n",
    "\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e0f3adbe-4dfa-4d34-a268-8da8c27abfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-16 12:52:14,944] A new study created in memory with name: tps-feb-2022\n",
      "[I 2024-06-16 12:52:51,752] Trial 0 finished with value: 0.6481481481481481 and parameters: {'logreg_c': 5705708424.191827}. Best is trial 0 with value: 0.6481481481481481.\n",
      "[I 2024-06-16 12:53:35,833] Trial 1 finished with value: 0.5972222222222222 and parameters: {'logreg_c': 5.1299049881000455e-09}. Best is trial 0 with value: 0.6481481481481481.\n",
      "[I 2024-06-16 12:54:10,721] Trial 2 finished with value: 0.6481481481481481 and parameters: {'logreg_c': 1445315.6881947566}. Best is trial 0 with value: 0.6481481481481481.\n",
      "[I 2024-06-16 12:54:57,640] Trial 3 finished with value: 0.5231481481481481 and parameters: {'logreg_c': 2.471575396723528e-09}. Best is trial 0 with value: 0.6481481481481481.\n",
      "[I 2024-06-16 12:55:41,436] Trial 4 finished with value: 0.6759259259259259 and parameters: {'logreg_c': 2.527992265558401e-06}. Best is trial 4 with value: 0.6759259259259259.\n",
      "[I 2024-06-16 12:56:16,799] Trial 5 finished with value: 0.6481481481481481 and parameters: {'logreg_c': 3802760.1952809715}. Best is trial 4 with value: 0.6759259259259259.\n",
      "[I 2024-06-16 12:56:57,283] Trial 6 finished with value: 0.6481481481481481 and parameters: {'logreg_c': 77.67559023001009}. Best is trial 4 with value: 0.6759259259259259.\n",
      "[I 2024-06-16 12:57:45,907] Trial 7 finished with value: 0.3888888888888889 and parameters: {'logreg_c': 5.083946400402248e-10}. Best is trial 4 with value: 0.6759259259259259.\n",
      "[I 2024-06-16 12:58:25,091] Trial 8 finished with value: 0.6481481481481481 and parameters: {'logreg_c': 6132.196215491802}. Best is trial 4 with value: 0.6759259259259259.\n",
      "[I 2024-06-16 12:59:08,993] Trial 9 finished with value: 0.7037037037037037 and parameters: {'logreg_c': 1.233381092916111e-07}. Best is trial 9 with value: 0.7037037037037037.\n",
      "[I 2024-06-16 12:59:51,691] Trial 10 finished with value: 0.6759259259259259 and parameters: {'logreg_c': 0.021433737019814127}. Best is trial 9 with value: 0.7037037037037037.\n",
      "[I 2024-06-16 13:00:33,823] Trial 11 finished with value: 0.6620370370370371 and parameters: {'logreg_c': 0.0001642355483437786}. Best is trial 9 with value: 0.7037037037037037.\n",
      "[I 2024-06-16 13:01:18,299] Trial 12 finished with value: 0.7037037037037037 and parameters: {'logreg_c': 1.6369577706635953e-05}. Best is trial 9 with value: 0.7037037037037037.\n",
      "[I 2024-06-16 13:02:01,908] Trial 13 finished with value: 0.6990740740740741 and parameters: {'logreg_c': 4.452457642132533e-06}. Best is trial 9 with value: 0.7037037037037037.\n",
      "[I 2024-06-16 13:02:47,271] Trial 14 finished with value: 0.6527777777777778 and parameters: {'logreg_c': 0.0012264448907960393}. Best is trial 9 with value: 0.7037037037037037.\n",
      "[I 2024-06-16 13:03:25,762] Trial 15 finished with value: 0.6620370370370371 and parameters: {'logreg_c': 0.5613642007307603}. Best is trial 9 with value: 0.7037037037037037.\n",
      "[I 2024-06-16 13:04:14,938] Trial 16 finished with value: 0.7037037037037037 and parameters: {'logreg_c': 1.0164706635174132e-06}. Best is trial 9 with value: 0.7037037037037037.\n",
      "[I 2024-06-16 13:05:00,719] Trial 17 finished with value: 0.6898148148148148 and parameters: {'logreg_c': 1.2996452952507715e-07}. Best is trial 9 with value: 0.7037037037037037.\n",
      "[I 2024-06-16 13:05:44,941] Trial 18 finished with value: 0.6527777777777778 and parameters: {'logreg_c': 0.00023903751506952975}. Best is trial 9 with value: 0.7037037037037037.\n",
      "[I 2024-06-16 13:06:25,377] Trial 19 finished with value: 0.6666666666666666 and parameters: {'logreg_c': 0.37257376306429524}. Best is trial 9 with value: 0.7037037037037037.\n",
      "[I 2024-06-16 13:07:08,344] Trial 20 finished with value: 0.35185185185185186 and parameters: {'logreg_c': 2.063337931974129e-10}. Best is trial 9 with value: 0.7037037037037037.\n",
      "[I 2024-06-16 13:07:55,634] Trial 21 finished with value: 0.6990740740740741 and parameters: {'logreg_c': 4.1854326988171306e-07}. Best is trial 9 with value: 0.7037037037037037.\n",
      "[I 2024-06-16 13:08:42,998] Trial 22 finished with value: 0.6712962962962963 and parameters: {'logreg_c': 2.1202030572328257e-05}. Best is trial 9 with value: 0.7037037037037037.\n",
      "[I 2024-06-16 13:09:28,154] Trial 23 finished with value: 0.6435185185185185 and parameters: {'logreg_c': 1.3295677006822261e-08}. Best is trial 9 with value: 0.7037037037037037.\n",
      "[I 2024-06-16 13:10:12,153] Trial 24 finished with value: 0.6666666666666666 and parameters: {'logreg_c': 0.00673119941924875}. Best is trial 9 with value: 0.7037037037037037.\n",
      "[I 2024-06-16 13:11:01,000] Trial 25 finished with value: 0.6944444444444444 and parameters: {'logreg_c': 1.072637159472425e-07}. Best is trial 9 with value: 0.7037037037037037.\n",
      "[I 2024-06-16 13:11:37,614] Trial 26 finished with value: 0.6481481481481481 and parameters: {'logreg_c': 19.47721141010234}. Best is trial 9 with value: 0.7037037037037037.\n",
      "[I 2024-06-16 13:12:28,942] Trial 27 finished with value: 0.6527777777777778 and parameters: {'logreg_c': 5.599008627237505e-05}. Best is trial 9 with value: 0.7037037037037037.\n",
      "[I 2024-06-16 13:13:12,908] Trial 28 finished with value: 0.6944444444444444 and parameters: {'logreg_c': 1.1085085944035997e-06}. Best is trial 9 with value: 0.7037037037037037.\n",
      "[I 2024-06-16 13:14:02,708] Trial 29 finished with value: 0.6759259259259259 and parameters: {'logreg_c': 2.016150518531555e-08}. Best is trial 9 with value: 0.7037037037037037.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(study_name=\"tps-feb-2022\", direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "706d5939-fcde-41d3-a887-5fd91e1cff22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Best accuracy:  0.7037037037037037\n",
      "  Value: 0.7037037037037037\n",
      "  Params: \n",
      "    logreg_c: 1.233381092916111e-07\n"
     ]
    }
   ],
   "source": [
    "trial = study.best_trial\n",
    "print(\"  Best accuracy: \", study.best_value)\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "795924e9-059f-4ee6-b5cf-013093349b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1.233381092916111e-07)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=1.233381092916111e-07)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1.233381092916111e-07)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "best_params = study.best_params\n",
    "logreg_c = best_params[\"logreg_c\"]\n",
    "X_combined = np.vstack((X_train, X_val))\n",
    "y_combined = np.hstack((y_train, y_val))\n",
    "best_clf = LogisticRegression(C=logreg_c)\n",
    "best_clf.fit(X_combined, y_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7fc586a5-45da-4454-b7a4-fd75c538c828",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_preds = best_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5d4b33ad-6423-45f5-bce1-08eeb096c53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set evaluation: {'accuracy': 0.7037037037037037, 'precision': 0.7026678783971783, 'recall': 0.7007491789819376, 'f1_score': 0.6976624063049259}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "overall_metrics = {\n",
    "    'accuracy': accuracy_score(y_test, best_preds),\n",
    "    'precision': precision_score(y_test, best_preds, average='macro'),\n",
    "    'recall': recall_score(y_test, best_preds, average='macro'),\n",
    "    'f1_score': f1_score(y_test, best_preds, average='macro')\n",
    "}\n",
    "\n",
    "print(\"Test set evaluation:\", overall_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "404c97e2-9aa4-4dad-894a-8fd1820a5163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender bias analysis: {'female': {'accuracy': 0.7102803738317757, 'precision': 0.7141739388062918, 'recall': 0.7029761904761904, 'f1': 0.70165816334615, 'tpr': array([0.57142857, 0.85714286, 0.78571429, 0.8       , 0.46666667,\n",
      "       0.85714286, 0.78571429, 0.5       ]), 'fpr': array([0.02      , 0.03225806, 0.01075269, 0.08695652, 0.0326087 ,\n",
      "       0.05376344, 0.03225806, 0.06451613]), 'fnr': array([0.42857143, 0.14285714, 0.21428571, 0.2       , 0.53333333,\n",
      "       0.14285714, 0.21428571, 0.5       ]), 'precision_value': array([0.66666667, 0.8       , 0.91666667, 0.6       , 0.7       ,\n",
      "       0.70588235, 0.78571429, 0.53846154]), 'positive_rate': 3.7289719626168223}, 'male': {'accuracy': 0.6972477064220184, 'precision': 0.6980881691408007, 'recall': 0.6952380952380952, 'f1': 0.6835446207593774, 'tpr': array([0.71428571, 0.93333333, 0.66666667, 0.42857143, 0.6       ,\n",
      "       0.64285714, 0.64285714, 0.93333333]), 'fpr': array([0.03921569, 0.05319149, 0.0212766 , 0.02105263, 0.04255319,\n",
      "       0.06315789, 0.03157895, 0.07446809]), 'fnr': array([0.28571429, 0.06666667, 0.33333333, 0.57142857, 0.4       ,\n",
      "       0.35714286, 0.35714286, 0.06666667]), 'precision_value': array([0.55555556, 0.73684211, 0.83333333, 0.75      , 0.69230769,\n",
      "       0.6       , 0.75      , 0.66666667]), 'positive_rate': 3.7889908256880735}}\n",
      "Disparate Impact Ratio: 0.9841596705211467\n",
      "False Positive Equality: 0.0016726146465961753\n",
      "False Negative Equality: 0.007738095238095266\n"
     ]
    }
   ],
   "source": [
    "metrics_by_gender = {}\n",
    "for gender in np.unique(gender_test):\n",
    "    gender_indices = np.where(gender_test == gender)\n",
    "    X_gender_test = X_test[gender_indices]\n",
    "    y_gender_test = y_test[gender_indices]\n",
    "    y_pred = best_clf.predict(X_gender_test)\n",
    "\n",
    "    accuracy = np.mean(y_pred == y_gender_test)\n",
    "    precision = precision_score(y_gender_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_gender_test, y_pred, average='macro')\n",
    "    f1 = f1_score(y_gender_test, y_pred, average='macro')\n",
    "\n",
    "    cm = confusion_matrix(y_gender_test, y_pred)\n",
    "    tn = np.sum(cm) - (np.sum(cm, axis=0) + np.sum(cm, axis=1) - np.diag(cm))\n",
    "    fp = np.sum(cm, axis=0) - np.diag(cm)\n",
    "    fn = np.sum(cm, axis=1) - np.diag(cm)\n",
    "    tp = np.diag(cm)\n",
    "    tpr = tp / (tp + fn)  # True Positive Rate\n",
    "    fpr = fp / (fp + tn)  # False Positive Rate\n",
    "    fnr = fn / (fn + tp)  # False Negative Rate\n",
    "    precision_value = tp / (tp + fp)\n",
    "\n",
    "    metrics_by_gender[gender] = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'tpr': tpr,\n",
    "        'fpr': fpr,\n",
    "        'fnr': fnr,\n",
    "        'precision_value': precision_value,\n",
    "        'positive_rate': np.mean(y_pred)\n",
    "    }\n",
    "\n",
    "# Additional fairness metrics\n",
    "positive_rates = [metrics_by_gender[gender]['positive_rate'] for gender in metrics_by_gender]\n",
    "disparate_impact_ratio = min(positive_rates) / max(positive_rates)\n",
    "\n",
    "print(\"Gender bias analysis:\", metrics_by_gender)\n",
    "print(\"Disparate Impact Ratio:\", disparate_impact_ratio)\n",
    "\n",
    "for gender in metrics_by_gender:\n",
    "    metrics_by_gender[gender]['demographic_parity'] = metrics_by_gender[gender]['positive_rate']\n",
    "    metrics_by_gender[gender]['equalized_odds'] = (metrics_by_gender[gender]['fpr'], metrics_by_gender[gender]['fnr'])\n",
    "    metrics_by_gender[gender]['equal_opportunity'] = metrics_by_gender[gender]['tpr']\n",
    "    metrics_by_gender[gender]['predictive_parity'] = metrics_by_gender[gender]['precision_value']\n",
    "\n",
    "fpr_values = [metrics_by_gender[gender]['fpr'] for gender in metrics_by_gender]\n",
    "fnr_values = [metrics_by_gender[gender]['fnr'] for gender in metrics_by_gender]\n",
    "\n",
    "avg_fpr_values = [np.mean(fpr) for fpr in fpr_values]\n",
    "avg_fnr_values = [np.mean(fnr) for fnr in fnr_values]\n",
    "\n",
    "false_positive_equality = max(avg_fpr_values) - min(avg_fpr_values)\n",
    "false_negative_equality = max(avg_fnr_values) - min(avg_fnr_values)\n",
    "\n",
    "print(\"False Positive Equality:\", false_positive_equality)\n",
    "print(\"False Negative Equality:\", false_negative_equality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a28d1992-367e-4abc-8875-fada0741fbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Metric  \\\n",
      "0                    Accuracy   \n",
      "1                   Precision   \n",
      "2                      Recall   \n",
      "3                    F1 Score   \n",
      "4          True Positive Rate   \n",
      "5         False Positive Rate   \n",
      "6         False Negative Rate   \n",
      "7           Predictive Parity   \n",
      "8               Positive Rate   \n",
      "9          Demographic Parity   \n",
      "10  Equalized Odds (FPR, FNR)   \n",
      "11    Equal Opportunity (TPR)   \n",
      "\n",
      "                                                 Male  \\\n",
      "0                                            0.697248   \n",
      "1                                            0.698088   \n",
      "2                                            0.695238   \n",
      "3                                            0.683545   \n",
      "4   [0.7142857142857143, 0.9333333333333333, 0.666...   \n",
      "5   [0.0392156862745098, 0.05319148936170213, 0.02...   \n",
      "6   [0.2857142857142857, 0.06666666666666667, 0.33...   \n",
      "7   [0.5555555555555556, 0.7368421052631579, 0.833...   \n",
      "8                                            3.788991   \n",
      "9                                            3.788991   \n",
      "10  ([0.0392156862745098, 0.05319148936170213, 0.0...   \n",
      "11  [0.7142857142857143, 0.9333333333333333, 0.666...   \n",
      "\n",
      "                                               Female  \n",
      "0                                             0.71028  \n",
      "1                                            0.714174  \n",
      "2                                            0.702976  \n",
      "3                                            0.701658  \n",
      "4   [0.5714285714285714, 0.8571428571428571, 0.785...  \n",
      "5   [0.02, 0.03225806451612903, 0.0107526881720430...  \n",
      "6   [0.42857142857142855, 0.14285714285714285, 0.2...  \n",
      "7   [0.6666666666666666, 0.8, 0.9166666666666666, ...  \n",
      "8                                            3.728972  \n",
      "9                                            3.728972  \n",
      "10  ([0.02, 0.03225806451612903, 0.010752688172043...  \n",
      "11  [0.5714285714285714, 0.8571428571428571, 0.785...  \n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'Metric': [\n",
    "        'Accuracy', 'Precision', 'Recall', 'F1 Score', 'True Positive Rate', 'False Positive Rate',\n",
    "        'False Negative Rate', 'Predictive Parity', 'Positive Rate', 'Demographic Parity',\n",
    "        'Equalized Odds (FPR, FNR)', 'Equal Opportunity (TPR)'\n",
    "    ],\n",
    "    'Male': [\n",
    "        metrics_by_gender['male']['accuracy'], metrics_by_gender['male']['precision'],\n",
    "        metrics_by_gender['male']['recall'], metrics_by_gender['male']['f1'],\n",
    "        metrics_by_gender['male']['tpr'], metrics_by_gender['male']['fpr'],\n",
    "        metrics_by_gender['male']['fnr'], metrics_by_gender['male']['precision_value'],\n",
    "        metrics_by_gender['male']['positive_rate'], metrics_by_gender['male']['demographic_parity'],\n",
    "        metrics_by_gender['male']['equalized_odds'], metrics_by_gender['male']['equal_opportunity']\n",
    "    ],\n",
    "    'Female': [\n",
    "        metrics_by_gender['female']['accuracy'], metrics_by_gender['female']['precision'],\n",
    "        metrics_by_gender['female']['recall'], metrics_by_gender['female']['f1'],\n",
    "        metrics_by_gender['female']['tpr'], metrics_by_gender['female']['fpr'],\n",
    "        metrics_by_gender['female']['fnr'], metrics_by_gender['female']['precision_value'],\n",
    "        metrics_by_gender['female']['positive_rate'], metrics_by_gender['female']['demographic_parity'],\n",
    "        metrics_by_gender['female']['equalized_odds'], metrics_by_gender['female']['equal_opportunity']\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create DataFrame and display\n",
    "df = pd.DataFrame(data)\n",
    "csv_file_path = 'early_fusion_metrics_results.csv'\n",
    "df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c0c81a-e312-48c0-b08c-57d72c8d0252",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross-Modal Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29894d62-9c96-49b3-bccc-dc7a91c7f178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Dense, Flatten, Add, Multiply, Input\n",
    "from tensorflow.keras.models import Model\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eadc826d-17db-410f-a6c6-70afe2035c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(Layer):\n",
    "    def __init__(self, num_heads, key_dim):\n",
    "        super(CrossAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.key_dim = key_dim\n",
    "        self.query_dense = Dense(key_dim * num_heads, use_bias=False)\n",
    "        self.key_dense = Dense(key_dim * num_heads, use_bias=False)\n",
    "        self.value_dense = Dense(key_dim * num_heads, use_bias=False)\n",
    "        self.combine_heads = Dense(key_dim * num_heads)\n",
    "\n",
    "    def call(self, query, context):\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(context)\n",
    "        value = self.value_dense(context)\n",
    "        \n",
    "        query = tf.reshape(query, (-1, query.shape[1], self.num_heads, self.key_dim))\n",
    "        key = tf.reshape(key, (-1, key.shape[1], self.num_heads, self.key_dim))\n",
    "        value = tf.reshape(value, (-1, value.shape[1], self.num_heads, self.key_dim))\n",
    "\n",
    "        attention = tf.einsum('bijh,bjkh->bikh', query, key) / (self.key_dim ** 0.5)\n",
    "        attention_weights = tf.nn.softmax(attention, axis=-1)\n",
    "        out = tf.einsum('bikh,bjkh->bijh', attention_weights, value)\n",
    "        out = tf.reshape(out, (-1, query.shape[1], self.num_heads * self.key_dim))\n",
    "        \n",
    "        return self.combine_heads(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6e411f7-1a0e-4bd6-b376-620ee475dc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Localization Network with input shape: (None, 48, 48, 1)\n",
      "Building Bilinear Interpolation Layer with input shape: ((None, 48, 48, 1), (None, 2, 3))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No such layer: conv2d_5. Existing layers are: ['conv2d_7', 'batch_normalization', 'activation', 'max_pooling2d_3', 'conv2d_8', 'batch_normalization_1', 'activation_1', 'max_pooling2d_4', 'conv2d_9', 'batch_normalization_2', 'activation_2', 'conv2d_10', 'batch_normalization_3', 'activation_3', 'conv2d_11', 'batch_normalization_4', 'activation_4', 'max_pooling2d_5', 'flatten_2', 'dense_6', 'batch_normalization_5', 'activation_5', 'dropout_2', 'dense_7', 'batch_normalization_6', 'activation_6', 'dropout_3', 'dense_8', 'batch_normalization_7', 'activation_7'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m model_audio\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     38\u001b[0m model_audio\u001b[38;5;241m.\u001b[39mload_weights(save_dir_aud \u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_1.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 39\u001b[0m model_audio \u001b[38;5;241m=\u001b[39m Model(inputs\u001b[38;5;241m=\u001b[39mmodel_audio\u001b[38;5;241m.\u001b[39minput, outputs\u001b[38;5;241m=\u001b[39m\u001b[43mmodel_audio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconv2d_5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39moutput)\n\u001b[1;32m     40\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[1;32m     42\u001b[0m combined_model \u001b[38;5;241m=\u001b[39m create_crossmodal_model(final_model_video, model_audio, num_classes)\n",
      "File \u001b[0;32m/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/engine/training.py:3567\u001b[0m, in \u001b[0;36mModel.get_layer\u001b[0;34m(self, name, index)\u001b[0m\n\u001b[1;32m   3565\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m name:\n\u001b[1;32m   3566\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m layer\n\u001b[0;32m-> 3567\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3568\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such layer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Existing layers are: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3569\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(layer\u001b[38;5;241m.\u001b[39mname\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mlayer\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3570\u001b[0m     )\n\u001b[1;32m   3571\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3572\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvide either a layer name or layer index at `get_layer`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3573\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: No such layer: conv2d_5. Existing layers are: ['conv2d_7', 'batch_normalization', 'activation', 'max_pooling2d_3', 'conv2d_8', 'batch_normalization_1', 'activation_1', 'max_pooling2d_4', 'conv2d_9', 'batch_normalization_2', 'activation_2', 'conv2d_10', 'batch_normalization_3', 'activation_3', 'conv2d_11', 'batch_normalization_4', 'activation_4', 'max_pooling2d_5', 'flatten_2', 'dense_6', 'batch_normalization_5', 'activation_5', 'dropout_2', 'dense_7', 'batch_normalization_6', 'activation_6', 'dropout_3', 'dense_8', 'batch_normalization_7', 'activation_7']."
     ]
    }
   ],
   "source": [
    "def create_crossmodal_model(visual_model, audio_model, num_classes):\n",
    "    #visual_input = visual_model.input\n",
    "    visual_features = visual_model.input\n",
    "\n",
    "    #audio_input = Input(shape=(128, 128, 3))\n",
    "    #audio_input = audio_model.input\n",
    "    audio_features = audio_model.input\n",
    "    #audio_features = audio_model(audio_input)\n",
    "\n",
    "    # Self-Attention for visual and audio features\n",
    "    visual_attention = tf.keras.layers.MultiHeadAttention(num_heads=8, key_dim=64)(visual_features, visual_features)\n",
    "    audio_attention = tf.keras.layers.MultiHeadAttention(num_heads=8, key_dim=64)(audio_features, audio_features)\n",
    "\n",
    "    # Cross-Attention from visual to audio and vice versa\n",
    "    visual_to_audio_attention = CrossAttention(num_heads=8, key_dim=64)(visual_attention, audio_attention)\n",
    "    audio_to_visual_attention = CrossAttention(num_heads=8, key_dim=64)(audio_attention, visual_attention)\n",
    "\n",
    "    # Combine the features\n",
    "    combined_features = Add()([visual_attention, visual_to_audio_attention])\n",
    "    combined_features = Multiply()([combined_features, audio_to_visual_attention])\n",
    "\n",
    "    # Fully connected layers\n",
    "    combined_features = Flatten()(combined_features)\n",
    "    output = Dense(num_classes, activation='softmax')(combined_features)\n",
    "\n",
    "    return Model(inputs=[visual_input, audio_input], outputs=output)\n",
    "\n",
    "save_dir = os.path.abspath(DIR)+'/saved_models_lrcn_stn/'\n",
    "final_model_video = create__LRCN_with_STN()\n",
    "final_model_video.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=[\"accuracy\"])\n",
    "final_model_video.load_weights(save_dir + \"model_1.h5\")  # Adjust to load the best model if necessary\n",
    "\n",
    "final_model_video = Model(inputs=final_model_video.input, outputs=final_model_video.get_layer('time_distributed_2').output)\n",
    "\n",
    "save_dir_aud = os.path.abspath(DIR)+'/saved_model_feature_extraction_audio/'\n",
    "model_audio = model_alexnet()\n",
    "model_audio.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=[\"accuracy\"])\n",
    "model_audio.load_weights(save_dir_aud +\"model_1.h5\")\n",
    "model_audio = Model(inputs=model_audio.input, outputs=model_audio.get_layer('conv2d_5').output)\n",
    "num_classes = 8\n",
    "\n",
    "combined_model = create_crossmodal_model(final_model_video, model_audio, num_classes)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9cdce2a0-7c3e-4dbb-8b36-6dcf6add778b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Localization Network with input shape: (None, 48, 48, 1)\n",
      "Building Bilinear Interpolation Layer with input shape: ((None, 48, 48, 1), (None, 2, 3))\n"
     ]
    }
   ],
   "source": [
    "save_dir = os.path.abspath(DIR)+'/saved_models_lrcn_stn/'\n",
    "final_model_video = create__LRCN_with_STN()\n",
    "final_model_video.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=[\"accuracy\"])\n",
    "final_model_video.load_weights(save_dir + \"model_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a63daad1-5954-4779-9e0d-f64cad503d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 20, 48, 48, 1) dtype=float32 (created by layer 'input_6')>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model_video.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f092bd76-4899-4d81-8fcf-b257210b6b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 8) dtype=float32 (created by layer 'dense_23')>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model_video.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c14db42c-fb22-45e7-8dc0-dc393f2dd8c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 128, 128, 3) dtype=float32 (created by layer 'conv2d_30_input')>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_audio.input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e0e365e4-ec6f-4e58-ad39-e33000a8efb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 8) dtype=float32 (created by layer 'activation_31')>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_audio.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c5f554-48b4-4660-a85d-10d6919d7d26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc6d113-386d-42f4-8820-dce1d7dfbd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intermediate fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d6771e5-6767-4772-a651-aece4bd63354",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "indice_fold = 1\n",
    "save_dir = os.path.abspath(DIR)+'/saved_model_feature_extraction_audio/'\n",
    "model_audio = model_alexnet()\n",
    "model_audio.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=[\"accuracy\"])\n",
    "model_audio.load_weights(save_dir +\"model_\"+str(indice_fold)+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db2c7202-8771-43a3-be62-9a7b2f82d637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Localization Network with input shape: (None, 48, 48, 1)\n",
      "Building Bilinear Interpolation Layer with input shape: ((None, 48, 48, 1), (None, 2, 3))\n"
     ]
    }
   ],
   "source": [
    "save_dir = os.path.abspath(DIR)+'/saved_models_lrcn_stn/'\n",
    "\n",
    "model_video = create__LRCN_with_STN()\n",
    "model_video.compile(loss='sparese_categorical_crossentropy', optimizer='Adam', metrics=[\"accuracy\"])\n",
    "model_video.load_weights(save_dir+\"model_\"+str(indice_fold)+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee10c662-2607-47d2-ae13-a409f2f619bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_video_model=Model(inputs=model_video.input, outputs=model_video.get_layer('time_distributed_5').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a2e57bd-6a68-45a0-92f7-7761ef2d046c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 7s 191ms/step\n"
     ]
    }
   ],
   "source": [
    "features_video=features_video_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20e73631-6355-43b5-9541-665ffbe0f737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1008, 20, 1024)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04ea85bc-eef0-478b-9f39-415ee5ef7135",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_audio_model=Model(inputs=model_audio.input, outputs=model_audio.get_layer('conv2d_16').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1811c117-b493-428a-a600-c8d3bf613021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 12s 293ms/step\n"
     ]
    }
   ],
   "source": [
    "features_audio = features_audio_model.predict(X_train_aud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a959290b-8de0-487f-83db-3f76a50166ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1008, 32, 32, 256)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_audio.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "27999af6-e6dc-458d-8877-4c52bffb6b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 2s 232ms/step\n",
      "7/7 [==============================] - 2s 236ms/step\n",
      "7/7 [==============================] - 2s 287ms/step\n",
      "7/7 [==============================] - 2s 275ms/step\n"
     ]
    }
   ],
   "source": [
    "features_video_val = features_video_model.predict(X_val)\n",
    "features_video_test = features_video_model.predict(X_test)\n",
    "\n",
    "features_audio_val = features_audio_model.predict(X_val_aud)\n",
    "features_audio_test = features_audio_model.predict(X_test_aud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "283267bd-5a56-4f21-8810-f6a6b0cfc9ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216, 32, 32, 256)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_audio_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "47d8c25a-d7ef-41fa-a145-31baa3ca1797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216, 262144)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_audio_flattened = np.reshape(features_audio, (1008, -1))\n",
    "features_audio_flattened_val = np.reshape(features_audio_val, (216, -1))\n",
    "features_audio_flattened_test = np.reshape(features_audio_test, (216, -1))\n",
    "features_audio_flattened_val.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ea7c6e7f-3a3c-4f87-b256-d1cbc368edec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "lda = PCA(n_components=1000)\n",
    "features_audio_flattened = lda.fit_transform(features_audio_flattened)\n",
    "features_audio_flattened_val = lda.transform(features_audio_flattened_val)\n",
    "features_audio_flattened_test = lda.transform(features_audio_flattened_test)\n",
    "\n",
    "# X_test = lda.transform(X_test)\n",
    "# X_val = lda.transform(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "24cb2fde-7072-491e-a848-3af12d7cfda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216, 1000)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_audio_flattened_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "15ed0dab-b46e-4f98-a9b0-18fb232124f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.10063721e+02,  5.79397827e+02, -4.13256500e+02, ...,\n",
       "        -2.42818222e+01,  5.88011932e+00,  1.06233454e+00],\n",
       "       [ 1.31789734e+03, -2.95173248e+02, -5.66947510e+02, ...,\n",
       "        -6.98942757e+00,  3.30174279e+00,  1.11193764e+00],\n",
       "       [-5.96122986e+02, -1.26955925e+02, -3.18186874e+01, ...,\n",
       "         3.06036329e+00,  4.48986721e+00, -5.27141380e+00],\n",
       "       ...,\n",
       "       [-8.35318115e+02,  2.15608459e+02, -3.29985443e+02, ...,\n",
       "        -2.29646778e+00,  5.72856855e+00,  1.25495796e+01],\n",
       "       [-9.42429993e+02, -7.86249771e+01, -4.49961273e+02, ...,\n",
       "         6.77876472e-01,  1.25635633e+01, -1.15308666e+01],\n",
       "       [ 8.87471436e+02,  4.45727921e+01, -5.61877686e+02, ...,\n",
       "         1.15943079e+01,  2.06615200e+01, -6.21164131e+00]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_audio_flattened_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fd5288d2-c9b8-4180-b067-a0e99b2a531d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(216, 20, 1000)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_audio_reshape = np.reshape(features_audio_flattened, (1008, 1, 1000))\n",
    "features_audio_repeated = np.repeat(features_audio_reshape, 20, axis=1)\n",
    "\n",
    "features_audio_reshape_val = np.reshape(features_audio_flattened_val, (216, 1, 1000))\n",
    "features_audio_repeated_val = np.repeat(features_audio_reshape_val, 20, axis=1)\n",
    "\n",
    "features_audio_reshape_test = np.reshape(features_audio_flattened_test, (216, 1, 1000))\n",
    "features_audio_repeated_test = np.repeat(features_audio_reshape_test, 20, axis=1)\n",
    "# X_val_aud_repeated = X_val_aud_repeated/255\n",
    "features_audio_repeated_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9671da69-3df7-418e-9ad3-f40a1bf809c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_train_data = np.concatenate((features_video, features_audio_repeated), axis=-1)\n",
    "concatenated_val_data = np.concatenate((features_video_val, features_audio_repeated_val), axis=-1)\n",
    "concatenated_test_data = np.concatenate((features_video_test, features_audio_repeated_test), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "54805844-f2e1-479d-b897-abf937b60771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1008, 20, 2024)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c822e575-ddd6-4c4d-8b74-f431c3ce5e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(np.unique(y_train))\n",
    "print(num_classes)\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_val = to_categorical(y_val, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bff2d219-b6c1-486b-b6e1-24102e87bcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(trial):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Suggest the number of LSTM units\n",
    "    lstm_units = trial.suggest_int(\"lstm_units\", 32, 256)\n",
    "    model.add(LSTM(lstm_units, input_shape=(concatenated_train_data.shape[1], concatenated_train_data.shape[2]), return_sequences=False))\n",
    "\n",
    "    # Suggest a dropout rate\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Add a dense layer with softmax activation for multi-class classification\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "34a90f21-b80f-4b78-8985-c72209fd61d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def objective(trial):\n",
    "#     logreg_c = trial.suggest_float(\"logreg_c\", 1e-10, 1e10, log=True)\n",
    "#     X_combined = np.vstack((concatenated_train_data, concatenated_val_data))\n",
    "#     y_combined = np.hstack((y_train, y_val))\n",
    "    \n",
    "#     # Initialize the logistic regression model with the suggested C value\n",
    "#     clf = linear_model.LogisticRegression(C=logreg_c)\n",
    "    \n",
    "#     # Fit the model on the combined training and validation data\n",
    "#     clf.fit(X_combined, y_combined)\n",
    "#     preds = clf.predict(concatenated_test_data)\n",
    "#     score = accuracy_score(y_test, preds)\n",
    "#     gc.collect()\n",
    "#     return score\n",
    "\n",
    "def objective(trial):\n",
    "    model = create_model(trial)\n",
    "    \n",
    "    # Fit the model on the training data\n",
    "    model.fit(concatenated_train_data, y_train, epochs=80, batch_size=16, validation_data=(concatenated_val_data, y_val), verbose=0)\n",
    "    \n",
    "    # Evaluate the model on the test data\n",
    "    preds = model.predict(concatenated_test_data)\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    y_test_labels = np.argmax(y_test, axis=1)\n",
    "    score = accuracy_score(y_test_labels, preds)\n",
    "    \n",
    "    # Clean up memory\n",
    "    gc.collect()\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "239394b9-4944-4651-9718-e618369a5a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-14 22:58:56,779] A new study created in memory with name: no-name-bcc86627-bddb-4f8c-a3bb-24cac29d3ec9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-14 23:01:57,290] Trial 0 finished with value: 0.1388888888888889 and parameters: {'lstm_units': 241, 'dropout_rate': 0.3827106750177438}. Best is trial 0 with value: 0.1388888888888889.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-14 23:03:19,324] Trial 1 finished with value: 0.11574074074074074 and parameters: {'lstm_units': 74, 'dropout_rate': 0.19331554189753747}. Best is trial 0 with value: 0.1388888888888889.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-14 23:04:56,986] Trial 2 finished with value: 0.12962962962962962 and parameters: {'lstm_units': 97, 'dropout_rate': 0.3371819000803809}. Best is trial 0 with value: 0.1388888888888889.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-14 23:06:22,027] Trial 3 finished with value: 0.16203703703703703 and parameters: {'lstm_units': 77, 'dropout_rate': 0.18403895161884842}. Best is trial 3 with value: 0.16203703703703703.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-14 23:08:27,523] Trial 4 finished with value: 0.16666666666666666 and parameters: {'lstm_units': 153, 'dropout_rate': 0.3683462516079533}. Best is trial 4 with value: 0.16666666666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-14 23:11:24,027] Trial 5 finished with value: 0.12962962962962962 and parameters: {'lstm_units': 234, 'dropout_rate': 0.11345614240351641}. Best is trial 4 with value: 0.16666666666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-14 23:14:17,039] Trial 6 finished with value: 0.11574074074074074 and parameters: {'lstm_units': 228, 'dropout_rate': 0.3129173801100682}. Best is trial 4 with value: 0.16666666666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-14 23:15:14,603] Trial 7 finished with value: 0.16203703703703703 and parameters: {'lstm_units': 36, 'dropout_rate': 0.33686439769435245}. Best is trial 4 with value: 0.16666666666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-14 23:16:41,113] Trial 8 finished with value: 0.10648148148148148 and parameters: {'lstm_units': 84, 'dropout_rate': 0.10943754376007303}. Best is trial 4 with value: 0.16666666666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-14 23:17:42,679] Trial 9 finished with value: 0.09722222222222222 and parameters: {'lstm_units': 34, 'dropout_rate': 0.29503027606085075}. Best is trial 4 with value: 0.16666666666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-14 23:19:59,977] Trial 10 finished with value: 0.13425925925925927 and parameters: {'lstm_units': 172, 'dropout_rate': 0.4909920772539739}. Best is trial 4 with value: 0.16666666666666666.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-14 23:22:05,694] Trial 11 finished with value: 0.14814814814814814 and parameters: {'lstm_units': 154, 'dropout_rate': 0.22427138283832374}. Best is trial 4 with value: 0.16666666666666666.\n",
      "[W 2024-07-14 23:23:42,214] Trial 12 failed with parameters: {'lstm_units': 126, 'dropout_rate': 0.42887831517757125} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_21469/3251019886.py\", line 20, in objective\n",
      "    model.fit(concatenated_train_data, y_train, epochs=80, batch_size=16, validation_data=(concatenated_val_data, y_val), verbose=0)\n",
      "  File \"/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1807, in fit\n",
      "    tmp_logs = self.train_function(iterator)\n",
      "  File \"/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 832, in __call__\n",
      "    result = self._call(*args, **kwds)\n",
      "  File \"/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\", line 868, in _call\n",
      "    return tracing_compilation.call_function(\n",
      "  File \"/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\", line 139, in call_function\n",
      "    return function._call_flat(  # pylint: disable=protected-access\n",
      "  File \"/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\", line 1323, in _call_flat\n",
      "    return self._inference_function.call_preflattened(args)\n",
      "  File \"/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 216, in call_preflattened\n",
      "    flat_outputs = self.call_flat(*args)\n",
      "  File \"/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\", line 251, in call_flat\n",
      "    outputs = self._bound_context.call_function(\n",
      "  File \"/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/context.py\", line 1486, in call_function\n",
      "    outputs = execute.execute(\n",
      "  File \"/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\", line 53, in quick_execute\n",
      "    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n",
      "KeyboardInterrupt\n",
      "[W 2024-07-14 23:23:42,358] Trial 12 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgc\u001b[39;00m\n\u001b[1;32m      4\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/optuna/study/study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/optuna/study/_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/optuna/study/_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/optuna/study/_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[75], line 20\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m create_model(trial)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Fit the model on the training data\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcatenated_train_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m80\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconcatenated_val_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test data\u001b[39;00m\n\u001b[1;32m     23\u001b[0m preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(concatenated_test_data)\n",
      "File \u001b[0;32m/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/var/scratch/mpa326/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import accuracy_score\n",
    "import gc\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c113e189-e6e5-45da-907d-d07747a4fcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_video_flattened = np.reshape(features_video, (1008, -1))\n",
    "features_video_flattened_val = np.reshape(features_video_val, (216, -1))\n",
    "features_video_flattened_test = np.reshape(features_video_test, (216, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "50a36812-1bdf-4306-85d8-a65c93c6a8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_train_data = np.concatenate((features_video_flattened, features_audio_flattened), axis=-1)\n",
    "concatenated_val_data = np.concatenate((features_video_flattened_val, features_audio_flattened_val), axis=-1)\n",
    "concatenated_test_data = np.concatenate((features_video_flattened_test, features_audio_flattened_test), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d17d3e5b-1f00-43d3-8a78-7f73bb233a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    logreg_c = trial.suggest_float(\"logreg_c\", 1e-10, 1e10, log=True)\n",
    "    X_combined = np.vstack((concatenated_train_data, concatenated_val_data))\n",
    "    y_combined = np.hstack((y_train, y_val))\n",
    "    \n",
    "    # Initialize the logistic regression model with the suggested C value\n",
    "    clf = linear_model.LogisticRegression(C=logreg_c)\n",
    "    \n",
    "    # Fit the model on the combined training and validation data\n",
    "    clf.fit(X_combined, y_combined)\n",
    "    preds = clf.predict(concatenated_test_data)\n",
    "    score = accuracy_score(y_test, preds)\n",
    "    gc.collect()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bfd4e891-7b15-4fb2-8abf-d10f889f5c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-07-14 23:25:33,962] A new study created in memory with name: no-name-acb75a6c-6b7f-4b2d-9401-024ff6fd76b6\n",
      "[I 2024-07-14 23:26:03,166] Trial 0 finished with value: 0.1388888888888889 and parameters: {'logreg_c': 7.476308017052857e-05}. Best is trial 0 with value: 0.1388888888888889.\n",
      "[I 2024-07-14 23:26:19,757] Trial 1 finished with value: 0.14351851851851852 and parameters: {'logreg_c': 13548729.740835818}. Best is trial 1 with value: 0.14351851851851852.\n",
      "[I 2024-07-14 23:26:35,464] Trial 2 finished with value: 0.14351851851851852 and parameters: {'logreg_c': 412710128.95377797}. Best is trial 1 with value: 0.14351851851851852.\n",
      "[I 2024-07-14 23:27:04,413] Trial 3 finished with value: 0.13425925925925927 and parameters: {'logreg_c': 0.0004987116260962908}. Best is trial 1 with value: 0.14351851851851852.\n",
      "[I 2024-07-14 23:27:33,259] Trial 4 finished with value: 0.12962962962962962 and parameters: {'logreg_c': 3.171930631946704e-05}. Best is trial 1 with value: 0.14351851851851852.\n",
      "[I 2024-07-14 23:27:49,758] Trial 5 finished with value: 0.14351851851851852 and parameters: {'logreg_c': 2443968.032470509}. Best is trial 1 with value: 0.14351851851851852.\n",
      "[I 2024-07-14 23:28:05,832] Trial 6 finished with value: 0.12962962962962962 and parameters: {'logreg_c': 1.7400566947641607e-10}. Best is trial 1 with value: 0.14351851851851852.\n",
      "[I 2024-07-14 23:28:23,041] Trial 7 finished with value: 0.14351851851851852 and parameters: {'logreg_c': 57662473.66456681}. Best is trial 1 with value: 0.14351851851851852.\n",
      "[I 2024-07-14 23:28:52,655] Trial 8 finished with value: 0.13425925925925927 and parameters: {'logreg_c': 6.298001697744524e-05}. Best is trial 1 with value: 0.14351851851851852.\n",
      "[I 2024-07-14 23:29:04,298] Trial 9 finished with value: 0.10185185185185185 and parameters: {'logreg_c': 9.34691161104226e-10}. Best is trial 1 with value: 0.14351851851851852.\n",
      "[I 2024-07-14 23:29:23,814] Trial 10 finished with value: 0.14351851851851852 and parameters: {'logreg_c': 2283.9349443846695}. Best is trial 1 with value: 0.14351851851851852.\n",
      "[I 2024-07-14 23:29:39,572] Trial 11 finished with value: 0.14351851851851852 and parameters: {'logreg_c': 1544215274.0583436}. Best is trial 1 with value: 0.14351851851851852.\n",
      "[I 2024-07-14 23:29:59,495] Trial 12 finished with value: 0.14351851851851852 and parameters: {'logreg_c': 5314.373999805157}. Best is trial 1 with value: 0.14351851851851852.\n",
      "[I 2024-07-14 23:30:19,310] Trial 13 finished with value: 0.14351851851851852 and parameters: {'logreg_c': 17367.71489869959}. Best is trial 1 with value: 0.14351851851851852.\n",
      "[I 2024-07-14 23:30:38,436] Trial 14 finished with value: 0.14351851851851852 and parameters: {'logreg_c': 5248475034.27779}. Best is trial 1 with value: 0.14351851851851852.\n",
      "[I 2024-07-14 23:31:07,897] Trial 15 finished with value: 0.1574074074074074 and parameters: {'logreg_c': 1.2103682657669137}. Best is trial 15 with value: 0.1574074074074074.\n",
      "[I 2024-07-14 23:31:38,006] Trial 16 finished with value: 0.1574074074074074 and parameters: {'logreg_c': 2.2632425216495533}. Best is trial 15 with value: 0.1574074074074074.\n",
      "[I 2024-07-14 23:32:08,129] Trial 17 finished with value: 0.1527777777777778 and parameters: {'logreg_c': 0.9170500581112362}. Best is trial 15 with value: 0.1574074074074074.\n",
      "[I 2024-07-14 23:32:36,801] Trial 18 finished with value: 0.1527777777777778 and parameters: {'logreg_c': 0.6228417794410301}. Best is trial 15 with value: 0.1574074074074074.\n",
      "[I 2024-07-14 23:32:57,691] Trial 19 finished with value: 0.13425925925925927 and parameters: {'logreg_c': 94.67031973534753}. Best is trial 15 with value: 0.1574074074074074.\n",
      "[I 2024-07-14 23:33:26,112] Trial 20 finished with value: 0.1574074074074074 and parameters: {'logreg_c': 0.02112569932706813}. Best is trial 15 with value: 0.1574074074074074.\n",
      "[I 2024-07-14 23:33:58,205] Trial 21 finished with value: 0.14351851851851852 and parameters: {'logreg_c': 0.017965811352599628}. Best is trial 15 with value: 0.1574074074074074.\n",
      "[I 2024-07-14 23:34:23,244] Trial 22 finished with value: 0.1388888888888889 and parameters: {'logreg_c': 54.612359709961396}. Best is trial 15 with value: 0.1574074074074074.\n",
      "[I 2024-07-14 23:34:54,716] Trial 23 finished with value: 0.14351851851851852 and parameters: {'logreg_c': 0.011140404487173582}. Best is trial 15 with value: 0.1574074074074074.\n",
      "[I 2024-07-14 23:35:23,839] Trial 24 finished with value: 0.14351851851851852 and parameters: {'logreg_c': 8.820403851618716e-07}. Best is trial 15 with value: 0.1574074074074074.\n",
      "[I 2024-07-14 23:35:52,509] Trial 25 finished with value: 0.1574074074074074 and parameters: {'logreg_c': 15.088247433307387}. Best is trial 15 with value: 0.1574074074074074.\n",
      "[I 2024-07-14 23:36:19,066] Trial 26 finished with value: 0.1527777777777778 and parameters: {'logreg_c': 0.0214483263165708}. Best is trial 15 with value: 0.1574074074074074.\n",
      "[I 2024-07-14 23:36:35,644] Trial 27 finished with value: 0.14351851851851852 and parameters: {'logreg_c': 387665.47207311966}. Best is trial 15 with value: 0.1574074074074074.\n",
      "[I 2024-07-14 23:37:04,484] Trial 28 finished with value: 0.14351851851851852 and parameters: {'logreg_c': 2.1594936198747073e-06}. Best is trial 15 with value: 0.1574074074074074.\n",
      "[I 2024-07-14 23:37:33,843] Trial 29 finished with value: 0.1574074074074074 and parameters: {'logreg_c': 0.44408435622605463}. Best is trial 15 with value: 0.1574074074074074.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530298d6-803f-4a68-84ef-692f5b8df89c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
